{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/reduce_test.csv\n",
      "data/reduce_train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "import re\n",
    "\n",
    "base_dir = 'data/'\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(base_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "* In the last notebook we create our baseline model including a feature selection part. \n",
    "* Cohen cappa score of 0.456 (lb) with a local cv score of 0.529\n",
    "* In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve.\n",
    "* Next, we will check if this improvement aligns with the lb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Check the distribution of the target variable of the out of folds score and the prediction distribution. A good model should more or less have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(reduce_train['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(reduce_train)\n",
    "    reduce_train['accuracy_group'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True\n",
    "\n",
    "def cohenkappa(ypred, y):\n",
    "    y = y.get_label().astype(\"int\")\n",
    "    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n",
    "    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n",
    "    return \"cappa\", loss, True\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod(\n",
    "            (datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv(base_dir + 'train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv(base_dir + 'test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv(base_dir + 'train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv(base_dir + 'specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv(base_dir + 'sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    user_activities_time = {'Clip_time_mean':[], 'Activity_time_mean': [], 'Game_time_mean': []}\n",
    "    \n",
    "    positive_words = \"play again|did it|job|wow|cool|nice|amazing|exactly|Great|awe|That's it|just right|good|Alright|gold|That's right|All right|right amount|Well done|you're right|happy|won|Whoa\"\n",
    "    negative_words = \"try again|too|Almost|n't|but|Whoops|Oops|not right|Uh oh\"\n",
    "    accumulated_positive_events = 0\n",
    "    accumulated_negative_events = 0\n",
    "    accumulated_positive_title = {'accumulated_positive_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_negative_title = {'accumulated_negative_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_positive_title_ratio = {'accumulated_positive_ratio_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_negative_title_ratio = {'accumulated_negative_ratio_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_won_game = {'accumulated_won_game_count_'+g: 0 for g in game_titles}\n",
    "    \n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0\n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    durations = []\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {e_c: 0 for e_c in list_of_event_code}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()}\n",
    "    title_event_code_count: Dict[str, int] = {t_e: 0 for t_e in all_title_event_code}\n",
    "    accumulated_correct_title = {'accumulated_correct_'+title: 0 for title in assess_titles}\n",
    "    accumulated_uncorrect_title = {'accumulated_uncorrect_'+title: 0 for title in assess_titles}\n",
    "    accumulated_accuracy_title = {'acc_mean_' + title: 0 for title in assess_titles}\n",
    "    accumulated_accuracy_titles = {'acc_' + title: [] for title in assess_titles}\n",
    "    \n",
    "    time_spent_each_act = {t+\"_time\": 0 for t in list_of_user_activities}\n",
    "    time_spent_each_acts = {t+\"_time\": [] for t in list_of_user_activities}\n",
    "    time_spent_each_act_mean = {t+\"_time_mean\": 0 for t in list_of_user_activities}\n",
    "    \n",
    "    \n",
    "    # itarates through each session of one installation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "    \n",
    "        if (session_type=='Clip'):\n",
    "            time_spent = media_sequence[session_title_text]\n",
    "            user_activities_time[session_type+'_time_mean'].append(time_spent)\n",
    "            time_spent_each_act[session_title_text + \"_time\"] += time_spent\n",
    "            time_spent_each_acts[session_title_text + \"_time\"].append(time_spent)\n",
    "        \n",
    "        elif(session_type=='Activity' or session_type=='Game'):\n",
    "            time_spent = (session.iloc[-1, 2] - session.iloc[0, 2]).seconds\n",
    "            user_activities_time[session_type+'_time_mean'].append(time_spent)\n",
    "            time_spent_each_act[session_title_text + \"_time\"] += time_spent\n",
    "            time_spent_each_acts[session_title_text + \"_time\"].append(time_spent)\n",
    "            \n",
    "            sum_positive_events = session['event_data'].str.contains(positive_words, flags=re.IGNORECASE).sum()\n",
    "            sum_negative_events = session['event_data'].str.contains(negative_words, flags=re.IGNORECASE).sum()\n",
    "            accumulated_positive_events += sum_positive_events\n",
    "            accumulated_negative_events += sum_negative_events\n",
    "            accumulated_positive_title['accumulated_positive_'+session_title_text] += sum_positive_events\n",
    "            accumulated_negative_title['accumulated_negative_'+session_title_text] += sum_negative_events\n",
    "            p = accumulated_positive_title['accumulated_positive_'+session_title_text]\n",
    "            n = accumulated_negative_title['accumulated_negative_'+session_title_text]\n",
    "            accumulated_positive_title_ratio['accumulated_positive__ratio_'+session_title_text] = p/(p+n) if (p+n)>0 else 0\n",
    "            accumulated_negative_title_ratio['accumulated_negative__ratio_'+session_title_text] = n/(p+n) if (p+n)>0 else 0\n",
    "            \n",
    "            if session_type == 'Game':\n",
    "                accumulated_won_game['accumulated_won_game_count_'+session_title_text]+=session['event_data'].str.contains('play again', flags=re.IGNORECASE).sum()\n",
    "        \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(accumulated_correct_title.copy())\n",
    "            features.update(accumulated_uncorrect_title.copy())\n",
    "            features.update(accumulated_accuracy_title.copy())\n",
    "            features.update(accumulated_positive_title)\n",
    "            features.update(accumulated_negative_title)\n",
    "            features.update(accumulated_positive_title_ratio)\n",
    "            features.update(accumulated_negative_title_ratio)\n",
    "            features.update(accumulated_won_game.copy())\n",
    "            features.update(time_spent_each_act.copy())\n",
    "            features.update(time_spent_each_act_mean.copy())\n",
    "            \n",
    "            variety_features = [('var_title', title_count),\n",
    "                                ('var_event_code', event_code_count),\n",
    "                               ('var_title_event_code', title_event_code_count)]\n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "            \n",
    "            # positive & negative events\n",
    "            features['accumulated_positive_events'] = accumulated_positive_events\n",
    "            features['accumulated_negative_events'] = accumulated_negative_events\n",
    "            positive_negative_events = accumulated_positive_events + accumulated_negative_events\n",
    "            features['positive_events_ratio'] = accumulated_positive_events/positive_negative_events if positive_negative_events > 0 else 0\n",
    "            features['negative_events_ratio'] = accumulated_negative_events/positive_negative_events if positive_negative_events > 0 else 0\n",
    "            accumulated_positive_events = 0\n",
    "            accumulated_negative_events = 0\n",
    "            \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_title['accumulated_correct_'+session_title_text] += true_attempts\n",
    "            accumulated_uncorrect_title['accumulated_uncorrect_'+session_title_text] += false_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "                features['accumulated_correct_duration'] = 0\n",
    "                features['accumulated_uncorrect_duration'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                features['accumulated_correct_duration'] = features['accumulated_correct_attempts']/np.sum(durations)\n",
    "                features['accumulated_uncorrect_duration'] = features['accumulated_uncorrect_attempts']/np.sum(durations)\n",
    "            if user_activities_time['Clip_time_mean']==[]:\n",
    "                features['Clip_time_mean'] = 0\n",
    "                features['Clip_time_std'] = 0\n",
    "            else:\n",
    "                features['Clip_time_mean'] = np.mean(user_activities_time['Clip_time_mean'])\n",
    "                features['Clip_time_std'] = np.std(user_activities_time['Clip_time_mean'])\n",
    "            if user_activities_time['Activity_time_mean']==[]:\n",
    "                features['Activity_time_mean'] = 0\n",
    "                features['Activity_time_std'] = 0\n",
    "            else:\n",
    "                features['Activity_time_mean'] = np.mean(user_activities_time['Activity_time_mean'])\n",
    "                features['Activity_time_std'] = np.std(user_activities_time['Activity_time_mean'])\n",
    "            if user_activities_time['Game_time_mean']==[]:\n",
    "                features['Game_time_mean'] = 0\n",
    "                features['Game_time_std'] = 0\n",
    "            else:\n",
    "                features['Game_time_mean'] = np.mean(user_activities_time['Game_time_mean'])\n",
    "                features['Game_time_std'] = np.std(user_activities_time['Game_time_mean'])\n",
    "            time_spent = (session.iloc[-1, 2] - session.iloc[0, 2]).seconds\n",
    "            time_spent_each_act[session_title_text + \"_time\"] += time_spent\n",
    "            time_spent_each_acts[session_title_text + \"_time\"].append(time_spent)\n",
    "            durations.append(time_spent)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            accumulated_accuracy_titles['acc_' + session_title_text].append(accuracy)\n",
    "            if accumulated_accuracy_titles['acc_' + session_title_text]==[]:\n",
    "                accumulated_accuracy_title['acc_mean_' + session_title_text] = 0\n",
    "            else:\n",
    "                accumulated_accuracy_title['acc_mean_' + session_title_text] = np.mean(accumulated_accuracy_titles['acc_' + session_title_text])\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "        \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "        \n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reduce_train, reduce_test):\n",
    "    for df in [reduce_train, reduce_test]:\n",
    "        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n",
    "        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n",
    "        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "        \n",
    "        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n",
    "                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n",
    "                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n",
    "        \n",
    "        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n",
    "        \n",
    "    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "    features = [x for x in features if x not in ['accuracy_group', 'installation_id']] + ['acc_' + title for title in assess_titles]\n",
    "   \n",
    "    return reduce_train, reduce_test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_game_titles = ['All Star Sorting', 'Fireworks (Activity)', 'Flower Waterer (Activity)', 'Air Show', 'Crystals Rule', 'Bug Measurer (Activity)', 'Sandcastle Builder (Activity)', 'Scrub-A-Dub', 'Watering Hole (Activity)', 'Dino Drink', 'Bubble Bath', 'Bottle Filler (Activity)', 'Dino Dive', 'Chow Time', 'Chicken Balancer (Activity)', 'Happy Camel', 'Leaf Leader', 'Pan Balance', 'Egg Dropper (Activity)']\n",
    "game_titles = ['All Star Sorting', 'Air Show', 'Crystals Rule', 'Scrub-A-Dub', 'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time', 'Happy Camel', 'Leaf Leader', 'Pan Balance']\n",
    "media_sequence = {'Welcome to Lost Lagoon!': 19, 'Tree Top City - Level 1':17, 'Ordering Spheres':61, 'Costume Box':61,'12 Monkeys':109, 'Tree Top City - Level 2':25, \"Pirate's Tale\":80, \n",
    "                  'Treasure Map':156, 'Tree Top City - Level 3':26, 'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18, \n",
    "                  'Balancing Act':72,'Lifting Heavy Things':118, 'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19, 'Heavy, Heavier, Heaviest':61}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理-特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e5dc554f74496bab1643cabbdf3105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in long_scalars\n",
      "invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca74d86700c4c8ead2b023161d19aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(17690, 755) (1000, 755) ['session_title']\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, \\\n",
    "list_of_event_code, activities_labels, assess_titles, list_of_event_id,\\\n",
    "all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "if not os.path.exists(base_dir + 'reduce_train.csv'):\n",
    "    reduce_train, reduce_test, categoricals = get_train_and_test(train, test)\n",
    "    reduce_train.to_csv(base_dir + 'reduce_train.csv')\n",
    "    reduce_test.to_csv(base_dir + 'reduce_test.csv')\n",
    "    print(reduce_train.shape, reduce_test.shape, categoricals)\n",
    "else:\n",
    "    reduce_train = pd.read_csv(base_dir + 'reduce_train.csv')\n",
    "    reduce_test = pd.read_csv(base_dir + 'reduce_test.csv')\n",
    "    categoricals = ['session_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call feature engineering function\n",
    "# reduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stract_hists(feature, train=reduce_train, test=reduce_test, adjust=False, plot=False):\n",
    "    n_bins = 10\n",
    "    train_data = train[feature]\n",
    "    test_data = test[feature]\n",
    "    if adjust:\n",
    "        test_data *= train_data.mean() / test_data.mean()\n",
    "    perc_90 = np.percentile(train_data, 95)\n",
    "    train_data = np.clip(train_data, 0, perc_90)\n",
    "    test_data = np.clip(test_data, 0, perc_90)\n",
    "    train_hist = np.histogram(train_data, bins=n_bins)[0] / len(train_data)\n",
    "    test_hist = np.histogram(test_data, bins=n_bins)[0] / len(test_data)\n",
    "    msre = mean_squared_error(train_hist, test_hist)\n",
    "    if plot:\n",
    "        print(msre)\n",
    "        plt.bar(range(n_bins), train_hist, color='blue', alpha=0.5)\n",
    "        plt.bar(range(n_bins), test_hist, color='red', alpha=0.5)\n",
    "        plt.show()\n",
    "    return msre\n",
    "# stract_hists('Magma Peak - Level 1_2000', adjust=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call feature engineering function\n",
    "features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in features if x not in ['accuracy_group', 'installation_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: FEAT_A: 2050 FEAT_B: 2040 - Correlation: 0.9965259434878118\n",
      "2: FEAT_A: 2050 FEAT_B: Scrub-A-Dub_3121 - Correlation: 0.9999839030068793\n",
      "3: FEAT_A: 2050 FEAT_B: Scrub-A-Dub_3021 - Correlation: 0.9998050146713992\n",
      "4: FEAT_A: 2050 FEAT_B: Scrub-A-Dub_2030 - Correlation: 0.9966123918733654\n",
      "5: FEAT_A: 2050 FEAT_B: Scrub-A-Dub_2040 - Correlation: 0.9965259434878118\n",
      "6: FEAT_A: 2050 FEAT_B: Scrub-A-Dub_2050 - Correlation: 1.0\n",
      "7: FEAT_A: 2050 FEAT_B: Scrub-A-Dub_2020 - Correlation: 0.9965084543995759\n",
      "8: FEAT_A: 2050 FEAT_B: accumulated_positive_Scrub-A-Dub - Correlation: 0.9952342543487924\n",
      "9: FEAT_A: 4230 FEAT_B: 4235 - Correlation: 0.9999995197498746\n",
      "10: FEAT_A: 4230 FEAT_B: Bubble Bath_4230 - Correlation: 0.9999999999999998\n",
      "11: FEAT_A: 4230 FEAT_B: Bubble Bath_4235 - Correlation: 0.9999995197498746\n",
      "12: FEAT_A: 5000 FEAT_B: 5010 - Correlation: 0.9991849213605333\n",
      "13: FEAT_A: 5000 FEAT_B: Watering Hole (Activity)_5010 - Correlation: 0.9991849213605333\n",
      "14: FEAT_A: 5000 FEAT_B: Watering Hole (Activity)_5000 - Correlation: 1.0\n",
      "15: FEAT_A: 3110 FEAT_B: 3010 - Correlation: 0.9999293402893735\n",
      "16: FEAT_A: 3120 FEAT_B: 3020 - Correlation: 0.9998761417908972\n",
      "17: FEAT_A: 3121 FEAT_B: 3021 - Correlation: 0.9999098200487934\n",
      "18: FEAT_A: 4031 FEAT_B: Dino Drink_4031 - Correlation: 1.0\n",
      "19: FEAT_A: 4050 FEAT_B: Crystals Rule_4050 - Correlation: 0.9999999999999999\n",
      "20: FEAT_A: 2020 FEAT_B: 2030 - Correlation: 0.9959933262816534\n",
      "21: FEAT_A: 4220 FEAT_B: Bubble Bath_4220 - Correlation: 1.0\n",
      "22: FEAT_A: Slop Problem FEAT_B: Slop Problem_2000 - Correlation: 1.0\n",
      "23: FEAT_A: Slop Problem FEAT_B: Slop Problem_time - Correlation: 0.9999999999999962\n",
      "24: FEAT_A: Welcome to Lost Lagoon! FEAT_B: Welcome to Lost Lagoon!_2000 - Correlation: 1.0\n",
      "25: FEAT_A: Welcome to Lost Lagoon! FEAT_B: Welcome to Lost Lagoon!_time - Correlation: 1.0\n",
      "26: FEAT_A: Ordering Spheres FEAT_B: Ordering Spheres_2000 - Correlation: 1.0\n",
      "27: FEAT_A: Ordering Spheres FEAT_B: Ordering Spheres_time - Correlation: 1.0\n",
      "28: FEAT_A: Tree Top City - Level 1 FEAT_B: Tree Top City - Level 1_2000 - Correlation: 0.9999999999999999\n",
      "29: FEAT_A: Tree Top City - Level 1 FEAT_B: Tree Top City - Level 1_time - Correlation: 0.9999999999999996\n",
      "30: FEAT_A: Tree Top City - Level 2 FEAT_B: Tree Top City - Level 2_2000 - Correlation: 1.0\n",
      "31: FEAT_A: Tree Top City - Level 2 FEAT_B: Tree Top City - Level 2_time - Correlation: 0.9999999999999994\n",
      "32: FEAT_A: Heavy, Heavier, Heaviest FEAT_B: Heavy, Heavier, Heaviest_2000 - Correlation: 1.0\n",
      "33: FEAT_A: Heavy, Heavier, Heaviest FEAT_B: Heavy, Heavier, Heaviest_time - Correlation: 0.9999999999999998\n",
      "34: FEAT_A: Balancing Act FEAT_B: Balancing Act_2000 - Correlation: 1.0\n",
      "35: FEAT_A: Balancing Act FEAT_B: Balancing Act_time - Correlation: 0.9999999999999996\n",
      "36: FEAT_A: Honey Cake FEAT_B: Honey Cake_2000 - Correlation: 1.0\n",
      "37: FEAT_A: Honey Cake FEAT_B: Honey Cake_time - Correlation: 0.9999999999999987\n",
      "38: FEAT_A: Pirate's Tale FEAT_B: Pirate's Tale_2000 - Correlation: 0.9999999999999999\n",
      "39: FEAT_A: Pirate's Tale FEAT_B: Pirate's Tale_time - Correlation: 0.9999999999999989\n",
      "40: FEAT_A: Magma Peak - Level 2 FEAT_B: Magma Peak - Level 2_2000 - Correlation: 1.0\n",
      "41: FEAT_A: Magma Peak - Level 2 FEAT_B: Magma Peak - Level 2_time - Correlation: 0.9999999999999989\n",
      "42: FEAT_A: Lifting Heavy Things FEAT_B: Lifting Heavy Things_2000 - Correlation: 0.9999999999999999\n",
      "43: FEAT_A: Lifting Heavy Things FEAT_B: Lifting Heavy Things_time - Correlation: 1.0\n",
      "44: FEAT_A: Rulers FEAT_B: Rulers_2000 - Correlation: 1.0\n",
      "45: FEAT_A: Rulers FEAT_B: Rulers_time - Correlation: 1.0\n",
      "46: FEAT_A: 12 Monkeys FEAT_B: 12 Monkeys_2000 - Correlation: 1.0\n",
      "47: FEAT_A: 12 Monkeys FEAT_B: 12 Monkeys_time - Correlation: 0.9999999999999998\n",
      "48: FEAT_A: Costume Box FEAT_B: Costume Box_2000 - Correlation: 1.0\n",
      "49: FEAT_A: Costume Box FEAT_B: Costume Box_time - Correlation: 1.0\n",
      "50: FEAT_A: Magma Peak - Level 1 FEAT_B: Magma Peak - Level 1_2000 - Correlation: 1.0\n",
      "51: FEAT_A: Magma Peak - Level 1 FEAT_B: Magma Peak - Level 1_time - Correlation: 1.0\n",
      "52: FEAT_A: Bottle Filler (Activity) FEAT_B: Bottle Filler (Activity)_4030 - Correlation: 0.9950043311420306\n",
      "53: FEAT_A: Crystal Caves - Level 3 FEAT_B: Crystal Caves - Level 3_2000 - Correlation: 1.0\n",
      "54: FEAT_A: Crystal Caves - Level 3 FEAT_B: Crystal Caves - Level 3_time - Correlation: 1.0\n",
      "55: FEAT_A: Treasure Map FEAT_B: Treasure Map_2000 - Correlation: 1.0\n",
      "56: FEAT_A: Treasure Map FEAT_B: Treasure Map_time - Correlation: 0.9999999999999994\n",
      "57: FEAT_A: Crystal Caves - Level 1 FEAT_B: Crystal Caves - Level 1_2000 - Correlation: 1.0\n",
      "58: FEAT_A: Crystal Caves - Level 1 FEAT_B: Crystal Caves - Level 1_time - Correlation: 0.9999999999999999\n",
      "59: FEAT_A: Tree Top City - Level 3 FEAT_B: Tree Top City - Level 3_2000 - Correlation: 1.0\n",
      "60: FEAT_A: Tree Top City - Level 3 FEAT_B: Tree Top City - Level 3_time - Correlation: 1.0\n",
      "61: FEAT_A: Crystal Caves - Level 2 FEAT_B: Crystal Caves - Level 2_2000 - Correlation: 1.0\n",
      "62: FEAT_A: Crystal Caves - Level 2 FEAT_B: Crystal Caves - Level 2_time - Correlation: 1.0\n",
      "63: FEAT_A: Dino Dive_3020 FEAT_B: Dino Dive_3120 - Correlation: 0.9995923561196808\n",
      "64: FEAT_A: Dino Dive_3020 FEAT_B: accumulated_negative_Dino Dive - Correlation: 0.9998998552734173\n",
      "65: FEAT_A: Bottle Filler (Activity)_2030 FEAT_B: Bottle Filler (Activity)_2020 - Correlation: 0.998817689964623\n",
      "66: FEAT_A: Mushroom Sorter (Assessment)_2030 FEAT_B: Mushroom Sorter (Assessment)_2010 - Correlation: 0.9962760616821671\n",
      "67: FEAT_A: Mushroom Sorter (Assessment)_2030 FEAT_B: accumulated_correct_Mushroom Sorter (Assessment) - Correlation: 0.9985426312249888\n",
      "68: FEAT_A: Bottle Filler (Activity)_3110 FEAT_B: Bottle Filler (Activity)_3010 - Correlation: 0.999935162643595\n",
      "69: FEAT_A: Chow Time_3020 FEAT_B: Chow Time_3120 - Correlation: 0.9998673365188063\n",
      "70: FEAT_A: Dino Drink_2030 FEAT_B: Dino Drink_3021 - Correlation: 0.9984674845132689\n",
      "71: FEAT_A: Dino Drink_2030 FEAT_B: Dino Drink_3121 - Correlation: 0.9986046680098601\n",
      "72: FEAT_A: Dino Drink_2030 FEAT_B: accumulated_positive_Dino Drink - Correlation: 0.9985739305482345\n",
      "73: FEAT_A: Air Show_2030 FEAT_B: Air Show_3121 - Correlation: 0.9977888184537717\n",
      "74: FEAT_A: Air Show_2030 FEAT_B: Air Show_3021 - Correlation: 0.9976837802056778\n",
      "75: FEAT_A: Leaf Leader_2030 FEAT_B: Leaf Leader_3121 - Correlation: 0.9990885395773584\n",
      "76: FEAT_A: Leaf Leader_2030 FEAT_B: Leaf Leader_3021 - Correlation: 0.9999689260314981\n",
      "77: FEAT_A: Chow Time_3021 FEAT_B: Chow Time_2030 - Correlation: 0.9993683693704368\n",
      "78: FEAT_A: Chow Time_3021 FEAT_B: Chow Time_3121 - Correlation: 0.9996901555713447\n",
      "79: FEAT_A: Watering Hole (Activity)_3110 FEAT_B: Watering Hole (Activity)_3010 - Correlation: 0.9993109138888533\n",
      "80: FEAT_A: Bug Measurer (Activity)_3010 FEAT_B: Bug Measurer (Activity)_3110 - Correlation: 0.9999850342981554\n",
      "81: FEAT_A: Pan Balance_2030 FEAT_B: Pan Balance_3021 - Correlation: 0.9999803429610506\n",
      "82: FEAT_A: Pan Balance_2030 FEAT_B: Pan Balance_3121 - Correlation: 0.9996196393003264\n",
      "83: FEAT_A: Pan Balance_2030 FEAT_B: Pan Balance_2020 - Correlation: 0.9973125883100831\n",
      "84: FEAT_A: Pan Balance_2030 FEAT_B: accumulated_positive_Pan Balance - Correlation: 0.9988099130792666\n",
      "85: FEAT_A: Egg Dropper (Activity)_3010 FEAT_B: Egg Dropper (Activity)_3110 - Correlation: 0.9998336590281087\n",
      "86: FEAT_A: Cart Balancer (Assessment)_2000 FEAT_B: Cart Balancer (Assessment)_2020 - Correlation: 0.999978626569043\n",
      "87: FEAT_A: Air Show_3120 FEAT_B: Air Show_3020 - Correlation: 0.999628997408126\n",
      "88: FEAT_A: Chest Sorter (Assessment)_2020 FEAT_B: Chest Sorter (Assessment)_2000 - Correlation: 0.9999999999999999\n",
      "89: FEAT_A: Mushroom Sorter (Assessment)_2000 FEAT_B: Mushroom Sorter (Assessment)_2025 - Correlation: 0.9999982205265872\n",
      "90: FEAT_A: Chest Sorter (Assessment)_3020 FEAT_B: Chest Sorter (Assessment)_3120 - Correlation: 0.9972489515829078\n",
      "91: FEAT_A: Chest Sorter (Assessment)_3020 FEAT_B: accumulated_uncorrect_Chest Sorter (Assessment) - Correlation: 0.9999880332296728\n",
      "92: FEAT_A: Sandcastle Builder (Activity)_4020 FEAT_B: accumulated_positive_Sandcastle Builder (Activity) - Correlation: 0.9984492933082746\n",
      "93: FEAT_A: Air Show_3110 FEAT_B: Air Show_3010 - Correlation: 0.999953679734225\n",
      "94: FEAT_A: Cauldron Filler (Assessment)_3121 FEAT_B: Cauldron Filler (Assessment)_3021 - Correlation: 0.999576326704631\n",
      "95: FEAT_A: Cauldron Filler (Assessment)_3121 FEAT_B: Cauldron Filler (Assessment)_2030 - Correlation: 0.9990905166101879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96: FEAT_A: Bubble Bath_2030 FEAT_B: Bubble Bath_2035 - Correlation: 0.9991496470458585\n",
      "97: FEAT_A: Bubble Bath_2030 FEAT_B: Bubble Bath_4020 - Correlation: 0.9962789226264855\n",
      "98: FEAT_A: Bubble Bath_2030 FEAT_B: Bubble Bath_2025 - Correlation: 0.9964317167511039\n",
      "99: FEAT_A: Cauldron Filler (Assessment)_3020 FEAT_B: Cauldron Filler (Assessment)_3120 - Correlation: 0.9998190477466209\n",
      "100: FEAT_A: Chest Sorter (Assessment)_3021 FEAT_B: Chest Sorter (Assessment)_3121 - Correlation: 0.9985179906980775\n",
      "101: FEAT_A: Chest Sorter (Assessment)_3021 FEAT_B: accumulated_correct_Chest Sorter (Assessment) - Correlation: 0.9996140232445475\n",
      "102: FEAT_A: Watering Hole (Activity)_4025 FEAT_B: Watering Hole (Activity)_4020 - Correlation: 0.9991434495208743\n",
      "103: FEAT_A: Crystals Rule_3120 FEAT_B: Crystals Rule_3020 - Correlation: 0.999835058794711\n",
      "104: FEAT_A: Chest Sorter (Assessment)_3110 FEAT_B: Chest Sorter (Assessment)_3010 - Correlation: 0.9977337946782758\n",
      "105: FEAT_A: Crystals Rule_3021 FEAT_B: Crystals Rule_3121 - Correlation: 0.9998920962508026\n",
      "106: FEAT_A: Crystals Rule_3021 FEAT_B: Crystals Rule_2030 - Correlation: 0.9998606654761331\n",
      "107: FEAT_A: Crystals Rule_3021 FEAT_B: Crystals Rule_2020 - Correlation: 0.99823323877902\n",
      "108: FEAT_A: Crystals Rule_3021 FEAT_B: accumulated_positive_Crystals Rule - Correlation: 0.9999730785082726\n",
      "109: FEAT_A: All Star Sorting_3021 FEAT_B: All Star Sorting_2030 - Correlation: 0.9995251307611352\n",
      "110: FEAT_A: All Star Sorting_3021 FEAT_B: All Star Sorting_3121 - Correlation: 0.9991356096406656\n",
      "111: FEAT_A: All Star Sorting_3021 FEAT_B: accumulated_positive_All Star Sorting - Correlation: 0.999785180252152\n",
      "112: FEAT_A: Cart Balancer (Assessment)_2010 FEAT_B: Cart Balancer (Assessment)_3121 - Correlation: 0.999849464604504\n",
      "113: FEAT_A: Cart Balancer (Assessment)_2010 FEAT_B: Cart Balancer (Assessment)_2030 - Correlation: 0.999849464604504\n",
      "114: FEAT_A: Bubble Bath_3010 FEAT_B: Bubble Bath_3110 - Correlation: 0.9997266832893074\n",
      "115: FEAT_A: Bubble Bath_3120 FEAT_B: Bubble Bath_3020 - Correlation: 0.998105247261057\n",
      "116: FEAT_A: Bubble Bath_3120 FEAT_B: accumulated_negative_Bubble Bath - Correlation: 0.9968448073981443\n",
      "117: FEAT_A: Scrub-A-Dub_3010 FEAT_B: Scrub-A-Dub_3110 - Correlation: 0.9999426890770878\n",
      "118: FEAT_A: Leaf Leader_3110 FEAT_B: Leaf Leader_3010 - Correlation: 0.9994585292841954\n",
      "119: FEAT_A: Scrub-A-Dub_3020 FEAT_B: Scrub-A-Dub_3120 - Correlation: 0.9999763070332106\n",
      "120: FEAT_A: Bird Measurer (Assessment)_3010 FEAT_B: Bird Measurer (Assessment)_3110 - Correlation: 0.9993801763820348\n",
      "121: FEAT_A: Cauldron Filler (Assessment)_4030 FEAT_B: Cauldron Filler (Assessment)_4020 - Correlation: 0.9967763987631819\n",
      "122: FEAT_A: Bird Measurer (Assessment)_3121 FEAT_B: Bird Measurer (Assessment)_3021 - Correlation: 0.9981555049446889\n",
      "123: FEAT_A: Bird Measurer (Assessment)_3121 FEAT_B: accumulated_correct_Bird Measurer (Assessment) - Correlation: 0.9981555049446889\n",
      "124: FEAT_A: Bubble Bath_3121 FEAT_B: Bubble Bath_3021 - Correlation: 0.9997831892615398\n",
      "125: FEAT_A: Mushroom Sorter (Assessment)_3010 FEAT_B: Mushroom Sorter (Assessment)_3110 - Correlation: 0.9991003891313368\n",
      "126: FEAT_A: Flower Waterer (Activity)_2000 FEAT_B: accumulated_negative_Flower Waterer (Activity) - Correlation: 0.9956652868094414\n",
      "127: FEAT_A: All Star Sorting_4010 FEAT_B: All Star Sorting_2000 - Correlation: 0.9980151285383981\n",
      "128: FEAT_A: Cart Balancer (Assessment)_3021 FEAT_B: accumulated_correct_Cart Balancer (Assessment) - Correlation: 0.9999170128095375\n",
      "129: FEAT_A: Cauldron Filler (Assessment)_3010 FEAT_B: Cauldron Filler (Assessment)_3110 - Correlation: 0.9998567985670082\n",
      "130: FEAT_A: All Star Sorting_3020 FEAT_B: All Star Sorting_3120 - Correlation: 0.9979692879543319\n",
      "131: FEAT_A: All Star Sorting_3020 FEAT_B: All Star Sorting_2025 - Correlation: 0.9999983835744551\n",
      "132: FEAT_A: All Star Sorting_3020 FEAT_B: accumulated_negative_All Star Sorting - Correlation: 0.9995085966685365\n",
      "133: FEAT_A: Dino Drink_3010 FEAT_B: Dino Drink_3110 - Correlation: 0.9986531654717626\n",
      "134: FEAT_A: Egg Dropper (Activity)_2000 FEAT_B: Egg Dropper (Activity)_2020 - Correlation: 0.9999999999999999\n",
      "135: FEAT_A: Leaf Leader_3120 FEAT_B: Leaf Leader_3020 - Correlation: 0.9972721980394412\n",
      "136: FEAT_A: Leaf Leader_3120 FEAT_B: accumulated_negative_Leaf Leader - Correlation: 0.9992945066599757\n",
      "137: FEAT_A: Happy Camel_3120 FEAT_B: Happy Camel_3020 - Correlation: 0.9998900847287077\n",
      "138: FEAT_A: Dino Dive_3110 FEAT_B: Dino Dive_3010 - Correlation: 0.9998637945770242\n",
      "139: FEAT_A: Mushroom Sorter (Assessment)_3120 FEAT_B: Mushroom Sorter (Assessment)_3020 - Correlation: 0.998929717261588\n",
      "140: FEAT_A: Mushroom Sorter (Assessment)_3120 FEAT_B: accumulated_uncorrect_Mushroom Sorter (Assessment) - Correlation: 0.9989293679278667\n",
      "141: FEAT_A: Fireworks (Activity)_3110 FEAT_B: Fireworks (Activity)_3010 - Correlation: 0.9999125179829755\n",
      "142: FEAT_A: Mushroom Sorter (Assessment)_2035 FEAT_B: Mushroom Sorter (Assessment)_3121 - Correlation: 0.9963987221516345\n",
      "143: FEAT_A: Mushroom Sorter (Assessment)_2035 FEAT_B: Mushroom Sorter (Assessment)_3021 - Correlation: 0.9963745894369906\n",
      "144: FEAT_A: Mushroom Sorter (Assessment)_2035 FEAT_B: Mushroom Sorter (Assessment)_2020 - Correlation: 0.9999970893851744\n",
      "145: FEAT_A: Mushroom Sorter (Assessment)_2035 FEAT_B: Mushroom Sorter (Assessment)_4025 - Correlation: 0.9996646794414074\n",
      "146: FEAT_A: Dino Dive_3121 FEAT_B: Dino Dive_3021 - Correlation: 0.9995444786291265\n",
      "147: FEAT_A: Dino Dive_3121 FEAT_B: Dino Dive_2020 - Correlation: 0.9950004881933643\n",
      "148: FEAT_A: Happy Camel_2030 FEAT_B: Happy Camel_3121 - Correlation: 0.9979559120623818\n",
      "149: FEAT_A: Happy Camel_2030 FEAT_B: Happy Camel_3021 - Correlation: 0.9998350234117662\n",
      "150: FEAT_A: Bubble Bath_4045 FEAT_B: Bubble Bath_2020 - Correlation: 0.9980774800878145\n",
      "151: FEAT_A: Dino Dive_2030 FEAT_B: accumulated_positive_Dino Dive - Correlation: 0.9957765241071828\n",
      "152: FEAT_A: Dino Drink_3120 FEAT_B: Dino Drink_3020 - Correlation: 0.9998406115110345\n",
      "153: FEAT_A: Cart Balancer (Assessment)_3120 FEAT_B: Cart Balancer (Assessment)_3020 - Correlation: 0.9973945339840646\n",
      "154: FEAT_A: Crystals Rule_4020 FEAT_B: Crystals Rule_3010 - Correlation: 0.9988936322895169\n",
      "155: FEAT_A: Crystals Rule_4020 FEAT_B: Crystals Rule_3110 - Correlation: 0.9988970478897697\n",
      "156: FEAT_A: Flower Waterer (Activity)_3110 FEAT_B: Flower Waterer (Activity)_3010 - Correlation: 0.9996926215355526\n",
      "157: FEAT_A: Sandcastle Builder (Activity)_3110 FEAT_B: Sandcastle Builder (Activity)_3010 - Correlation: 0.9999521729413294\n",
      "158: FEAT_A: Bird Measurer (Assessment)_3020 FEAT_B: Bird Measurer (Assessment)_3120 - Correlation: 0.9992191329664104\n",
      "159: FEAT_A: Bird Measurer (Assessment)_3020 FEAT_B: Bird Measurer (Assessment)_4110 - Correlation: 0.9988424704659317\n",
      "160: FEAT_A: Bird Measurer (Assessment)_3020 FEAT_B: accumulated_uncorrect_Bird Measurer (Assessment) - Correlation: 0.9991605930121137\n",
      "161: FEAT_A: All Star Sorting_3110 FEAT_B: All Star Sorting_3010 - Correlation: 0.9992130941883633\n",
      "162: FEAT_A: Happy Camel_3010 FEAT_B: Happy Camel_3110 - Correlation: 0.9996590210382708\n",
      "163: FEAT_A: Chicken Balancer (Activity)_3010 FEAT_B: Chicken Balancer (Activity)_3110 - Correlation: 0.9993007600205108\n",
      "164: FEAT_A: Pan Balance_3010 FEAT_B: Pan Balance_3110 - Correlation: 0.9994848234397947\n",
      "165: FEAT_A: Chest Sorter (Assessment)_2030 FEAT_B: Chest Sorter (Assessment)_2010 - Correlation: 0.9999999999999998\n",
      "166: FEAT_A: Pan Balance_3020 FEAT_B: Pan Balance_3120 - Correlation: 0.9999667370361688\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "to_remove = []\n",
    "for feat_a in features:\n",
    "    for feat_b in features:\n",
    "        if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n",
    "#             c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]   \n",
    "            c = np.abs(np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1])  \n",
    "            if c > 0.995:  # 相关性\n",
    "                counter += 1\n",
    "                to_remove.append(feat_b)\n",
    "                print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_Cart Balancer (Assessment) -0.04020325710970143 -0.47065833333333335 0.006732930476733109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottle Filler (Activity)_2010 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandcastle Builder (Activity)_2010 0.0 0.0\n",
      "Bubble Bath_4080 0.004070096099491238 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chest Sorter (Assessment)_4080 0.012832108535895986 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy Camel_4080 0.0008479366873940079 0.0\n",
      "Cart Balancer (Assessment)_4080 0.007292255511588468 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrub-A-Dub_4080 0.0 0.0\n",
      "Dino Drink_4080 0.0009044657998869418 0.0\n",
      "Leaf Leader_4080 0.0004522328999434709 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan Balance_2010 0.0 0.0\n",
      "Mushroom Sorter (Assessment)_4080 0.04392312040700961 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egg Dropper (Activity)_4080 0.01978518937252685 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan Balance_4080 0.0013001695873374789 0.0\n",
      "Crystals Rule_2010 0.0 0.0\n",
      "Fireworks (Activity)_4080 0.0013566986998304127 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug Measurer (Activity)_4080 0.008988128886376484 0.0\n",
      "Bubble Bath_4090 0.14703222159412097 0.008 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Show_4080 0.0 0.0\n",
      "Watering Hole (Activity)_2010 0.0007348784624081402 0.0\n",
      "Mushroom Sorter (Assessment)_4090 0.17382702091577162 0.008 0.0\n",
      "Dino Dive_4080 0.0002826455624646693 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accumulated_positive_Bug Measurer (Activity) 0.0 0.0\n",
      "accumulated_positive_Watering Hole (Activity) 0.0 0.0\n",
      "accumulated_positive_Egg Dropper (Activity) 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accumulated_positive_ratio_All Star Sorting 0.0 0.0\n",
      "accumulated_positive_ratio_Fireworks (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Flower Waterer (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Air Show 0.0 0.0\n",
      "accumulated_positive_ratio_Crystals Rule 0.0 0.0\n",
      "accumulated_positive_ratio_Bug Measurer (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Sandcastle Builder (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Scrub-A-Dub 0.0 0.0\n",
      "accumulated_positive_ratio_Watering Hole (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Dino Drink 0.0 0.0\n",
      "accumulated_positive_ratio_Bubble Bath 0.0 0.0\n",
      "accumulated_positive_ratio_Bottle Filler (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Dino Dive 0.0 0.0\n",
      "accumulated_positive_ratio_Chow Time 0.0 0.0\n",
      "accumulated_positive_ratio_Chicken Balancer (Activity) 0.0 0.0\n",
      "accumulated_positive_ratio_Happy Camel 0.0 0.0\n",
      "accumulated_positive_ratio_Leaf Leader 0.0 0.0\n",
      "accumulated_positive_ratio_Pan Balance 0.0 0.0\n",
      "accumulated_positive_ratio_Egg Dropper (Activity) 0.0 0.0\n",
      "accumulated_positive__ratio_Chow Time 0.6391272192680654 0.6420521040926622\n",
      "accumulated_positive__ratio_All Star Sorting 0.6614931322331272 0.6673315924060677\n",
      "accumulated_positive__ratio_Fireworks (Activity) 0.8033610849793156 0.7821704796191697\n",
      "accumulated_positive__ratio_Egg Dropper (Activity) 0.0 0.0\n",
      "accumulated_positive__ratio_Bug Measurer (Activity) 0.0 0.0\n",
      "accumulated_positive__ratio_Sandcastle Builder (Activity) 0.6865650565643375 0.666932633053414\n",
      "accumulated_positive__ratio_Dino Dive 0.6738004787030683 0.678831087942721\n",
      "accumulated_negative_ratio_All Star Sorting 0.0 0.0\n",
      "accumulated_negative_ratio_Fireworks (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Flower Waterer (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Air Show 0.0 0.0\n",
      "accumulated_negative_ratio_Crystals Rule 0.0 0.0\n",
      "accumulated_negative_ratio_Bug Measurer (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Sandcastle Builder (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Scrub-A-Dub 0.0 0.0\n",
      "accumulated_negative_ratio_Watering Hole (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Dino Drink 0.0 0.0\n",
      "accumulated_negative_ratio_Bubble Bath 0.0 0.0\n",
      "accumulated_negative_ratio_Bottle Filler (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Dino Dive 0.0 0.0\n",
      "accumulated_negative_ratio_Chow Time 0.0 0.0\n",
      "accumulated_negative_ratio_Chicken Balancer (Activity) 0.0 0.0\n",
      "accumulated_negative_ratio_Happy Camel 0.0 0.0\n",
      "accumulated_negative_ratio_Leaf Leader 0.0 0.0\n",
      "accumulated_negative_ratio_Pan Balance 0.0 0.0\n",
      "accumulated_negative_ratio_Egg Dropper (Activity) 0.0 0.0\n",
      "accumulated_negative__ratio_Chow Time 0.3177701332632862 0.3068367847962266\n",
      "accumulated_negative__ratio_All Star Sorting 0.2630792676393895 0.23347269713816823\n",
      "accumulated_negative__ratio_Fireworks (Activity) 0.16201982148162947 0.15985850588807657\n",
      "accumulated_negative__ratio_Egg Dropper (Activity) 0.8383463458338666 0.8353909465020576\n",
      "accumulated_negative__ratio_Bug Measurer (Activity) 1.0 1.0\n",
      "accumulated_negative__ratio_Sandcastle Builder (Activity) 0.29780448587366465 0.3027643366435557\n",
      "accumulated_negative__ratio_Dino Dive 0.30838997441057353 0.3076553985437655\n",
      "accumulated_won_game_count_All Star Sorting 0.0 0.0\n",
      "accumulated_won_game_count_Air Show 0.0 0.0\n",
      "accumulated_won_game_count_Crystals Rule 0.0 0.0\n",
      "accumulated_won_game_count_Scrub-A-Dub 0.0 0.0\n",
      "accumulated_won_game_count_Dino Drink 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accumulated_won_game_count_Dino Dive 0.0 0.0\n",
      "accumulated_won_game_count_Chow Time 0.0 0.0\n",
      "accumulated_won_game_count_Leaf Leader 0.0 0.0\n",
      "accumulated_won_game_count_Pan Balance 0.0 0.0\n",
      "Chest Sorter (Assessment)_time 452.7551158846806 36.574 0.007628145048781528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicken Balancer (Activity)_time_mean 0.0 0.0\n",
      "Sandcastle Builder (Activity)_time_mean 0.0 0.0\n",
      "Dino Dive_time_mean 0.0 0.0\n",
      "Cauldron Filler (Assessment)_time_mean 0.0 0.0\n",
      "Bird Measurer (Assessment)_time_mean 0.0 0.0\n",
      "Scrub-A-Dub_time_mean 0.0 0.0\n",
      "Slop Problem_time_mean 0.0 0.0\n",
      "Crystals Rule_time_mean 0.0 0.0\n",
      "Welcome to Lost Lagoon!_time_mean 0.0 0.0\n",
      "Cart Balancer (Assessment)_time_mean 0.0 0.0\n",
      "Air Show_time_mean 0.0 0.0\n",
      "Ordering Spheres_time_mean 0.0 0.0\n",
      "Tree Top City - Level 1_time_mean 0.0 0.0\n",
      "Tree Top City - Level 2_time_mean 0.0 0.0\n",
      "Chest Sorter (Assessment)_time_mean 0.0 0.0\n",
      "Heavy, Heavier, Heaviest_time_mean 0.0 0.0\n",
      "Balancing Act_time_mean 0.0 0.0\n",
      "Honey Cake_time_mean 0.0 0.0\n",
      "Pirate's Tale_time_mean 0.0 0.0\n",
      "Magma Peak - Level 2_time_mean 0.0 0.0\n",
      "Happy Camel_time_mean 0.0 0.0\n",
      "Mushroom Sorter (Assessment)_time_mean 0.0 0.0\n",
      "Dino Drink_time_mean 0.0 0.0\n",
      "Lifting Heavy Things_time_mean 0.0 0.0\n",
      "Rulers_time_mean 0.0 0.0\n",
      "Chow Time_time_mean 0.0 0.0\n",
      "12 Monkeys_time_mean 0.0 0.0\n",
      "Costume Box_time_mean 0.0 0.0\n",
      "Leaf Leader_time_mean 0.0 0.0\n",
      "Bug Measurer (Activity)_time_mean 0.0 0.0\n",
      "All Star Sorting_time_mean 0.0 0.0\n",
      "Magma Peak - Level 1_time_mean 0.0 0.0\n",
      "Bottle Filler (Activity)_time_mean 0.0 0.0\n",
      "Crystal Caves - Level 3_time_mean 0.0 0.0\n",
      "Bubble Bath_time_mean 0.0 0.0\n",
      "Watering Hole (Activity)_time_mean 0.0 0.0\n",
      "Egg Dropper (Activity)_time_mean 0.0 0.0\n",
      "Pan Balance_time_mean 0.0 0.0\n",
      "Treasure Map_time_mean 0.0 0.0\n",
      "Crystal Caves - Level 1_time_mean 0.0 0.0\n",
      "Tree Top City - Level 3_time_mean 0.0 0.0\n",
      "Flower Waterer (Activity)_time_mean 0.0 0.0\n",
      "Fireworks (Activity)_time_mean 0.0 0.0\n",
      "Crystal Caves - Level 2_time_mean 0.0 0.0\n",
      "accumulated_correct_duration 0.013648313971991021 0.011118958574255097\n",
      "accumulated_uncorrect_duration 0.02033511794886075 0.012346878742113307\n",
      "accumulated_positive__ratio_Scrub-A-Dub 0.6419502098683012 0.6565333544126236\n",
      "accumulated_positive__ratio_Watering Hole (Activity) 0.0 0.0\n",
      "accumulated_positive__ratio_Dino Drink 0.7570395963873091 0.7545109047918206\n",
      "accumulated_positive__ratio_Bubble Bath 0.7303347443352604 0.7209228384354864\n",
      "accumulated_positive__ratio_Bottle Filler (Activity) 0.9110415401407411 0.9090275853541502\n",
      "accumulated_positive__ratio_Chicken Balancer (Activity) 0.7120049237473374 0.7312574608341293\n",
      "accumulated_positive__ratio_Happy Camel 0.4480334978784757 0.44587625723829033\n",
      "accumulated_positive__ratio_Leaf Leader 0.2047021288596243 0.20700257999771904\n",
      "accumulated_positive__ratio_Pan Balance 0.5319360797913424 0.5268594455780458\n",
      "accumulated_positive__ratio_Flower Waterer (Activity) 0.6530522695373719 0.5906405829874609\n",
      "accumulated_positive__ratio_Air Show 0.693812451903412 0.7159885134534759\n",
      "accumulated_positive__ratio_Crystals Rule 0.5250274400813333 0.4993658348829681\n",
      "accumulated_negative__ratio_Scrub-A-Dub 0.34743971055610195 0.3222545243752551\n",
      "accumulated_negative__ratio_Watering Hole (Activity) 0.9002183406113538 0.8704225352112676\n",
      "accumulated_negative__ratio_Dino Drink 0.09900271705410746 0.09805319777228197\n",
      "accumulated_negative__ratio_Bubble Bath 0.17684564095370647 0.1554407979281499\n",
      "accumulated_negative__ratio_Bottle Filler (Activity) 0.08725777958715009 0.09097241464584974\n",
      "accumulated_negative__ratio_Chicken Balancer (Activity) 0.24323156273914914 0.21923758867082102\n",
      "accumulated_negative__ratio_Happy Camel 0.5094506904560289 0.501976503497906\n",
      "accumulated_negative__ratio_Leaf Leader 0.6881550139975185 0.6712582895674984\n",
      "accumulated_negative__ratio_Pan Balance 0.4408658590803421 0.4425728688324346\n",
      "accumulated_negative__ratio_Flower Waterer (Activity) 0.33250240826423044 0.3833478563188975\n",
      "accumulated_negative__ratio_Air Show 0.28015364979150303 0.2662337087687464\n",
      "accumulated_negative__ratio_Crystals Rule 0.3585902600157675 0.3316843934275342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "to_exclude = [] \n",
    "ajusted_test = reduce_test.copy()\n",
    "for feature in ajusted_test.columns:\n",
    "    if feature not in ['accuracy_group', 'installation_id', 'session_title']:\n",
    "        data = reduce_train[feature]\n",
    "        train_mean = data.mean()\n",
    "        data = ajusted_test[feature] \n",
    "        test_mean = data.mean()\n",
    "        try:\n",
    "            error = stract_hists(feature, adjust=True)\n",
    "            ajust_factor = train_mean / test_mean\n",
    "            if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature, train_mean, test_mean, error)\n",
    "            else:\n",
    "                ajusted_test[feature] *= ajust_factor\n",
    "        except:\n",
    "            to_exclude.append(feature)\n",
    "            print(feature, train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 430), (1000, 755), 430, ['session_title'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [x for x in features if x not in (to_exclude + to_remove)]\n",
    "reduce_train[features].shape, ajusted_test.shape, len(features), categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17690, 755), (1000, 755), 430)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_train.shape, reduce_test.shape, len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | baggin... | colsam... | lambda_l1 | lambda_l2 | learni... | max_depth |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.900969\tvalid_1's rmse: 0.997777\n",
      "[200]\ttraining's rmse: 0.840186\tvalid_1's rmse: 1.00097\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's rmse: 0.898694\tvalid_1's rmse: 0.997373\n",
      "Partial score of fold 0 is: 0.5759253775615302\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.903959\tvalid_1's rmse: 0.99206\n",
      "[200]\ttraining's rmse: 0.841881\tvalid_1's rmse: 0.9903\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's rmse: 0.87652\tvalid_1's rmse: 0.98893\n",
      "Partial score of fold 1 is: 0.5913137393884114\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.905368\tvalid_1's rmse: 0.989193\n",
      "[200]\ttraining's rmse: 0.843435\tvalid_1's rmse: 0.987478\n",
      "[300]\ttraining's rmse: 0.797337\tvalid_1's rmse: 0.988354\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's rmse: 0.85942\tvalid_1's rmse: 0.986107\n",
      "Partial score of fold 2 is: 0.602586609098801\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.905783\tvalid_1's rmse: 0.981391\n",
      "[200]\ttraining's rmse: 0.842431\tvalid_1's rmse: 0.974743\n",
      "[300]\ttraining's rmse: 0.795398\tvalid_1's rmse: 0.978723\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's rmse: 0.845937\tvalid_1's rmse: 0.974461\n",
      "Partial score of fold 3 is: 0.5984711169823096\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.903765\tvalid_1's rmse: 0.986657\n",
      "[200]\ttraining's rmse: 0.839991\tvalid_1's rmse: 0.987484\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's rmse: 0.879353\tvalid_1's rmse: 0.985005\n",
      "Partial score of fold 4 is: 0.5941655436648354\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5927  \u001b[0m | \u001b[0m 0.4363  \u001b[0m | \u001b[0m 5.612   \u001b[0m | \u001b[0m 0.5208  \u001b[0m | \u001b[0m 3.84    \u001b[0m | \u001b[0m 2.768   \u001b[0m | \u001b[0m 0.05549 \u001b[0m | \u001b[0m 8.45    \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.95017\tvalid_1's rmse: 1.00965\n",
      "[200]\ttraining's rmse: 0.889748\tvalid_1's rmse: 0.994989\n",
      "[300]\ttraining's rmse: 0.850484\tvalid_1's rmse: 0.993919\n",
      "[400]\ttraining's rmse: 0.817997\tvalid_1's rmse: 0.99456\n",
      "Early stopping, best iteration is:\n",
      "[286]\ttraining's rmse: 0.855489\tvalid_1's rmse: 0.993741\n",
      "Partial score of fold 0 is: 0.5786093941592421\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.950534\tvalid_1's rmse: 1.00565\n",
      "[200]\ttraining's rmse: 0.890628\tvalid_1's rmse: 0.988283\n",
      "[300]\ttraining's rmse: 0.850834\tvalid_1's rmse: 0.985603\n",
      "[400]\ttraining's rmse: 0.818366\tvalid_1's rmse: 0.984666\n",
      "[500]\ttraining's rmse: 0.790179\tvalid_1's rmse: 0.985419\n",
      "Early stopping, best iteration is:\n",
      "[364]\ttraining's rmse: 0.829492\tvalid_1's rmse: 0.984308\n",
      "Partial score of fold 1 is: 0.5938188215462756\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.952157\tvalid_1's rmse: 1.00027\n",
      "[200]\ttraining's rmse: 0.892971\tvalid_1's rmse: 0.982446\n",
      "[300]\ttraining's rmse: 0.853318\tvalid_1's rmse: 0.978581\n",
      "[400]\ttraining's rmse: 0.820971\tvalid_1's rmse: 0.977388\n",
      "[500]\ttraining's rmse: 0.793613\tvalid_1's rmse: 0.97766\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's rmse: 0.820087\tvalid_1's rmse: 0.977203\n",
      "Partial score of fold 2 is: 0.6101018555723942\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.953965\tvalid_1's rmse: 0.99672\n",
      "[200]\ttraining's rmse: 0.893869\tvalid_1's rmse: 0.975334\n",
      "[300]\ttraining's rmse: 0.854475\tvalid_1's rmse: 0.970175\n",
      "[400]\ttraining's rmse: 0.823081\tvalid_1's rmse: 0.968975\n",
      "[500]\ttraining's rmse: 0.795373\tvalid_1's rmse: 0.968227\n",
      "[600]\ttraining's rmse: 0.770658\tvalid_1's rmse: 0.968413\n",
      "Early stopping, best iteration is:\n",
      "[481]\ttraining's rmse: 0.800342\tvalid_1's rmse: 0.968108\n",
      "Partial score of fold 3 is: 0.6058074290160552\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.950313\tvalid_1's rmse: 1.00233\n",
      "[200]\ttraining's rmse: 0.890702\tvalid_1's rmse: 0.985061\n",
      "[300]\ttraining's rmse: 0.851706\tvalid_1's rmse: 0.981128\n",
      "[400]\ttraining's rmse: 0.819041\tvalid_1's rmse: 0.980272\n",
      "[500]\ttraining's rmse: 0.791902\tvalid_1's rmse: 0.980552\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's rmse: 0.828056\tvalid_1's rmse: 0.97965\n",
      "Partial score of fold 4 is: 0.5936286072286698\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5965  \u001b[0m | \u001b[95m 0.9397  \u001b[0m | \u001b[95m 1.656   \u001b[0m | \u001b[95m 0.4619  \u001b[0m | \u001b[95m 5.615   \u001b[0m | \u001b[95m 0.5673  \u001b[0m | \u001b[95m 0.02914 \u001b[0m | \u001b[95m 10.17   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.881987\tvalid_1's rmse: 1.00052\n",
      "[200]\ttraining's rmse: 0.806788\tvalid_1's rmse: 1.00244\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's rmse: 0.869417\tvalid_1's rmse: 0.999557\n",
      "Partial score of fold 0 is: 0.5734202954036658\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.884004\tvalid_1's rmse: 0.991393\n",
      "[200]\ttraining's rmse: 0.808543\tvalid_1's rmse: 0.988722\n",
      "[300]\ttraining's rmse: 0.751305\tvalid_1's rmse: 0.989178\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's rmse: 0.81258\tvalid_1's rmse: 0.988216\n",
      "Partial score of fold 1 is: 0.5922084115876486\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.885802\tvalid_1's rmse: 0.9835\n",
      "[200]\ttraining's rmse: 0.810421\tvalid_1's rmse: 0.980196\n",
      "[300]\ttraining's rmse: 0.753554\tvalid_1's rmse: 0.982561\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's rmse: 0.811765\tvalid_1's rmse: 0.980078\n",
      "Partial score of fold 2 is: 0.6020498057792587\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.887146\tvalid_1's rmse: 0.975246\n",
      "[200]\ttraining's rmse: 0.812123\tvalid_1's rmse: 0.971365\n",
      "[300]\ttraining's rmse: 0.753868\tvalid_1's rmse: 0.974607\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's rmse: 0.80828\tvalid_1's rmse: 0.970885\n",
      "Partial score of fold 3 is: 0.6027655435386485\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.884007\tvalid_1's rmse: 0.98447\n",
      "[200]\ttraining's rmse: 0.809519\tvalid_1's rmse: 0.983622\n",
      "Early stopping, best iteration is:\n",
      "[146]\ttraining's rmse: 0.846607\tvalid_1's rmse: 0.981737\n",
      "Partial score of fold 4 is: 0.5945235012889458\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5932  \u001b[0m | \u001b[0m 0.7025  \u001b[0m | \u001b[0m 1.132   \u001b[0m | \u001b[0m 0.5615  \u001b[0m | \u001b[0m 0.384   \u001b[0m | \u001b[0m 0.06828 \u001b[0m | \u001b[0m 0.05332 \u001b[0m | \u001b[0m 11.81   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.874344\tvalid_1's rmse: 0.999361\n",
      "[200]\ttraining's rmse: 0.802763\tvalid_1's rmse: 1.00465\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's rmse: 0.873524\tvalid_1's rmse: 0.999138\n",
      "Partial score of fold 0 is: 0.5798619352381742\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.877993\tvalid_1's rmse: 0.987917\n",
      "[200]\ttraining's rmse: 0.805383\tvalid_1's rmse: 0.987426\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's rmse: 0.848733\tvalid_1's rmse: 0.985507\n",
      "Partial score of fold 1 is: 0.5981132481026146\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.879567\tvalid_1's rmse: 0.985879\n",
      "[200]\ttraining's rmse: 0.807681\tvalid_1's rmse: 0.987396\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's rmse: 0.847069\tvalid_1's rmse: 0.985237\n",
      "Partial score of fold 2 is: 0.6000815269409366\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.880816\tvalid_1's rmse: 0.976947\n",
      "[200]\ttraining's rmse: 0.810363\tvalid_1's rmse: 0.975012\n",
      "[300]\ttraining's rmse: 0.757324\tvalid_1's rmse: 0.978669\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's rmse: 0.830979\tvalid_1's rmse: 0.974156\n",
      "Partial score of fold 3 is: 0.5982921825424621\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.876593\tvalid_1's rmse: 0.987468\n",
      "[200]\ttraining's rmse: 0.806801\tvalid_1's rmse: 0.988691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's rmse: 0.883119\tvalid_1's rmse: 0.986972\n",
      "Partial score of fold 4 is: 0.5898700521755107\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5931  \u001b[0m | \u001b[0m 0.4736  \u001b[0m | \u001b[0m 1.014   \u001b[0m | \u001b[0m 0.5268  \u001b[0m | \u001b[0m 5.964   \u001b[0m | \u001b[0m 5.882   \u001b[0m | \u001b[0m 0.08045 \u001b[0m | \u001b[0m 11.74   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.875892\tvalid_1's rmse: 0.996458\n",
      "[200]\ttraining's rmse: 0.802228\tvalid_1's rmse: 1.00071\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's rmse: 0.863241\tvalid_1's rmse: 0.996032\n",
      "Partial score of fold 0 is: 0.5796830007983267\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.877235\tvalid_1's rmse: 0.991342\n",
      "[200]\ttraining's rmse: 0.802711\tvalid_1's rmse: 0.99196\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's rmse: 0.845409\tvalid_1's rmse: 0.989938\n",
      "Partial score of fold 1 is: 0.5941766904259707\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.878694\tvalid_1's rmse: 0.985624\n",
      "[200]\ttraining's rmse: 0.803735\tvalid_1's rmse: 0.983648\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's rmse: 0.841873\tvalid_1's rmse: 0.982262\n",
      "Partial score of fold 2 is: 0.6047338223769705\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.88071\tvalid_1's rmse: 0.974034\n",
      "[200]\ttraining's rmse: 0.809173\tvalid_1's rmse: 0.972966\n",
      "[300]\ttraining's rmse: 0.752974\tvalid_1's rmse: 0.973337\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's rmse: 0.797096\tvalid_1's rmse: 0.971859\n",
      "Partial score of fold 3 is: 0.6050916912566654\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.876864\tvalid_1's rmse: 0.986064\n",
      "[200]\ttraining's rmse: 0.802986\tvalid_1's rmse: 0.985934\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's rmse: 0.840491\tvalid_1's rmse: 0.985434\n",
      "Partial score of fold 4 is: 0.594702480101001\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5949  \u001b[0m | \u001b[0m 0.841   \u001b[0m | \u001b[0m 9.693   \u001b[0m | \u001b[0m 0.4212  \u001b[0m | \u001b[0m 5.988   \u001b[0m | \u001b[0m 0.1934  \u001b[0m | \u001b[0m 0.07019 \u001b[0m | \u001b[0m 11.78   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.851745\tvalid_1's rmse: 0.992987\n",
      "[200]\ttraining's rmse: 0.769426\tvalid_1's rmse: 0.998397\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's rmse: 0.857438\tvalid_1's rmse: 0.992314\n",
      "Partial score of fold 0 is: 0.582545951835886\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.852564\tvalid_1's rmse: 0.985285\n",
      "[200]\ttraining's rmse: 0.769834\tvalid_1's rmse: 0.986277\n",
      "[300]\ttraining's rmse: 0.707689\tvalid_1's rmse: 0.989457\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's rmse: 0.802665\tvalid_1's rmse: 0.984113\n",
      "Partial score of fold 1 is: 0.594355624865818\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.854753\tvalid_1's rmse: 0.9824\n",
      "[200]\ttraining's rmse: 0.772813\tvalid_1's rmse: 0.986665\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's rmse: 0.851687\tvalid_1's rmse: 0.982009\n",
      "Partial score of fold 2 is: 0.6056284945762078\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.855578\tvalid_1's rmse: 0.974137\n",
      "[200]\ttraining's rmse: 0.773798\tvalid_1's rmse: 0.975799\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's rmse: 0.847533\tvalid_1's rmse: 0.973368\n",
      "Partial score of fold 3 is: 0.6033023468581908\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.853513\tvalid_1's rmse: 0.98408\n",
      "[200]\ttraining's rmse: 0.76972\tvalid_1's rmse: 0.987811\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's rmse: 0.863877\tvalid_1's rmse: 0.983278\n",
      "Partial score of fold 4 is: 0.5873643488067379\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5933  \u001b[0m | \u001b[0m 0.9804  \u001b[0m | \u001b[0m 1.632   \u001b[0m | \u001b[0m 0.5895  \u001b[0m | \u001b[0m 5.961   \u001b[0m | \u001b[0m 0.08313 \u001b[0m | \u001b[0m 0.08627 \u001b[0m | \u001b[0m 8.035   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.923967\tvalid_1's rmse: 0.999266\n",
      "[200]\ttraining's rmse: 0.862099\tvalid_1's rmse: 0.994464\n",
      "[300]\ttraining's rmse: 0.818806\tvalid_1's rmse: 0.994401\n",
      "[400]\ttraining's rmse: 0.782337\tvalid_1's rmse: 0.995166\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's rmse: 0.824443\tvalid_1's rmse: 0.994158\n",
      "Partial score of fold 0 is: 0.5832616895952758\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.923952\tvalid_1's rmse: 0.9978\n",
      "[200]\ttraining's rmse: 0.862438\tvalid_1's rmse: 0.989042\n",
      "[300]\ttraining's rmse: 0.817868\tvalid_1's rmse: 0.988747\n",
      "[400]\ttraining's rmse: 0.780784\tvalid_1's rmse: 0.989262\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's rmse: 0.800803\tvalid_1's rmse: 0.988364\n",
      "Partial score of fold 1 is: 0.5864825095125301\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.926879\tvalid_1's rmse: 0.992043\n",
      "[200]\ttraining's rmse: 0.864555\tvalid_1's rmse: 0.981758\n",
      "[300]\ttraining's rmse: 0.821383\tvalid_1's rmse: 0.981239\n",
      "[400]\ttraining's rmse: 0.785613\tvalid_1's rmse: 0.981511\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's rmse: 0.805875\tvalid_1's rmse: 0.980908\n",
      "Partial score of fold 2 is: 0.6043759534972756\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.927238\tvalid_1's rmse: 0.981879\n",
      "[200]\ttraining's rmse: 0.864915\tvalid_1's rmse: 0.971974\n",
      "[300]\ttraining's rmse: 0.821637\tvalid_1's rmse: 0.970904\n",
      "[400]\ttraining's rmse: 0.786616\tvalid_1's rmse: 0.971784\n",
      "Early stopping, best iteration is:\n",
      "[339]\ttraining's rmse: 0.807621\tvalid_1's rmse: 0.970569\n",
      "Partial score of fold 3 is: 0.5999025925010892\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.925027\tvalid_1's rmse: 0.991263\n",
      "[200]\ttraining's rmse: 0.86435\tvalid_1's rmse: 0.982709\n",
      "[300]\ttraining's rmse: 0.820708\tvalid_1's rmse: 0.982629\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's rmse: 0.85345\tvalid_1's rmse: 0.982444\n",
      "Partial score of fold 4 is: 0.5923757555442835\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 0.9911  \u001b[0m | \u001b[0m 9.923   \u001b[0m | \u001b[0m 0.5864  \u001b[0m | \u001b[0m 0.0799  \u001b[0m | \u001b[0m 5.797   \u001b[0m | \u001b[0m 0.03539 \u001b[0m | \u001b[0m 8.148   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.82567\tvalid_1's rmse: 1.00083\n",
      "[200]\ttraining's rmse: 0.728905\tvalid_1's rmse: 1.00622\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's rmse: 0.873855\tvalid_1's rmse: 0.999595\n",
      "Partial score of fold 0 is: 0.5712730821254963\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.825312\tvalid_1's rmse: 0.992641\n",
      "[200]\ttraining's rmse: 0.728139\tvalid_1's rmse: 0.995674\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's rmse: 0.869289\tvalid_1's rmse: 0.990445\n",
      "Partial score of fold 1 is: 0.5859457061929877\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.829063\tvalid_1's rmse: 0.983404\n",
      "[200]\ttraining's rmse: 0.733732\tvalid_1's rmse: 0.985391\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's rmse: 0.818707\tvalid_1's rmse: 0.98285\n",
      "Partial score of fold 2 is: 0.6011551335800214\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.829487\tvalid_1's rmse: 0.975865\n",
      "[200]\ttraining's rmse: 0.734352\tvalid_1's rmse: 0.979196\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's rmse: 0.879723\tvalid_1's rmse: 0.975204\n",
      "Partial score of fold 3 is: 0.5979343136627672\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.827533\tvalid_1's rmse: 0.984255\n",
      "[200]\ttraining's rmse: 0.731722\tvalid_1's rmse: 0.991284\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's rmse: 0.822633\tvalid_1's rmse: 0.983846\n",
      "Partial score of fold 4 is: 0.5954183953492218\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5906  \u001b[0m | \u001b[0m 0.9441  \u001b[0m | \u001b[0m 9.821   \u001b[0m | \u001b[0m 0.5999  \u001b[0m | \u001b[0m 0.05487 \u001b[0m | \u001b[0m 5.888   \u001b[0m | \u001b[0m 0.09806 \u001b[0m | \u001b[0m 11.76   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.934958\tvalid_1's rmse: 1.00447\n",
      "[200]\ttraining's rmse: 0.877151\tvalid_1's rmse: 0.995274\n",
      "[300]\ttraining's rmse: 0.836029\tvalid_1's rmse: 0.995124\n",
      "[400]\ttraining's rmse: 0.802857\tvalid_1's rmse: 0.997076\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's rmse: 0.847322\tvalid_1's rmse: 0.994645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial score of fold 0 is: 0.5762832464412251\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.935585\tvalid_1's rmse: 0.998844\n",
      "[200]\ttraining's rmse: 0.878553\tvalid_1's rmse: 0.988183\n",
      "[300]\ttraining's rmse: 0.839235\tvalid_1's rmse: 0.987074\n",
      "[400]\ttraining's rmse: 0.806535\tvalid_1's rmse: 0.988786\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's rmse: 0.843311\tvalid_1's rmse: 0.986601\n",
      "Partial score of fold 1 is: 0.592387346027496\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.937908\tvalid_1's rmse: 0.993966\n",
      "[200]\ttraining's rmse: 0.879822\tvalid_1's rmse: 0.981484\n",
      "[300]\ttraining's rmse: 0.840964\tvalid_1's rmse: 0.979528\n",
      "[400]\ttraining's rmse: 0.809831\tvalid_1's rmse: 0.982203\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttraining's rmse: 0.83769\tvalid_1's rmse: 0.979208\n",
      "Partial score of fold 2 is: 0.60688103565514\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.939083\tvalid_1's rmse: 0.988798\n",
      "[200]\ttraining's rmse: 0.882369\tvalid_1's rmse: 0.974194\n",
      "[300]\ttraining's rmse: 0.843599\tvalid_1's rmse: 0.972338\n",
      "[400]\ttraining's rmse: 0.810585\tvalid_1's rmse: 0.973339\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's rmse: 0.854073\tvalid_1's rmse: 0.971892\n",
      "Partial score of fold 3 is: 0.5990079203018519\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.93561\tvalid_1's rmse: 0.996203\n",
      "[200]\ttraining's rmse: 0.878888\tvalid_1's rmse: 0.98669\n",
      "[300]\ttraining's rmse: 0.838555\tvalid_1's rmse: 0.985768\n",
      "[400]\ttraining's rmse: 0.807042\tvalid_1's rmse: 0.986382\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's rmse: 0.850458\tvalid_1's rmse: 0.985524\n",
      "Partial score of fold 4 is: 0.5904069886116763\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5937  \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 9.951   \u001b[0m | \u001b[0m 0.4725  \u001b[0m | \u001b[0m 5.948   \u001b[0m | \u001b[0m 0.0164  \u001b[0m | \u001b[0m 0.03632 \u001b[0m | \u001b[0m 8.444   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.869383\tvalid_1's rmse: 0.997313\n",
      "[200]\ttraining's rmse: 0.79096\tvalid_1's rmse: 0.99927\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's rmse: 0.845482\tvalid_1's rmse: 0.996728\n",
      "Partial score of fold 0 is: 0.5773568530803098\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.870295\tvalid_1's rmse: 0.989778\n",
      "[200]\ttraining's rmse: 0.792337\tvalid_1's rmse: 0.989012\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's rmse: 0.829177\tvalid_1's rmse: 0.988376\n",
      "Partial score of fold 1 is: 0.5941766904259707\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.872516\tvalid_1's rmse: 0.982663\n",
      "[200]\ttraining's rmse: 0.794365\tvalid_1's rmse: 0.982738\n",
      "[300]\ttraining's rmse: 0.73403\tvalid_1's rmse: 0.983282\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's rmse: 0.818293\tvalid_1's rmse: 0.980541\n",
      "Partial score of fold 2 is: 0.6047338223769705\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.875119\tvalid_1's rmse: 0.974131\n",
      "[200]\ttraining's rmse: 0.797154\tvalid_1's rmse: 0.973446\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's rmse: 0.863225\tvalid_1's rmse: 0.972086\n",
      "Partial score of fold 3 is: 0.6047338223769705\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.871961\tvalid_1's rmse: 0.985908\n",
      "[200]\ttraining's rmse: 0.792496\tvalid_1's rmse: 0.985627\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's rmse: 0.83851\tvalid_1's rmse: 0.984481\n",
      "Partial score of fold 4 is: 0.5902280097996211\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5939  \u001b[0m | \u001b[0m 0.7906  \u001b[0m | \u001b[0m 1.182   \u001b[0m | \u001b[0m 0.5274  \u001b[0m | \u001b[0m 0.00618 \u001b[0m | \u001b[0m 0.001979\u001b[0m | \u001b[0m 0.06216 \u001b[0m | \u001b[0m 8.047   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.904981\tvalid_1's rmse: 0.996635\n",
      "[200]\ttraining's rmse: 0.841096\tvalid_1's rmse: 0.996569\n",
      "[300]\ttraining's rmse: 0.794308\tvalid_1's rmse: 1.00059\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttraining's rmse: 0.865921\tvalid_1's rmse: 0.995237\n",
      "Partial score of fold 0 is: 0.5802198041178691\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.904947\tvalid_1's rmse: 0.991745\n",
      "[200]\ttraining's rmse: 0.841894\tvalid_1's rmse: 0.988132\n",
      "[300]\ttraining's rmse: 0.795158\tvalid_1's rmse: 0.990787\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's rmse: 0.843945\tvalid_1's rmse: 0.987765\n",
      "Partial score of fold 1 is: 0.5939977559861231\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.908321\tvalid_1's rmse: 0.988307\n",
      "[200]\ttraining's rmse: 0.843422\tvalid_1's rmse: 0.984267\n",
      "[300]\ttraining's rmse: 0.797669\tvalid_1's rmse: 0.985319\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's rmse: 0.856757\tvalid_1's rmse: 0.983483\n",
      "Partial score of fold 2 is: 0.6058074290160552\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.910526\tvalid_1's rmse: 0.981714\n",
      "[200]\ttraining's rmse: 0.847057\tvalid_1's rmse: 0.974037\n",
      "[300]\ttraining's rmse: 0.800583\tvalid_1's rmse: 0.974549\n",
      "[400]\ttraining's rmse: 0.761872\tvalid_1's rmse: 0.974766\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttraining's rmse: 0.817983\tvalid_1's rmse: 0.972898\n",
      "Partial score of fold 3 is: 0.6058074290160552\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.906418\tvalid_1's rmse: 0.990598\n",
      "[200]\ttraining's rmse: 0.843173\tvalid_1's rmse: 0.989557\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's rmse: 0.882328\tvalid_1's rmse: 0.988672\n",
      "Partial score of fold 4 is: 0.5884382216790691\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5943  \u001b[0m | \u001b[0m 0.4967  \u001b[0m | \u001b[0m 1.231   \u001b[0m | \u001b[0m 0.4352  \u001b[0m | \u001b[0m 5.827   \u001b[0m | \u001b[0m 0.04034 \u001b[0m | \u001b[0m 0.05387 \u001b[0m | \u001b[0m 11.79   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.907337\tvalid_1's rmse: 0.997734\n",
      "[200]\ttraining's rmse: 0.845832\tvalid_1's rmse: 0.996941\n",
      "[300]\ttraining's rmse: 0.800313\tvalid_1's rmse: 0.999653\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's rmse: 0.853922\tvalid_1's rmse: 0.995986\n",
      "Partial score of fold 0 is: 0.5755675086818353\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.909083\tvalid_1's rmse: 0.989214\n",
      "[200]\ttraining's rmse: 0.848299\tvalid_1's rmse: 0.983456\n",
      "[300]\ttraining's rmse: 0.803232\tvalid_1's rmse: 0.985607\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's rmse: 0.833403\tvalid_1's rmse: 0.983194\n",
      "Partial score of fold 1 is: 0.600260461380784\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.910423\tvalid_1's rmse: 0.985384\n",
      "[200]\ttraining's rmse: 0.847672\tvalid_1's rmse: 0.982663\n",
      "[300]\ttraining's rmse: 0.802385\tvalid_1's rmse: 0.981535\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's rmse: 0.827315\tvalid_1's rmse: 0.980935\n",
      "Partial score of fold 2 is: 0.6054495601363603\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.913236\tvalid_1's rmse: 0.977355\n",
      "[200]\ttraining's rmse: 0.851502\tvalid_1's rmse: 0.971203\n",
      "[300]\ttraining's rmse: 0.805367\tvalid_1's rmse: 0.970711\n",
      "Early stopping, best iteration is:\n",
      "[229]\ttraining's rmse: 0.836861\tvalid_1's rmse: 0.970127\n",
      "Partial score of fold 3 is: 0.5995447236213942\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.90889\tvalid_1's rmse: 0.98731\n",
      "[200]\ttraining's rmse: 0.848067\tvalid_1's rmse: 0.984163\n",
      "[300]\ttraining's rmse: 0.802513\tvalid_1's rmse: 0.987219\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's rmse: 0.85211\tvalid_1's rmse: 0.983709\n",
      "Partial score of fold 4 is: 0.5909439250478419\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.594   \u001b[0m | \u001b[0m 0.5644  \u001b[0m | \u001b[0m 1.34    \u001b[0m | \u001b[0m 0.4549  \u001b[0m | \u001b[0m 5.848   \u001b[0m | \u001b[0m 5.853   \u001b[0m | \u001b[0m 0.05406 \u001b[0m | \u001b[0m 8.011   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.850499\tvalid_1's rmse: 1.00545\n",
      "[200]\ttraining's rmse: 0.768969\tvalid_1's rmse: 1.00853\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 0.911356\tvalid_1's rmse: 1.00197\n",
      "Partial score of fold 0 is: 0.5718853268045783\n",
      "Training until validation scores don't improve for 150 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.851043\tvalid_1's rmse: 0.990163\n",
      "[200]\ttraining's rmse: 0.770219\tvalid_1's rmse: 0.995942\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's rmse: 0.850172\tvalid_1's rmse: 0.989931\n",
      "Partial score of fold 1 is: 0.59703964146353\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.855788\tvalid_1's rmse: 0.983256\n",
      "[200]\ttraining's rmse: 0.774567\tvalid_1's rmse: 0.986904\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's rmse: 0.873643\tvalid_1's rmse: 0.981288\n",
      "Partial score of fold 2 is: 0.6077757078543773\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.857022\tvalid_1's rmse: 0.976154\n",
      "[200]\ttraining's rmse: 0.77507\tvalid_1's rmse: 0.977238\n",
      "[300]\ttraining's rmse: 0.713933\tvalid_1's rmse: 0.981981\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's rmse: 0.811479\tvalid_1's rmse: 0.975472\n",
      "Partial score of fold 3 is: 0.6007972647003265\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.853648\tvalid_1's rmse: 0.990202\n",
      "[200]\ttraining's rmse: 0.773048\tvalid_1's rmse: 0.991996\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's rmse: 0.843668\tvalid_1's rmse: 0.989055\n",
      "Partial score of fold 4 is: 0.5889751581152347\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5924  \u001b[0m | \u001b[0m 0.7517  \u001b[0m | \u001b[0m 9.888   \u001b[0m | \u001b[0m 0.4683  \u001b[0m | \u001b[0m 5.87    \u001b[0m | \u001b[0m 0.02078 \u001b[0m | \u001b[0m 0.09419 \u001b[0m | \u001b[0m 8.605   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.874175\tvalid_1's rmse: 0.997542\n",
      "[200]\ttraining's rmse: 0.794826\tvalid_1's rmse: 0.998209\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's rmse: 0.836565\tvalid_1's rmse: 0.995629\n",
      "Partial score of fold 0 is: 0.5757464431216828\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.87657\tvalid_1's rmse: 0.989616\n",
      "[200]\ttraining's rmse: 0.797327\tvalid_1's rmse: 0.989915\n",
      "[300]\ttraining's rmse: 0.735453\tvalid_1's rmse: 0.992074\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttraining's rmse: 0.792001\tvalid_1's rmse: 0.989349\n",
      "Partial score of fold 1 is: 0.5889875916703944\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.878795\tvalid_1's rmse: 0.984366\n",
      "[200]\ttraining's rmse: 0.799131\tvalid_1's rmse: 0.984964\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's rmse: 0.840539\tvalid_1's rmse: 0.983594\n",
      "Partial score of fold 2 is: 0.6006183302604791\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.878531\tvalid_1's rmse: 0.97362\n",
      "[200]\ttraining's rmse: 0.799104\tvalid_1's rmse: 0.97095\n",
      "[300]\ttraining's rmse: 0.7411\tvalid_1's rmse: 0.972191\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's rmse: 0.81806\tvalid_1's rmse: 0.970313\n",
      "Partial score of fold 3 is: 0.6027655435386485\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.87754\tvalid_1's rmse: 0.983688\n",
      "[200]\ttraining's rmse: 0.797353\tvalid_1's rmse: 0.983849\n",
      "[300]\ttraining's rmse: 0.736306\tvalid_1's rmse: 0.983788\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's rmse: 0.808355\tvalid_1's rmse: 0.982761\n",
      "Partial score of fold 4 is: 0.5879012852429035\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5915  \u001b[0m | \u001b[0m 0.9516  \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m 0.5648  \u001b[0m | \u001b[0m 0.3986  \u001b[0m | \u001b[0m 0.06001 \u001b[0m | \u001b[0m 0.05715 \u001b[0m | \u001b[0m 11.8    \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.901101\tvalid_1's rmse: 0.993791\n",
      "[200]\ttraining's rmse: 0.835914\tvalid_1's rmse: 0.994521\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's rmse: 0.86838\tvalid_1's rmse: 0.993241\n",
      "Partial score of fold 0 is: 0.5762254897370791\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.902296\tvalid_1's rmse: 0.987327\n",
      "[200]\ttraining's rmse: 0.838473\tvalid_1's rmse: 0.983175\n",
      "[300]\ttraining's rmse: 0.790054\tvalid_1's rmse: 0.984202\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's rmse: 0.833624\tvalid_1's rmse: 0.982851\n",
      "Partial score of fold 1 is: 0.5975764447830723\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.904633\tvalid_1's rmse: 0.983274\n",
      "[200]\ttraining's rmse: 0.840024\tvalid_1's rmse: 0.978983\n",
      "[300]\ttraining's rmse: 0.792348\tvalid_1's rmse: 0.979283\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's rmse: 0.818911\tvalid_1's rmse: 0.978408\n",
      "Partial score of fold 2 is: 0.6033023468581908\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.905263\tvalid_1's rmse: 0.977876\n",
      "[200]\ttraining's rmse: 0.841119\tvalid_1's rmse: 0.971888\n",
      "[300]\ttraining's rmse: 0.793257\tvalid_1's rmse: 0.971728\n",
      "[400]\ttraining's rmse: 0.753705\tvalid_1's rmse: 0.970955\n",
      "Early stopping, best iteration is:\n",
      "[343]\ttraining's rmse: 0.775109\tvalid_1's rmse: 0.970566\n",
      "Partial score of fold 3 is: 0.6031234124183433\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.902232\tvalid_1's rmse: 0.9864\n",
      "[200]\ttraining's rmse: 0.838447\tvalid_1's rmse: 0.983958\n",
      "[300]\ttraining's rmse: 0.790372\tvalid_1's rmse: 0.98409\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's rmse: 0.844118\tvalid_1's rmse: 0.983593\n",
      "Partial score of fold 4 is: 0.5916598402960627\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5948  \u001b[0m | \u001b[0m 0.9371  \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m 0.5599  \u001b[0m | \u001b[0m 5.986   \u001b[0m | \u001b[0m 5.75    \u001b[0m | \u001b[0m 0.05208 \u001b[0m | \u001b[0m 8.216   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.955443\tvalid_1's rmse: 1.00985\n",
      "[200]\ttraining's rmse: 0.901556\tvalid_1's rmse: 0.997439\n",
      "[300]\ttraining's rmse: 0.866309\tvalid_1's rmse: 0.996844\n",
      "[400]\ttraining's rmse: 0.837186\tvalid_1's rmse: 0.998875\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's rmse: 0.880985\tvalid_1's rmse: 0.99668\n",
      "Partial score of fold 0 is: 0.5760110767479398\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.956583\tvalid_1's rmse: 1.00799\n",
      "[200]\ttraining's rmse: 0.902476\tvalid_1's rmse: 0.994196\n",
      "[300]\ttraining's rmse: 0.867358\tvalid_1's rmse: 0.990954\n",
      "[400]\ttraining's rmse: 0.838439\tvalid_1's rmse: 0.988945\n",
      "[500]\ttraining's rmse: 0.813844\tvalid_1's rmse: 0.989144\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's rmse: 0.830656\tvalid_1's rmse: 0.987955\n",
      "Partial score of fold 1 is: 0.6015130024597163\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.961667\tvalid_1's rmse: 1.00481\n",
      "[200]\ttraining's rmse: 0.905751\tvalid_1's rmse: 0.986674\n",
      "[300]\ttraining's rmse: 0.86928\tvalid_1's rmse: 0.982124\n",
      "[400]\ttraining's rmse: 0.840418\tvalid_1's rmse: 0.980931\n",
      "[500]\ttraining's rmse: 0.816214\tvalid_1's rmse: 0.981896\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's rmse: 0.839921\tvalid_1's rmse: 0.98081\n",
      "Partial score of fold 2 is: 0.604554887937123\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.95988\tvalid_1's rmse: 0.997626\n",
      "[200]\ttraining's rmse: 0.906524\tvalid_1's rmse: 0.978545\n",
      "[300]\ttraining's rmse: 0.87098\tvalid_1's rmse: 0.974011\n",
      "[400]\ttraining's rmse: 0.842155\tvalid_1's rmse: 0.971317\n",
      "[500]\ttraining's rmse: 0.817624\tvalid_1's rmse: 0.970994\n",
      "[600]\ttraining's rmse: 0.795739\tvalid_1's rmse: 0.970214\n",
      "[700]\ttraining's rmse: 0.775541\tvalid_1's rmse: 0.970787\n",
      "Early stopping, best iteration is:\n",
      "[597]\ttraining's rmse: 0.79633\tvalid_1's rmse: 0.97014\n",
      "Partial score of fold 3 is: 0.6011551335800214\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.956504\tvalid_1's rmse: 1.00201\n",
      "[200]\ttraining's rmse: 0.902896\tvalid_1's rmse: 0.98886\n",
      "[300]\ttraining's rmse: 0.867439\tvalid_1's rmse: 0.987434\n",
      "[400]\ttraining's rmse: 0.838577\tvalid_1's rmse: 0.986859\n",
      "[500]\ttraining's rmse: 0.813626\tvalid_1's rmse: 0.988677\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's rmse: 0.839911\tvalid_1's rmse: 0.986672\n",
      "Partial score of fold 4 is: 0.5893331157393451\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5949  \u001b[0m | \u001b[0m 0.4291  \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 0.4016  \u001b[0m | \u001b[0m 5.983   \u001b[0m | \u001b[0m 5.87    \u001b[0m | \u001b[0m 0.03117 \u001b[0m | \u001b[0m 11.68   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.902138\tvalid_1's rmse: 0.997667\n",
      "[200]\ttraining's rmse: 0.837604\tvalid_1's rmse: 0.996022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's rmse: 0.79036\tvalid_1's rmse: 0.998685\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's rmse: 0.853311\tvalid_1's rmse: 0.994968\n",
      "Partial score of fold 0 is: 0.5735992298435133\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.903838\tvalid_1's rmse: 0.991721\n",
      "[200]\ttraining's rmse: 0.838205\tvalid_1's rmse: 0.988048\n",
      "[300]\ttraining's rmse: 0.790642\tvalid_1's rmse: 0.987678\n",
      "[400]\ttraining's rmse: 0.751303\tvalid_1's rmse: 0.989342\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's rmse: 0.809655\tvalid_1's rmse: 0.987124\n",
      "Partial score of fold 1 is: 0.5952502970650553\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.906391\tvalid_1's rmse: 0.985702\n",
      "[200]\ttraining's rmse: 0.841895\tvalid_1's rmse: 0.979093\n",
      "[300]\ttraining's rmse: 0.793871\tvalid_1's rmse: 0.978467\n",
      "[400]\ttraining's rmse: 0.754938\tvalid_1's rmse: 0.980649\n",
      "Early stopping, best iteration is:\n",
      "[339]\ttraining's rmse: 0.777964\tvalid_1's rmse: 0.977918\n",
      "Partial score of fold 2 is: 0.6097439866926992\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.908156\tvalid_1's rmse: 0.979155\n",
      "[200]\ttraining's rmse: 0.844094\tvalid_1's rmse: 0.972537\n",
      "[300]\ttraining's rmse: 0.795702\tvalid_1's rmse: 0.972678\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's rmse: 0.838293\tvalid_1's rmse: 0.971795\n",
      "Partial score of fold 3 is: 0.6038391501777332\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.904854\tvalid_1's rmse: 0.986877\n",
      "[200]\ttraining's rmse: 0.841354\tvalid_1's rmse: 0.982064\n",
      "[300]\ttraining's rmse: 0.793204\tvalid_1's rmse: 0.983184\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's rmse: 0.831954\tvalid_1's rmse: 0.981337\n",
      "Partial score of fold 4 is: 0.5920177979201731\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5947  \u001b[0m | \u001b[0m 0.7695  \u001b[0m | \u001b[0m 1.081   \u001b[0m | \u001b[0m 0.43    \u001b[0m | \u001b[0m 5.941   \u001b[0m | \u001b[0m 0.177   \u001b[0m | \u001b[0m 0.05223 \u001b[0m | \u001b[0m 8.008   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.960315\tvalid_1's rmse: 1.01037\n",
      "[200]\ttraining's rmse: 0.905948\tvalid_1's rmse: 0.995134\n",
      "[300]\ttraining's rmse: 0.87198\tvalid_1's rmse: 0.993228\n",
      "[400]\ttraining's rmse: 0.84417\tvalid_1's rmse: 0.993553\n",
      "Early stopping, best iteration is:\n",
      "[346]\ttraining's rmse: 0.858399\tvalid_1's rmse: 0.992922\n",
      "Partial score of fold 0 is: 0.5807566074374115\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.961268\tvalid_1's rmse: 1.00814\n",
      "[200]\ttraining's rmse: 0.907287\tvalid_1's rmse: 0.990985\n",
      "[300]\ttraining's rmse: 0.872402\tvalid_1's rmse: 0.987221\n",
      "[400]\ttraining's rmse: 0.844485\tvalid_1's rmse: 0.986795\n",
      "[500]\ttraining's rmse: 0.820839\tvalid_1's rmse: 0.987034\n",
      "Early stopping, best iteration is:\n",
      "[422]\ttraining's rmse: 0.839057\tvalid_1's rmse: 0.986402\n",
      "Partial score of fold 1 is: 0.5981132481026146\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.963568\tvalid_1's rmse: 1.00483\n",
      "[200]\ttraining's rmse: 0.909497\tvalid_1's rmse: 0.985293\n",
      "[300]\ttraining's rmse: 0.875493\tvalid_1's rmse: 0.98138\n",
      "[400]\ttraining's rmse: 0.847337\tvalid_1's rmse: 0.981823\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's rmse: 0.861818\tvalid_1's rmse: 0.980669\n",
      "Partial score of fold 2 is: 0.6018708713394112\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.963954\tvalid_1's rmse: 0.996653\n",
      "[200]\ttraining's rmse: 0.911136\tvalid_1's rmse: 0.975358\n",
      "[300]\ttraining's rmse: 0.876954\tvalid_1's rmse: 0.969253\n",
      "[400]\ttraining's rmse: 0.84943\tvalid_1's rmse: 0.96905\n",
      "[500]\ttraining's rmse: 0.825085\tvalid_1's rmse: 0.968114\n",
      "[600]\ttraining's rmse: 0.804164\tvalid_1's rmse: 0.967722\n",
      "[700]\ttraining's rmse: 0.785013\tvalid_1's rmse: 0.967713\n",
      "Early stopping, best iteration is:\n",
      "[648]\ttraining's rmse: 0.794739\tvalid_1's rmse: 0.967406\n",
      "Partial score of fold 3 is: 0.6093861178130043\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.961212\tvalid_1's rmse: 1.00441\n",
      "[200]\ttraining's rmse: 0.907435\tvalid_1's rmse: 0.986504\n",
      "[300]\ttraining's rmse: 0.873377\tvalid_1's rmse: 0.98271\n",
      "[400]\ttraining's rmse: 0.845882\tvalid_1's rmse: 0.981775\n",
      "[500]\ttraining's rmse: 0.82198\tvalid_1's rmse: 0.981855\n",
      "Early stopping, best iteration is:\n",
      "[421]\ttraining's rmse: 0.840577\tvalid_1's rmse: 0.981447\n",
      "Partial score of fold 4 is: 0.5959553317853874\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.5969  \u001b[0m | \u001b[95m 0.5703  \u001b[0m | \u001b[95m 1.107   \u001b[0m | \u001b[95m 0.5515  \u001b[0m | \u001b[95m 5.808   \u001b[0m | \u001b[95m 5.988   \u001b[0m | \u001b[95m 0.02607 \u001b[0m | \u001b[95m 8.185   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.86164\tvalid_1's rmse: 1.00126\n",
      "[200]\ttraining's rmse: 0.783803\tvalid_1's rmse: 1.00571\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's rmse: 0.897243\tvalid_1's rmse: 1.00062\n",
      "Partial score of fold 0 is: 0.5693785909514892\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.861589\tvalid_1's rmse: 0.989723\n",
      "[200]\ttraining's rmse: 0.784973\tvalid_1's rmse: 0.990028\n",
      "[300]\ttraining's rmse: 0.725944\tvalid_1's rmse: 0.992593\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttraining's rmse: 0.812219\tvalid_1's rmse: 0.987976\n",
      "Partial score of fold 1 is: 0.5961449692642926\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.86405\tvalid_1's rmse: 0.984112\n",
      "[200]\ttraining's rmse: 0.785454\tvalid_1's rmse: 0.985046\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's rmse: 0.842931\tvalid_1's rmse: 0.983492\n",
      "Partial score of fold 2 is: 0.6056284945762078\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.865694\tvalid_1's rmse: 0.975413\n",
      "[200]\ttraining's rmse: 0.786534\tvalid_1's rmse: 0.975524\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's rmse: 0.835232\tvalid_1's rmse: 0.97388\n",
      "Partial score of fold 3 is: 0.604554887937123\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.86227\tvalid_1's rmse: 0.986747\n",
      "[200]\ttraining's rmse: 0.783945\tvalid_1's rmse: 0.993284\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's rmse: 0.868471\tvalid_1's rmse: 0.986549\n",
      "Partial score of fold 4 is: 0.5871853699946827\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5933  \u001b[0m | \u001b[0m 0.7321  \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m 0.4441  \u001b[0m | \u001b[0m 5.976   \u001b[0m | \u001b[0m 5.742   \u001b[0m | \u001b[0m 0.08782 \u001b[0m | \u001b[0m 11.77   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.866022\tvalid_1's rmse: 1.00061\n",
      "[200]\ttraining's rmse: 0.791357\tvalid_1's rmse: 1.00664\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 0.89192\tvalid_1's rmse: 0.999127\n",
      "Partial score of fold 0 is: 0.5743149676029031\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.868514\tvalid_1's rmse: 0.990227\n",
      "[200]\ttraining's rmse: 0.792764\tvalid_1's rmse: 0.990052\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's rmse: 0.832679\tvalid_1's rmse: 0.988215\n",
      "Partial score of fold 1 is: 0.592387346027496\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.870834\tvalid_1's rmse: 0.982984\n",
      "[200]\ttraining's rmse: 0.797091\tvalid_1's rmse: 0.983631\n",
      "[300]\ttraining's rmse: 0.741651\tvalid_1's rmse: 0.986626\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttraining's rmse: 0.825915\tvalid_1's rmse: 0.979695\n",
      "Partial score of fold 2 is: 0.6072389045348349\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.871595\tvalid_1's rmse: 0.974933\n",
      "[200]\ttraining's rmse: 0.796384\tvalid_1's rmse: 0.973972\n",
      "[300]\ttraining's rmse: 0.74009\tvalid_1's rmse: 0.974938\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's rmse: 0.781614\tvalid_1's rmse: 0.972426\n",
      "Partial score of fold 3 is: 0.6016919368995637\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.869512\tvalid_1's rmse: 0.986346\n",
      "[200]\ttraining's rmse: 0.795204\tvalid_1's rmse: 0.992027\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's rmse: 0.881751\tvalid_1's rmse: 0.985852\n",
      "Partial score of fold 4 is: 0.586469454746462\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5928  \u001b[0m | \u001b[0m 0.5872  \u001b[0m | \u001b[0m 1.143   \u001b[0m | \u001b[0m 0.488   \u001b[0m | \u001b[0m 5.981   \u001b[0m | \u001b[0m 5.535   \u001b[0m | \u001b[0m 0.08688 \u001b[0m | \u001b[0m 8.016   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.854182\tvalid_1's rmse: 1.00288\n",
      "[200]\ttraining's rmse: 0.774735\tvalid_1's rmse: 1.00829\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's rmse: 0.898426\tvalid_1's rmse: 0.999797\n",
      "Partial score of fold 0 is: 0.5694837377270218\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.855152\tvalid_1's rmse: 0.991559\n",
      "[200]\ttraining's rmse: 0.776094\tvalid_1's rmse: 0.997474\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's rmse: 0.859041\tvalid_1's rmse: 0.991125\n",
      "Partial score of fold 1 is: 0.5938188215462756\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.859268\tvalid_1's rmse: 0.984204\n",
      "[200]\ttraining's rmse: 0.778206\tvalid_1's rmse: 0.991053\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's rmse: 0.870408\tvalid_1's rmse: 0.983289\n",
      "Partial score of fold 2 is: 0.6011551335800214\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.861589\tvalid_1's rmse: 0.976739\n",
      "[200]\ttraining's rmse: 0.780387\tvalid_1's rmse: 0.976135\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's rmse: 0.838995\tvalid_1's rmse: 0.973814\n",
      "Partial score of fold 3 is: 0.5993657891815468\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.856054\tvalid_1's rmse: 0.98904\n",
      "[200]\ttraining's rmse: 0.777917\tvalid_1's rmse: 0.992407\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 0.883758\tvalid_1's rmse: 0.987225\n",
      "Partial score of fold 4 is: 0.5913018826719523\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5912  \u001b[0m | \u001b[0m 0.6575  \u001b[0m | \u001b[0m 9.944   \u001b[0m | \u001b[0m 0.5246  \u001b[0m | \u001b[0m 5.839   \u001b[0m | \u001b[0m 5.945   \u001b[0m | \u001b[0m 0.09816 \u001b[0m | \u001b[0m 8.136   \u001b[0m |\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.835817\tvalid_1's rmse: 1.00562\n",
      "[200]\ttraining's rmse: 0.746338\tvalid_1's rmse: 1.01598\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 0.895876\tvalid_1's rmse: 1.00197\n",
      "Partial score of fold 0 is: 0.5725256232044285\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.837941\tvalid_1's rmse: 0.994272\n",
      "[200]\ttraining's rmse: 0.748444\tvalid_1's rmse: 1.00101\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's rmse: 0.852411\tvalid_1's rmse: 0.993428\n",
      "Partial score of fold 1 is: 0.5920294771478012\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.83865\tvalid_1's rmse: 0.989411\n",
      "[200]\ttraining's rmse: 0.746177\tvalid_1's rmse: 0.993904\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's rmse: 0.840704\tvalid_1's rmse: 0.989211\n",
      "Partial score of fold 2 is: 0.5993657891815468\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.840173\tvalid_1's rmse: 0.978522\n",
      "[200]\ttraining's rmse: 0.750218\tvalid_1's rmse: 0.984827\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's rmse: 0.850496\tvalid_1's rmse: 0.978104\n",
      "Partial score of fold 3 is: 0.5954292315049028\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.837966\tvalid_1's rmse: 0.98421\n",
      "[200]\ttraining's rmse: 0.749992\tvalid_1's rmse: 0.989042\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's rmse: 0.837097\tvalid_1's rmse: 0.983927\n",
      "Partial score of fold 4 is: 0.5916598402960627\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5895  \u001b[0m | \u001b[0m 0.6385  \u001b[0m | \u001b[0m 1.2     \u001b[0m | \u001b[0m 0.5543  \u001b[0m | \u001b[0m 0.08289 \u001b[0m | \u001b[0m 0.1948  \u001b[0m | \u001b[0m 0.09103 \u001b[0m | \u001b[0m 8.002   \u001b[0m |\n",
      "=============================================================================================================\n",
      "\n",
      " Time taken: 0 hours 9 minutes and 12.66 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LGB_CV(\n",
    "          max_depth,\n",
    "          learning_rate,\n",
    "          bagging_freq,\n",
    "          bagging_fraction,\n",
    "          colsample_bytree,\n",
    "#           feature_fraction,\n",
    "          lambda_l1,\n",
    "          lambda_l2,\n",
    "          target='accuracy_group',\n",
    "          categoricals=['session_title']\n",
    "         ):\n",
    "    train_df = reduce_train\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "#     folds = GroupKFold(n_splits=5)\n",
    "    \n",
    "    cv = folds.split(reduce_train, reduce_train[target])\n",
    "    \n",
    "    param = {\n",
    "        'objective':'regression',\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'metric': 'rmse',\n",
    "        'eval_metric': 'cappa',\n",
    "        \"bagging_seed\": 11,\n",
    "        \"metric\": 'rmse',\n",
    "        'early_stopping_rounds': 150,\n",
    "        'verbose': 100,\n",
    "        \"verbosity\": -1,\n",
    "        'seed': 42,\n",
    "        'bagging_freq': int(bagging_freq),\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'max_depth': int(max_depth),\n",
    "        'learning_rate': learning_rate,\n",
    "#         \"feature_fraction\": feature_fraction,\n",
    "        \"bagging_fraction\": bagging_fraction,\n",
    "        \"lambda_l1\": lambda_l1,\n",
    "        \"lambda_l2\": lambda_l2,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    oof_pred = np.zeros(train_df.shape[0])\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "        \n",
    "        x_train, x_val = train_df[features].iloc[train_idx], train_df[features].iloc[val_idx]   \n",
    "        y_train, y_val = train_df[target][train_idx], train_df[target][val_idx]\n",
    "\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=categoricals)\n",
    "        \n",
    "        clf = lgb.train(param, train_set, 10000, valid_sets = [train_set, val_set], verbose_eval=100, early_stopping_rounds=100)\n",
    "        \n",
    "        oof_pred[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        \n",
    "        del clf, train_idx, val_idx\n",
    "        gc.collect()\n",
    "    _, loss_score, _ = eval_qwk_lgb_regr(train_df[target], oof_pred)    \n",
    "#     return -mean_squared_error(oof, target)**0.5\n",
    "    return loss_score\n",
    "\n",
    "LGB_BO = BayesianOptimization(LGB_CV, {\n",
    "    'max_depth': (8, 12),\n",
    "#     'feature_fraction': (0.4, 1.0),\n",
    "    'bagging_freq': (1, 10),\n",
    "    'bagging_fraction': (0.4, 1.0),\n",
    "    'lambda_l1': (0, 6),\n",
    "    'lambda_l2': (0, 6),\n",
    "    'learning_rate': (0.025, 0.1),\n",
    "    'colsample_bytree': (0.4, 0.6)\n",
    "    })\n",
    "\n",
    "print('-'*126)\n",
    "\n",
    "start_time = timer(None)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0, random_state=1000)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Final Results\n",
      "Maximum  value: 0.596892\n",
      "Best  parameters: {'bagging_fraction': 0.5703482080116283, 'bagging_freq': 1.1066058349920214, 'colsample_bytree': 0.5515000831403941, 'lambda_l1': 5.8079230594147, 'lambda_l2': 5.988476114292218, 'learning_rate': 0.02606739709720534, 'max_depth': 8.184768586407403}\n"
     ]
    }
   ],
   "source": [
    "print('-'*130)\n",
    "print('Final Results')\n",
    "print('Maximum  value: %f' % LGB_BO.max['target'])\n",
    "print('Best  parameters:', LGB_BO.max['params'])\n",
    "\n",
    "if LGB_BO.max['target'] > 0.596892:\n",
    "    LGB_pramas = LGB_BO.max['params']\n",
    "else:\n",
    "    LGB_pramas = {\n",
    "    'bagging_fraction': 0.5703482080116283, \n",
    "    'bagging_freq': 1.1066058349920214,\n",
    "    'colsample_bytree': 0.5515000831403941,\n",
    "    'lambda_l1': 5.8079230594147,\n",
    "    'lambda_l2': 5.988476114292218, \n",
    "    'learning_rate': 0.02606739709720534,\n",
    "    'max_depth': 8.184768586407403}\n",
    "\n",
    "# Maximum  value: 0.596892\n",
    "# Best  parameters: {\n",
    "#     'bagging_fraction': 0.5703482080116283, \n",
    "#     'bagging_freq': 1.1066058349920214,\n",
    "#     'colsample_bytree': 0.5515000831403941,\n",
    "#     'lambda_l1': 5.8079230594147,\n",
    "#     'lambda_l2': 5.988476114292218, \n",
    "#     'learning_rate': 0.02606739709720534,\n",
    "#     'max_depth': 8.184768586407403}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | max_de... | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "[0]\ttrain-rmse:1.79776\tval-rmse:1.79807\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.834009\tval-rmse:0.99363\n",
      "Stopping. Best iteration:\n",
      "[81]\ttrain-rmse:0.841439\tval-rmse:0.992822\n",
      "\n",
      "Partial score of fold 0 is: 0.5800408696780217\n",
      "[0]\ttrain-rmse:1.79764\tval-rmse:1.79778\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.830414\tval-rmse:0.992301\n",
      "[200]\ttrain-rmse:0.808758\tval-rmse:0.992883\n",
      "Stopping. Best iteration:\n",
      "[120]\ttrain-rmse:0.826108\tval-rmse:0.991801\n",
      "\n",
      "Partial score of fold 1 is: 0.59703964146353\n",
      "[0]\ttrain-rmse:1.7978\tval-rmse:1.79834\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.83516\tval-rmse:0.986647\n",
      "[200]\ttrain-rmse:0.811239\tval-rmse:0.986363\n",
      "Stopping. Best iteration:\n",
      "[134]\ttrain-rmse:0.826012\tval-rmse:0.985119\n",
      "\n",
      "Partial score of fold 2 is: 0.5972185759033773\n",
      "[0]\ttrain-rmse:1.79772\tval-rmse:1.79787\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.836374\tval-rmse:0.979149\n",
      "[200]\ttrain-rmse:0.812363\tval-rmse:0.977575\n",
      "Stopping. Best iteration:\n",
      "[153]\ttrain-rmse:0.820011\tval-rmse:0.977169\n",
      "\n",
      "Partial score of fold 3 is: 0.6031234124183433\n",
      "[0]\ttrain-rmse:1.7977\tval-rmse:1.79814\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.832087\tval-rmse:0.988408\n",
      "[200]\ttrain-rmse:0.810553\tval-rmse:0.988811\n",
      "Stopping. Best iteration:\n",
      "[146]\ttrain-rmse:0.821708\tval-rmse:0.987961\n",
      "\n",
      "Partial score of fold 4 is: 0.5847235060228589\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5923  \u001b[0m | \u001b[0m 0.5718  \u001b[0m | \u001b[0m 9.121   \u001b[0m | \u001b[0m 1.071   \u001b[0m | \u001b[0m 8.294   \u001b[0m | \u001b[0m 0.6493  \u001b[0m | \u001b[0m 0.6593  \u001b[0m |\n",
      "[0]\ttrain-rmse:1.75182\tval-rmse:1.7529\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.930346\tval-rmse:1.00445\n",
      "[200]\ttrain-rmse:0.884252\tval-rmse:1.00249\n",
      "Stopping. Best iteration:\n",
      "[173]\ttrain-rmse:0.89527\tval-rmse:1.00101\n",
      "\n",
      "Partial score of fold 0 is: 0.575030705362293\n",
      "[0]\ttrain-rmse:1.7501\tval-rmse:1.75193\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.931441\tval-rmse:0.99962\n",
      "[200]\ttrain-rmse:0.887144\tval-rmse:0.998554\n",
      "Stopping. Best iteration:\n",
      "[144]\ttrain-rmse:0.906876\tval-rmse:0.998048\n",
      "\n",
      "Partial score of fold 1 is: 0.5905980016290215\n",
      "[0]\ttrain-rmse:1.74949\tval-rmse:1.75052\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.930914\tval-rmse:0.995761\n",
      "[200]\ttrain-rmse:0.888651\tval-rmse:0.992045\n",
      "Stopping. Best iteration:\n",
      "[198]\ttrain-rmse:0.888911\tval-rmse:0.991853\n",
      "\n",
      "Partial score of fold 2 is: 0.5984711169823096\n",
      "[0]\ttrain-rmse:1.74986\tval-rmse:1.75095\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.935252\tval-rmse:0.991678\n",
      "[200]\ttrain-rmse:0.890503\tval-rmse:0.986161\n",
      "Stopping. Best iteration:\n",
      "[163]\ttrain-rmse:0.905087\tval-rmse:0.985949\n",
      "\n",
      "Partial score of fold 3 is: 0.5954292315049028\n",
      "[0]\ttrain-rmse:1.75084\tval-rmse:1.74967\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.930436\tval-rmse:0.993404\n",
      "[200]\ttrain-rmse:0.885556\tval-rmse:0.989061\n",
      "[300]\ttrain-rmse:0.85494\tval-rmse:0.989043\n",
      "[400]\ttrain-rmse:0.832525\tval-rmse:0.990349\n",
      "Stopping. Best iteration:\n",
      "[331]\ttrain-rmse:0.848028\tval-rmse:0.987601\n",
      "\n",
      "Partial score of fold 4 is: 0.5900490309875659\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5901  \u001b[0m | \u001b[0m 0.7396  \u001b[0m | \u001b[0m 5.568   \u001b[0m | \u001b[0m 8.743   \u001b[0m | \u001b[0m 4.338   \u001b[0m | \u001b[0m 17.95   \u001b[0m | \u001b[0m 0.5432  \u001b[0m |\n",
      "[0]\ttrain-rmse:1.73769\tval-rmse:1.74759\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.446128\tval-rmse:1.04699\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-rmse:0.692133\tval-rmse:1.02782\n",
      "\n",
      "Partial score of fold 0 is: 0.5396016862724966\n",
      "[0]\ttrain-rmse:1.73612\tval-rmse:1.74659\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.447662\tval-rmse:1.03417\n",
      "Stopping. Best iteration:\n",
      "[38]\ttrain-rmse:0.634905\tval-rmse:1.01953\n",
      "\n",
      "Partial score of fold 1 is: 0.5431803750694457\n",
      "[0]\ttrain-rmse:1.73383\tval-rmse:1.74449\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.450649\tval-rmse:1.02821\n",
      "Stopping. Best iteration:\n",
      "[35]\ttrain-rmse:0.651874\tval-rmse:1.01442\n",
      "\n",
      "Partial score of fold 2 is: 0.55636500463822\n",
      "[0]\ttrain-rmse:1.73541\tval-rmse:1.74538\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.446582\tval-rmse:1.02516\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-rmse:0.668136\tval-rmse:1.01117\n",
      "\n",
      "Partial score of fold 3 is: 0.560537015734649\n",
      "[0]\ttrain-rmse:1.73453\tval-rmse:1.74805\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.450201\tval-rmse:1.03473\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-rmse:0.634334\tval-rmse:1.01814\n",
      "\n",
      "Partial score of fold 4 is: 0.53993496361211\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.547   \u001b[0m | \u001b[0m 0.8801  \u001b[0m | \u001b[0m 0.01235 \u001b[0m | \u001b[0m 0.787   \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 0.1102  \u001b[0m | \u001b[0m 0.4043  \u001b[0m |\n",
      "[0]\ttrain-rmse:1.76352\tval-rmse:1.76319\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01381\tval-rmse:1.03056\n",
      "[200]\ttrain-rmse:0.99578\tval-rmse:1.02027\n",
      "[300]\ttrain-rmse:0.99135\tval-rmse:1.01889\n",
      "Stopping. Best iteration:\n",
      "[293]\ttrain-rmse:0.99135\tval-rmse:1.01889\n",
      "\n",
      "Partial score of fold 0 is: 0.5537375070204457\n",
      "[0]\ttrain-rmse:1.7631\tval-rmse:1.76391\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01457\tval-rmse:1.03128\n",
      "[200]\ttrain-rmse:0.997555\tval-rmse:1.01987\n",
      "[300]\ttrain-rmse:0.99198\tval-rmse:1.01728\n",
      "[400]\ttrain-rmse:0.990816\tval-rmse:1.0166\n",
      "[500]\ttrain-rmse:0.989783\tval-rmse:1.01622\n",
      "Stopping. Best iteration:\n",
      "[489]\ttrain-rmse:0.989783\tval-rmse:1.01622\n",
      "\n",
      "Partial score of fold 1 is: 0.5716309510051912\n",
      "[0]\ttrain-rmse:1.76334\tval-rmse:1.76365\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01469\tval-rmse:1.02644\n",
      "[200]\ttrain-rmse:0.99441\tval-rmse:1.01253\n",
      "[300]\ttrain-rmse:0.993214\tval-rmse:1.01218\n",
      "[400]\ttrain-rmse:0.992642\tval-rmse:1.01205\n",
      "Stopping. Best iteration:\n",
      "[306]\ttrain-rmse:0.992853\tval-rmse:1.01202\n",
      "\n",
      "Partial score of fold 2 is: 0.5792264818029105\n",
      "[0]\ttrain-rmse:1.76314\tval-rmse:1.76384\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01607\tval-rmse:1.02221\n",
      "[200]\ttrain-rmse:0.99938\tval-rmse:1.01054\n",
      "[300]\ttrain-rmse:0.99301\tval-rmse:1.00707\n",
      "[400]\ttrain-rmse:0.991677\tval-rmse:1.00607\n",
      "[500]\ttrain-rmse:0.990104\tval-rmse:1.00554\n",
      "[600]\ttrain-rmse:0.989775\tval-rmse:1.00547\n",
      "[700]\ttrain-rmse:0.988542\tval-rmse:1.00477\n",
      "[800]\ttrain-rmse:0.988299\tval-rmse:1.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[700]\ttrain-rmse:0.988542\tval-rmse:1.00477\n",
      "\n",
      "Partial score of fold 3 is: 0.5787883285990895\n",
      "[0]\ttrain-rmse:1.76335\tval-rmse:1.76254\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01524\tval-rmse:1.02532\n",
      "[200]\ttrain-rmse:0.995878\tval-rmse:1.0127\n",
      "[300]\ttrain-rmse:0.991159\tval-rmse:1.01008\n",
      "[400]\ttrain-rmse:0.989173\tval-rmse:1.00913\n",
      "[500]\ttrain-rmse:0.988595\tval-rmse:1.00864\n",
      "Stopping. Best iteration:\n",
      "[461]\ttrain-rmse:0.988595\tval-rmse:1.00864\n",
      "\n",
      "Partial score of fold 4 is: 0.5760886836472603\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0]\ttrain-rmse:1.76426\tval-rmse:1.76445\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01374\tval-rmse:1.0306\n",
      "[200]\ttrain-rmse:0.992448\tval-rmse:1.02185\n",
      "[300]\ttrain-rmse:0.980415\tval-rmse:1.01857\n",
      "[400]\ttrain-rmse:0.972358\tval-rmse:1.01831\n",
      "Stopping. Best iteration:\n",
      "[348]\ttrain-rmse:0.976803\tval-rmse:1.01763\n",
      "\n",
      "Partial score of fold 0 is: 0.5608948846143439\n",
      "[0]\ttrain-rmse:1.76283\tval-rmse:1.76383\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01548\tval-rmse:1.03347\n",
      "[200]\ttrain-rmse:0.992426\tval-rmse:1.01995\n",
      "[300]\ttrain-rmse:0.980172\tval-rmse:1.01489\n",
      "[400]\ttrain-rmse:0.973366\tval-rmse:1.01336\n",
      "[500]\ttrain-rmse:0.966945\tval-rmse:1.01157\n",
      "[600]\ttrain-rmse:0.96289\tval-rmse:1.01052\n",
      "[700]\ttrain-rmse:0.959576\tval-rmse:1.00988\n",
      "[800]\ttrain-rmse:0.956152\tval-rmse:1.00962\n",
      "[900]\ttrain-rmse:0.952369\tval-rmse:1.00902\n",
      "[1000]\ttrain-rmse:0.949333\tval-rmse:1.00843\n",
      "Stopping. Best iteration:\n",
      "[989]\ttrain-rmse:0.949581\tval-rmse:1.00775\n",
      "\n",
      "Partial score of fold 1 is: 0.584514230674208\n",
      "[0]\ttrain-rmse:1.76234\tval-rmse:1.76262\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01477\tval-rmse:1.03061\n",
      "[200]\ttrain-rmse:0.991174\tval-rmse:1.0203\n",
      "[300]\ttrain-rmse:0.979835\tval-rmse:1.01639\n",
      "[400]\ttrain-rmse:0.972874\tval-rmse:1.01422\n",
      "[500]\ttrain-rmse:0.965987\tval-rmse:1.0118\n",
      "[600]\ttrain-rmse:0.960732\tval-rmse:1.01209\n",
      "Stopping. Best iteration:\n",
      "[552]\ttrain-rmse:0.962542\tval-rmse:1.01123\n",
      "\n",
      "Partial score of fold 2 is: 0.5809355418772589\n",
      "[0]\ttrain-rmse:1.76326\tval-rmse:1.76382\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.02052\tval-rmse:1.02971\n",
      "[200]\ttrain-rmse:0.996324\tval-rmse:1.01249\n",
      "[300]\ttrain-rmse:0.982112\tval-rmse:1.00346\n",
      "[400]\ttrain-rmse:0.975924\tval-rmse:1.0013\n",
      "[500]\ttrain-rmse:0.969817\tval-rmse:0.999385\n",
      "[600]\ttrain-rmse:0.965232\tval-rmse:0.998083\n",
      "[700]\ttrain-rmse:0.959821\tval-rmse:0.99593\n",
      "Stopping. Best iteration:\n",
      "[691]\ttrain-rmse:0.960253\tval-rmse:0.995483\n",
      "\n",
      "Partial score of fold 3 is: 0.5852299684335979\n",
      "[0]\ttrain-rmse:1.76301\tval-rmse:1.76205\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01766\tval-rmse:1.02739\n",
      "[200]\ttrain-rmse:0.994239\tval-rmse:1.01348\n",
      "[300]\ttrain-rmse:0.98239\tval-rmse:1.01064\n",
      "[400]\ttrain-rmse:0.976028\tval-rmse:1.00886\n",
      "[500]\ttrain-rmse:0.969525\tval-rmse:1.00625\n",
      "Stopping. Best iteration:\n",
      "[445]\ttrain-rmse:0.97221\tval-rmse:1.00536\n",
      "\n",
      "Partial score of fold 4 is: 0.5753727683990395\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5775  \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.4     \u001b[0m |\n",
      "[0]\ttrain-rmse:1.73329\tval-rmse:1.74004\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.81076\tval-rmse:0.996782\n",
      "Stopping. Best iteration:\n",
      "[45]\ttrain-rmse:0.810835\tval-rmse:0.996725\n",
      "\n",
      "Partial score of fold 0 is: 0.5728834920841235\n",
      "[0]\ttrain-rmse:1.73302\tval-rmse:1.74112\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.798208\tval-rmse:0.999068\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-rmse:0.798208\tval-rmse:0.999068\n",
      "\n",
      "Partial score of fold 1 is: 0.580577672997564\n",
      "[0]\ttrain-rmse:1.73495\tval-rmse:1.74338\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.804095\tval-rmse:0.993349\n",
      "Stopping. Best iteration:\n",
      "[62]\ttrain-rmse:0.804097\tval-rmse:0.993349\n",
      "\n",
      "Partial score of fold 2 is: 0.5873771817117673\n",
      "[0]\ttrain-rmse:1.73311\tval-rmse:1.74057\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.813615\tval-rmse:0.987244\n",
      "Stopping. Best iteration:\n",
      "[50]\ttrain-rmse:0.813641\tval-rmse:0.987227\n",
      "\n",
      "Partial score of fold 3 is: 0.584872099553903\n",
      "[0]\ttrain-rmse:1.73239\tval-rmse:1.74037\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.802268\tval-rmse:0.986357\n",
      "Stopping. Best iteration:\n",
      "[83]\ttrain-rmse:0.802269\tval-rmse:0.986357\n",
      "\n",
      "Partial score of fold 4 is: 0.5916598402960627\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5834  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "[0]\ttrain-rmse:1.74375\tval-rmse:1.74968\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.840268\tval-rmse:1.00767\n",
      "[200]\ttrain-rmse:0.817417\tval-rmse:1.00855\n",
      "Stopping. Best iteration:\n",
      "[161]\ttrain-rmse:0.825914\tval-rmse:1.00559\n",
      "\n",
      "Partial score of fold 0 is: 0.5701994754864116\n",
      "[0]\ttrain-rmse:1.74045\tval-rmse:1.7473\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.836789\tval-rmse:1.00762\n",
      "Stopping. Best iteration:\n",
      "[60]\ttrain-rmse:0.852987\tval-rmse:1.00565\n",
      "\n",
      "Partial score of fold 1 is: 0.5834406240351233\n",
      "[0]\ttrain-rmse:1.7387\tval-rmse:1.74491\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.84325\tval-rmse:0.999765\n",
      "[200]\ttrain-rmse:0.820428\tval-rmse:0.998826\n",
      "Stopping. Best iteration:\n",
      "[160]\ttrain-rmse:0.82794\tval-rmse:0.997442\n",
      "\n",
      "Partial score of fold 2 is: 0.5830827551554284\n",
      "[0]\ttrain-rmse:1.74022\tval-rmse:1.74417\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.843376\tval-rmse:0.988626\n",
      "[200]\ttrain-rmse:0.822321\tval-rmse:0.987354\n",
      "[300]\ttrain-rmse:0.811227\tval-rmse:0.98745\n",
      "Stopping. Best iteration:\n",
      "[255]\ttrain-rmse:0.814657\tval-rmse:0.986315\n",
      "\n",
      "Partial score of fold 3 is: 0.594355624865818\n",
      "[0]\ttrain-rmse:1.7397\tval-rmse:1.74472\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.841178\tval-rmse:0.992179\n",
      "[200]\ttrain-rmse:0.817402\tval-rmse:0.991268\n",
      "[300]\ttrain-rmse:0.806918\tval-rmse:0.991568\n",
      "Stopping. Best iteration:\n",
      "[204]\ttrain-rmse:0.816248\tval-rmse:0.990902\n",
      "\n",
      "Partial score of fold 4 is: 0.5880802640549587\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5843  \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 5.431   \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 6.177   \u001b[0m | \u001b[0m 0.4     \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comment out any parameter you don't want to test\n",
    "def XGB_CV(\n",
    "          max_depth,\n",
    "          gamma,\n",
    "          min_child_weight,\n",
    "          max_delta_step,\n",
    "          subsample,\n",
    "          colsample_bytree,\n",
    "          target='accuracy_group',\n",
    "          verbosity=100\n",
    "         ):\n",
    "\n",
    "    train_df = reduce_train\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    \n",
    "    cv = folds.split(reduce_train, reduce_train[target])\n",
    "    \n",
    "    params = {\n",
    "      'booster' : 'gbtree',\n",
    "      'max_depth' : int(max_depth),\n",
    "      'gamma' : gamma,\n",
    "      'eta' : 0.1,\n",
    "      'nthread' : 4,\n",
    "      'silent' : True,\n",
    "#       'eval_metric': 'auc',\n",
    "      'subsample' : max(min(subsample, 1), 0),\n",
    "      'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "      'min_child_weight' : min_child_weight,\n",
    "      'max_delta_step' : int(max_delta_step),\n",
    "      'seed' : 1001,\n",
    "      'objective':'reg:squarederror',\n",
    "    }\n",
    "    \n",
    "    \n",
    "    oof_pred = np.zeros(train_df.shape[0])\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "        \n",
    "        x_train, x_val = train_df[features].iloc[train_idx], train_df[features].iloc[val_idx]   \n",
    "        y_train, y_val = train_df[target][train_idx], train_df[target][val_idx]\n",
    "\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        \n",
    "        clf = xgb.train(params, \n",
    "                         train_set, \n",
    "                         num_boost_round=5000, \n",
    "                         evals=[(train_set, 'train'), \n",
    "                                (val_set, 'val')], \n",
    "                         verbose_eval=verbosity,\n",
    "                         early_stopping_rounds=100)\n",
    "        \n",
    "        oof_pred[val_idx] = clf.predict(xgb.DMatrix(train_df.iloc[val_idx][features]))\n",
    "\n",
    "        print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        \n",
    "        del clf, train_idx, val_idx\n",
    "        gc.collect()\n",
    "    _, loss_score, _ = eval_qwk_lgb_regr(train_df[target], oof_pred)    \n",
    "#     return -mean_squared_error(oof, target)**0.5\n",
    "    return loss_score\n",
    "\n",
    "    \n",
    "XGB_BO = BayesianOptimization(XGB_CV, {\n",
    "                                     'max_depth': (2, 12),\n",
    "                                     'gamma': (0.001, 10.0),\n",
    "                                     'min_child_weight': (0, 20),\n",
    "                                     'max_delta_step': (0, 10),\n",
    "                                     'subsample': (0.4, 1.0),\n",
    "                                     'colsample_bytree' :(0.4, 1.0)\n",
    "                                    })\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    XGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Final Results\n",
      "Maximum  value: 0.592347\n",
      "Best  parameters: {'colsample_bytree': 0.5718422563102614, 'gamma': 9.121035497281943, 'max_delta_step': 1.070668157937703, 'max_depth': 8.29419083806185, 'min_child_weight': 0.6493316414338923, 'subsample': 0.6592648167510096}\n"
     ]
    }
   ],
   "source": [
    "print('-'*130)\n",
    "print('Final Results')\n",
    "print('Maximum  value: %f' % XGB_BO.max['target'])\n",
    "print('Best  parameters:', XGB_BO.max['params'])\n",
    "\n",
    "\n",
    "\n",
    "if LGB_BO.max['target'] > 0.592347:\n",
    "    XGB_params = XGB_BO.max['params']\n",
    "else:\n",
    "    XGB_params = {\n",
    "    'colsample_bytree': 0.5718422563102614,\n",
    "    'gamma': 9.121035497281943,\n",
    "    'max_delta_step': 1.070668157937703, \n",
    "    'max_depth': 8.29419083806185, \n",
    "    'min_child_weight': 0.6493316414338923,\n",
    "    'subsample': 0.6592648167510096}\n",
    "    \n",
    "# Maximum  value: 0.592347   # 0.538\n",
    "# Best  parameters: {\n",
    "#     'colsample_bytree': 0.5718422563102614,\n",
    "#     'gamma': 9.121035497281943,\n",
    "#     'max_delta_step': 1.070668157937703, \n",
    "#     'max_depth': 8.29419083806185, \n",
    "#     'min_child_weight': 0.6493316414338923,\n",
    "#     'subsample': 0.6592648167510096}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   depth   | l2_lea... | learni... |\n",
      "-------------------------------------------------------------------------\n",
      "0:\tlearn: 1.2440304\ttest: 1.2447129\tbest: 1.2447129 (0)\ttotal: 46.6ms\tremaining: 1m 33s\n",
      "100:\tlearn: 0.9845430\ttest: 1.0193443\tbest: 1.0193443 (100)\ttotal: 3.31s\tremaining: 1m 2s\n",
      "200:\tlearn: 0.9511248\ttest: 1.0068062\tbest: 1.0068062 (200)\ttotal: 6.54s\tremaining: 58.5s\n",
      "300:\tlearn: 0.9267576\ttest: 1.0025797\tbest: 1.0025749 (299)\ttotal: 9.74s\tremaining: 55s\n",
      "400:\tlearn: 0.9080314\ttest: 1.0011230\tbest: 1.0011038 (381)\ttotal: 12.9s\tremaining: 51.5s\n",
      "500:\tlearn: 0.8888687\ttest: 1.0000323\tbest: 1.0000122 (499)\ttotal: 16.1s\tremaining: 48.2s\n",
      "600:\tlearn: 0.8701528\ttest: 0.9998173\tbest: 0.9992552 (525)\ttotal: 19.3s\tremaining: 44.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9992552246\n",
      "bestIteration = 525\n",
      "\n",
      "Shrink model to first 526 iterations.\n",
      "Partial score of fold 0 is: 0.5714520165653438\n",
      "0:\tlearn: 1.2442991\ttest: 1.2446638\tbest: 1.2446638 (0)\ttotal: 32.4ms\tremaining: 1m 4s\n",
      "100:\tlearn: 0.9895175\ttest: 1.0166727\tbest: 1.0166727 (100)\ttotal: 3.24s\tremaining: 1m\n",
      "200:\tlearn: 0.9554871\ttest: 1.0033288\tbest: 1.0033288 (200)\ttotal: 6.51s\tremaining: 58.2s\n",
      "300:\tlearn: 0.9325429\ttest: 0.9973650\tbest: 0.9973650 (300)\ttotal: 9.71s\tremaining: 54.8s\n",
      "400:\tlearn: 0.9108396\ttest: 0.9944790\tbest: 0.9943915 (391)\ttotal: 12.9s\tremaining: 51.5s\n",
      "500:\tlearn: 0.8915546\ttest: 0.9931936\tbest: 0.9931936 (500)\ttotal: 16.1s\tremaining: 48.2s\n",
      "600:\tlearn: 0.8713023\ttest: 0.9921005\tbest: 0.9921005 (600)\ttotal: 19.3s\tremaining: 44.9s\n",
      "700:\tlearn: 0.8536997\ttest: 0.9923967\tbest: 0.9920895 (603)\ttotal: 22.5s\tremaining: 41.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9920895093\n",
      "bestIteration = 603\n",
      "\n",
      "Shrink model to first 604 iterations.\n",
      "Partial score of fold 1 is: 0.5868403783922249\n",
      "0:\tlearn: 1.2436879\ttest: 1.2440691\tbest: 1.2440691 (0)\ttotal: 31.9ms\tremaining: 1m 3s\n",
      "100:\tlearn: 0.9893302\ttest: 1.0097920\tbest: 1.0097920 (100)\ttotal: 3.25s\tremaining: 1m 1s\n",
      "200:\tlearn: 0.9559206\ttest: 0.9947081\tbest: 0.9947081 (200)\ttotal: 6.48s\tremaining: 58s\n",
      "300:\tlearn: 0.9297231\ttest: 0.9880966\tbest: 0.9880953 (299)\ttotal: 9.7s\tremaining: 54.8s\n",
      "400:\tlearn: 0.9085728\ttest: 0.9850585\tbest: 0.9850585 (400)\ttotal: 12.9s\tremaining: 51.4s\n",
      "500:\tlearn: 0.8888496\ttest: 0.9833174\tbest: 0.9832966 (499)\ttotal: 16.1s\tremaining: 48.2s\n",
      "600:\tlearn: 0.8701940\ttest: 0.9816713\tbest: 0.9816713 (600)\ttotal: 19.3s\tremaining: 44.9s\n",
      "700:\tlearn: 0.8528444\ttest: 0.9809832\tbest: 0.9809567 (689)\ttotal: 22.5s\tremaining: 41.7s\n",
      "800:\tlearn: 0.8370603\ttest: 0.9805031\tbest: 0.9804505 (795)\ttotal: 25.7s\tremaining: 38.5s\n",
      "900:\tlearn: 0.8211235\ttest: 0.9802890\tbest: 0.9799634 (868)\ttotal: 28.9s\tremaining: 35.3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9799634234\n",
      "bestIteration = 868\n",
      "\n",
      "Shrink model to first 869 iterations.\n",
      "Partial score of fold 2 is: 0.6058074290160552\n",
      "0:\tlearn: 1.2440397\ttest: 1.2438683\tbest: 1.2438683 (0)\ttotal: 31.6ms\tremaining: 1m 3s\n",
      "100:\tlearn: 0.9907272\ttest: 1.0034168\tbest: 1.0034168 (100)\ttotal: 3.23s\tremaining: 1m\n",
      "200:\tlearn: 0.9552009\ttest: 0.9881650\tbest: 0.9881650 (200)\ttotal: 6.46s\tremaining: 57.8s\n",
      "300:\tlearn: 0.9305896\ttest: 0.9821240\tbest: 0.9821240 (300)\ttotal: 9.69s\tremaining: 54.7s\n",
      "400:\tlearn: 0.9109013\ttest: 0.9789758\tbest: 0.9789758 (400)\ttotal: 12.9s\tremaining: 51.3s\n",
      "500:\tlearn: 0.8928147\ttest: 0.9767121\tbest: 0.9767121 (500)\ttotal: 16.1s\tremaining: 48s\n",
      "600:\tlearn: 0.8757790\ttest: 0.9758511\tbest: 0.9758421 (591)\ttotal: 19.2s\tremaining: 44.8s\n",
      "700:\tlearn: 0.8611663\ttest: 0.9755420\tbest: 0.9754298 (688)\ttotal: 22.4s\tremaining: 41.5s\n",
      "800:\tlearn: 0.8472280\ttest: 0.9749985\tbest: 0.9749180 (798)\ttotal: 25.6s\tremaining: 38.3s\n",
      "900:\tlearn: 0.8327582\ttest: 0.9747886\tbest: 0.9745529 (864)\ttotal: 28.8s\tremaining: 35.1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9745529336\n",
      "bestIteration = 864\n",
      "\n",
      "Shrink model to first 865 iterations.\n",
      "Partial score of fold 3 is: 0.598650051422157\n",
      "0:\tlearn: 1.2443927\ttest: 1.2437981\tbest: 1.2437981 (0)\ttotal: 31.4ms\tremaining: 1m 2s\n",
      "100:\tlearn: 0.9890298\ttest: 1.0055152\tbest: 1.0055152 (100)\ttotal: 3.23s\tremaining: 1m\n",
      "200:\tlearn: 0.9551719\ttest: 0.9924450\tbest: 0.9924450 (200)\ttotal: 6.44s\tremaining: 57.6s\n",
      "300:\tlearn: 0.9309478\ttest: 0.9880165\tbest: 0.9880165 (300)\ttotal: 9.66s\tremaining: 54.5s\n",
      "400:\tlearn: 0.9089570\ttest: 0.9859528\tbest: 0.9859055 (397)\ttotal: 12.8s\tremaining: 51.2s\n",
      "500:\tlearn: 0.8904371\ttest: 0.9848226\tbest: 0.9848072 (498)\ttotal: 16s\tremaining: 48s\n",
      "600:\tlearn: 0.8722057\ttest: 0.9840306\tbest: 0.9839406 (575)\ttotal: 19.2s\tremaining: 44.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9839406493\n",
      "bestIteration = 575\n",
      "\n",
      "Shrink model to first 576 iterations.\n",
      "Partial score of fold 4 is: 0.5920177979201731\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5905  \u001b[0m | \u001b[0m 0.793   \u001b[0m | \u001b[0m 8.19    \u001b[0m | \u001b[0m 17.7    \u001b[0m | \u001b[0m 0.03873 \u001b[0m |\n",
      "0:\tlearn: 1.2312263\ttest: 1.2321526\tbest: 1.2321526 (0)\ttotal: 211ms\tremaining: 7m 2s\n",
      "100:\tlearn: 0.9148590\ttest: 1.0093282\tbest: 1.0093282 (100)\ttotal: 18.4s\tremaining: 5m 46s\n",
      "200:\tlearn: 0.8293166\ttest: 1.0021434\tbest: 1.0020119 (189)\ttotal: 36.7s\tremaining: 5m 28s\n",
      "300:\tlearn: 0.7783548\ttest: 1.0024371\tbest: 1.0015155 (234)\ttotal: 55s\tremaining: 5m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.001515544\n",
      "bestIteration = 234\n",
      "\n",
      "Shrink model to first 235 iterations.\n",
      "Partial score of fold 0 is: 0.5730624265239709\n",
      "0:\tlearn: 1.2313695\ttest: 1.2328652\tbest: 1.2328652 (0)\ttotal: 186ms\tremaining: 6m 12s\n",
      "100:\tlearn: 0.9110606\ttest: 1.0016364\tbest: 1.0016364 (100)\ttotal: 18.2s\tremaining: 5m 42s\n",
      "200:\tlearn: 0.8307138\ttest: 0.9946782\tbest: 0.9946782 (200)\ttotal: 36.4s\tremaining: 5m 25s\n",
      "300:\tlearn: 0.7834011\ttest: 0.9935388\tbest: 0.9935388 (300)\ttotal: 54.4s\tremaining: 5m 7s\n",
      "400:\tlearn: 0.7365368\ttest: 0.9941862\tbest: 0.9929487 (335)\ttotal: 1m 12s\tremaining: 4m 49s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9929486813\n",
      "bestIteration = 335\n",
      "\n",
      "Shrink model to first 336 iterations.\n",
      "Partial score of fold 1 is: 0.5889875916703944\n",
      "0:\tlearn: 1.2318837\ttest: 1.2329195\tbest: 1.2329195 (0)\ttotal: 181ms\tremaining: 6m 2s\n",
      "100:\tlearn: 0.9159541\ttest: 0.9953710\tbest: 0.9953710 (100)\ttotal: 18.3s\tremaining: 5m 44s\n",
      "200:\tlearn: 0.8412504\ttest: 0.9868436\tbest: 0.9868436 (200)\ttotal: 36.5s\tremaining: 5m 26s\n",
      "300:\tlearn: 0.7842450\ttest: 0.9842205\tbest: 0.9839782 (283)\ttotal: 54.7s\tremaining: 5m 8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.983978178\n",
      "bestIteration = 283\n",
      "\n",
      "Shrink model to first 284 iterations.\n",
      "Partial score of fold 2 is: 0.6015130024597163\n",
      "0:\tlearn: 1.2322129\ttest: 1.2321473\tbest: 1.2321473 (0)\ttotal: 180ms\tremaining: 6m\n",
      "100:\tlearn: 0.9173949\ttest: 0.9889748\tbest: 0.9889748 (100)\ttotal: 18.5s\tremaining: 5m 47s\n"
     ]
    }
   ],
   "source": [
    "def Cat_CV(\n",
    "        depth,\n",
    "        colsample_bylevel,\n",
    "        l2_leaf_reg,\n",
    "        learning_rate,\n",
    "        target='accuracy_group',\n",
    "        verbosity=100\n",
    "        ):\n",
    "\n",
    "    train_df = reduce_train\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    \n",
    "    cv = folds.split(reduce_train, reduce_train[target])\n",
    "    \n",
    "    params = {        \n",
    "        'loss_function': 'RMSE',\n",
    "        'task_type': \"CPU\",\n",
    "        'early_stopping_rounds': 100,\n",
    "        'random_seed': 42,\n",
    "        'use_best_model': True,\n",
    "        'depth': int(depth),\n",
    "        'colsample_bylevel': colsample_bylevel, \n",
    "        'l2_leaf_reg': l2_leaf_reg,\n",
    "        'learning_rate': learning_rate,\n",
    "        'iterations': 2000,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    oof_pred = np.zeros(train_df.shape[0])\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv):\n",
    "        \n",
    "        x_train, x_val = train_df[features].iloc[train_idx], train_df[features].iloc[val_idx]   \n",
    "        y_train, y_val = train_df[target][train_idx], train_df[target][val_idx]\n",
    "        \n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        \n",
    "        clf = CatBoostRegressor(**params)\n",
    "        clf.fit(x_train, \n",
    "                y_train, \n",
    "                eval_set=(x_val, y_val),\n",
    "                verbose=verbosity, \n",
    "                cat_features=categoricals)\n",
    "        \n",
    "        oof_pred[val_idx] = clf.predict(x_val)\n",
    "\n",
    "        print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        \n",
    "        del clf, train_idx, val_idx\n",
    "        gc.collect()\n",
    "    _, loss_score, _ = eval_qwk_lgb_regr(train_df[target], oof_pred)    \n",
    "    return loss_score\n",
    "\n",
    "    \n",
    "Cat_BO = BayesianOptimization(Cat_CV, {\n",
    "                                    'depth': (5, 15),\n",
    "                                    'colsample_bylevel': (0.4, 1.0), \n",
    "                                    'l2_leaf_reg': (10,30),\n",
    "                                    'learning_rate': (0.001, 0.1)\n",
    "                                    })\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    Cat_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*130)\n",
    "print('Final Results')\n",
    "print('Maximum  value: %f' % Cat_BO.max['target'])\n",
    "print('Best  parameters:', Cat_BO.max['params'])\n",
    "\n",
    "# if Cat_BO.max['target'] > 0.592347:\n",
    "#     Cat_params = Cat_BO.max['params']\n",
    "# else:\n",
    "#     Cat_params = {\n",
    "#     'colsample_bytree': 0.5718422563102614,\n",
    "#     'gamma': 9.121035497281943,\n",
    "#     'max_delta_step': 1.070668157937703, \n",
    "#     'max_depth': 8.29419083806185, \n",
    "#     'min_child_weight': 0.6493316414338923,\n",
    "#     'subsample': 0.6592648167510096}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True, params=None):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params(params)\n",
    "        self.y_pred, self.oof_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "#         cv = GroupKFold(n_splits=self.n_splits)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self, params):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(reduce_train), ))\n",
    "        y_pred = np.zeros((len(reduce_test), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            # 相当于降维\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]   \n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            # 针对不同模型处理数据\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            # 针对不同模型训练数据\n",
    "            model = self.train_model(train_set, val_set) \n",
    "            # 得到验证数据的预测值\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            # 得到测试数据的预测值\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof cohen kappa score is: ', loss_score)\n",
    "        return y_pred, oof_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self, params=None):\n",
    "        if params is None :\n",
    "            default_params = {\n",
    "                'n_estimators':2000,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'n_jobs': -1,\n",
    "                'eval_metric': 'cappa',\n",
    "                'subsample': 0.75,\n",
    "                'subsample_freq': 1,\n",
    "                'learning_rate': 0.01,\n",
    "                'feature_fraction': 0.9,\n",
    "                'max_depth': 15,\n",
    "                'lambda_l1': 1,  \n",
    "                'lambda_l2': 1,\n",
    "                'early_stopping_rounds': 100}\n",
    "        else:\n",
    "            default_params = {\n",
    "                \"bagging_seed\": 11,\n",
    "                'verbose': 100,\n",
    "                \"verbosity\": -1,\n",
    "                'seed': 42,\n",
    "                'n_estimators':2000,\n",
    "                'subsample': 0.75,\n",
    "                'subsample_freq': 1,\n",
    "                'n_jobs': -1,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'early_stopping_rounds': 100,\n",
    "                'eval_metric': 'cappa',\n",
    "                'learning_rate': params['learning_rate'],\n",
    "#                 'feature_fraction': params['feature_fraction'],\n",
    "                'colsample_bytree': params['colsample_bytree'], \n",
    "                'bagging_fraction': params['bagging_fraction'],\n",
    "                'bagging_freq': int(params['bagging_freq']),\n",
    "                'max_depth': int(params['max_depth']),\n",
    "                'lambda_l1': params['lambda_l1'],  \n",
    "                'lambda_l2': params['lambda_l2']}\n",
    "        return default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, \n",
    "                         train_set, \n",
    "                         num_boost_round=5000, \n",
    "                         evals=[(train_set, 'train'), \n",
    "                                (val_set, 'val')], \n",
    "                         verbose_eval=verbosity,\n",
    "                         early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self, params=None):\n",
    "        if params is None :\n",
    "            default_params = {\n",
    "                      'colsample_bytree': 0.8,                 \n",
    "                      'learning_rate': 0.01,\n",
    "                      'max_depth': 10,\n",
    "                      'subsample': 1,\n",
    "                      'objective':'reg:squarederror',\n",
    "                      #'eval_metric':'rmse',\n",
    "                      'min_child_weight':3,\n",
    "                      'gamma':0.25,\n",
    "                      'n_estimators':2000}\n",
    "        else:\n",
    "            default_params = {\n",
    "                  'colsample_bytree': params['colsample_bytree'],                 \n",
    "                  'learning_rate': 0.01,\n",
    "                  'max_depth': int(params['max_depth']),\n",
    "                  'subsample': params['subsample'],\n",
    "                  'objective':'reg:squarederror',\n",
    "                  #'eval_metric':'rmse',\n",
    "                  'min_child_weight':params['min_child_weight'],\n",
    "                  'gamma': params['gamma'],\n",
    "                  'n_estimators':2000,\n",
    "                  'max_delta_step': params['max_delta_step']}\n",
    "        return default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catb_Model(Base_Model):\n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        clf = CatBoostRegressor(**self.params)\n",
    "        clf.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                eval_set=(val_set['X'], val_set['y']),\n",
    "                verbose=verbosity, \n",
    "                cat_features=self.categoricals)\n",
    "        return clf\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self, params=None):\n",
    "        if params is None :\n",
    "            default_params = {\n",
    "                    'loss_function': 'RMSE',\n",
    "                    'task_type': \"CPU\",\n",
    "                    'iterations': 2000,\n",
    "                    'od_type': \"Iter\",\n",
    "                    'depth': 10,\n",
    "                    'colsample_bylevel': 0.5, \n",
    "                    'early_stopping_rounds': 300,\n",
    "                    'l2_leaf_reg': 18,\n",
    "                    'random_seed': 42,\n",
    "                    'use_best_model': True}\n",
    "        else:\n",
    "            default_params = {\n",
    "                    'loss_function': 'RMSE',\n",
    "                    'task_type': \"CPU\",\n",
    "                    'iterations': 2000,\n",
    "                    'od_type': \"Iter\",\n",
    "                    'depth': int(params['depth']),\n",
    "                    'early_stopping_rounds': 300,\n",
    "                    'colsample_bylevel': params['min_child_weight'], \n",
    "                    'l2_leaf_reg': params['l2_leaf_reg'],\n",
    "                    'learning_rate': parmas['learning_rate'],\n",
    "                    'random_seed': 42,\n",
    "                    'use_best_model': True}\n",
    "        return default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "class Nn_Model(Base_Model):\n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        print(train_df[features].shape)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(train_set['X'].shape[1],)),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(100, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(25, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1, activation='relu')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class Cnn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        self.create_feat_2d(features)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def create_feat_2d(self, features, n_feats_repeat=50):\n",
    "        self.n_feats = len(features)\n",
    "        self.n_feats_repeat = n_feats_repeat\n",
    "        self.mask = np.zeros((self.n_feats_repeat, self.n_feats), dtype=np.int32)\n",
    "        for i in range(self.n_feats_repeat):\n",
    "            l = list(range(self.n_feats))\n",
    "            for j in range(self.n_feats):\n",
    "                c = l.pop(choice(range(len(l))))\n",
    "                self.mask[i, j] = c\n",
    "        self.mask = tf.convert_to_tensor(self.mask)\n",
    "        print(self.mask.shape)\n",
    "       \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "\n",
    "        inp = tf.keras.layers.Input(shape=(self.n_feats))\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.gather(x, self.mask, axis=1))(inp)\n",
    "        x = tf.keras.layers.Reshape((self.n_feats_repeat, self.n_feats, 1))(x)\n",
    "        x = tf.keras.layers.Conv2D(18, (50, 50), strides=50, activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        #x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "        #x = tf.keras.layers.LayerNormalization()(x)\n",
    "        #x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        out = tf.keras.layers.Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inp, out)\n",
    "    \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2466972\ttest: 1.2472652\tbest: 1.2472652 (0)\ttotal: 228ms\tremaining: 7m 35s\n",
      "100:\tlearn: 0.9868761\ttest: 1.0291019\tbest: 1.0291019 (100)\ttotal: 9.05s\tremaining: 2m 50s\n",
      "200:\tlearn: 0.9401990\ttest: 1.0103550\tbest: 1.0103550 (200)\ttotal: 17.1s\tremaining: 2m 33s\n",
      "300:\tlearn: 0.9073364\ttest: 1.0036652\tbest: 1.0036652 (300)\ttotal: 25.6s\tremaining: 2m 24s\n",
      "400:\tlearn: 0.8743469\ttest: 0.9994654\tbest: 0.9994152 (398)\ttotal: 33.7s\tremaining: 2m 14s\n",
      "500:\tlearn: 0.8497647\ttest: 0.9975701\tbest: 0.9975701 (500)\ttotal: 41s\tremaining: 2m 2s\n",
      "600:\tlearn: 0.8289466\ttest: 0.9969782\tbest: 0.9967539 (589)\ttotal: 48.4s\tremaining: 1m 52s\n",
      "700:\tlearn: 0.8113833\ttest: 0.9969201\tbest: 0.9967539 (589)\ttotal: 56.5s\tremaining: 1m 44s\n",
      "800:\tlearn: 0.7925582\ttest: 0.9966511\tbest: 0.9966210 (789)\ttotal: 1m 3s\tremaining: 1m 35s\n",
      "900:\tlearn: 0.7745141\ttest: 0.9963527\tbest: 0.9962399 (889)\ttotal: 1m 11s\tremaining: 1m 27s\n",
      "1000:\tlearn: 0.7580732\ttest: 0.9961782\tbest: 0.9960776 (951)\ttotal: 1m 19s\tremaining: 1m 19s\n",
      "1100:\tlearn: 0.7435788\ttest: 0.9963758\tbest: 0.9960137 (1033)\ttotal: 1m 27s\tremaining: 1m 11s\n",
      "1200:\tlearn: 0.7285905\ttest: 0.9967187\tbest: 0.9960137 (1033)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "1300:\tlearn: 0.7147620\ttest: 0.9975642\tbest: 0.9960137 (1033)\ttotal: 1m 43s\tremaining: 55.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.9960137315\n",
      "bestIteration = 1033\n",
      "\n",
      "Shrink model to first 1034 iterations.\n",
      "Partial score of fold 0 is: 0.5787883285990895\n",
      "0:\tlearn: 1.2474257\ttest: 1.2476156\tbest: 1.2476156 (0)\ttotal: 93.4ms\tremaining: 3m 6s\n",
      "100:\tlearn: 0.9903183\ttest: 1.0188392\tbest: 1.0188392 (100)\ttotal: 10.7s\tremaining: 3m 21s\n",
      "200:\tlearn: 0.9423347\ttest: 0.9983143\tbest: 0.9983143 (200)\ttotal: 21.3s\tremaining: 3m 10s\n",
      "300:\tlearn: 0.9114995\ttest: 0.9916397\tbest: 0.9916397 (300)\ttotal: 32.1s\tremaining: 3m 1s\n",
      "400:\tlearn: 0.8817354\ttest: 0.9869477\tbest: 0.9869149 (399)\ttotal: 44.2s\tremaining: 2m 56s\n",
      "500:\tlearn: 0.8601952\ttest: 0.9847239\tbest: 0.9846851 (499)\ttotal: 57.7s\tremaining: 2m 52s\n",
      "600:\tlearn: 0.8388945\ttest: 0.9834758\tbest: 0.9834151 (593)\ttotal: 1m 10s\tremaining: 2m 43s\n",
      "700:\tlearn: 0.8200719\ttest: 0.9828901\tbest: 0.9828867 (697)\ttotal: 1m 18s\tremaining: 2m 26s\n",
      "800:\tlearn: 0.8016068\ttest: 0.9824786\tbest: 0.9823654 (795)\ttotal: 1m 27s\tremaining: 2m 10s\n",
      "900:\tlearn: 0.7854361\ttest: 0.9819293\tbest: 0.9818909 (894)\ttotal: 1m 37s\tremaining: 1m 58s\n",
      "1000:\tlearn: 0.7674218\ttest: 0.9820398\tbest: 0.9818312 (946)\ttotal: 1m 46s\tremaining: 1m 46s\n",
      "1100:\tlearn: 0.7520612\ttest: 0.9825269\tbest: 0.9818312 (946)\ttotal: 1m 57s\tremaining: 1m 35s\n",
      "1200:\tlearn: 0.7369786\ttest: 0.9825842\tbest: 0.9818312 (946)\ttotal: 2m 6s\tremaining: 1m 24s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.9818312036\n",
      "bestIteration = 946\n",
      "\n",
      "Shrink model to first 947 iterations.\n",
      "Partial score of fold 1 is: 0.594713493745513\n",
      "0:\tlearn: 1.2478014\ttest: 1.2484916\tbest: 1.2484916 (0)\ttotal: 64.4ms\tremaining: 2m 8s\n",
      "100:\tlearn: 0.9877737\ttest: 1.0277956\tbest: 1.0277956 (100)\ttotal: 8.15s\tremaining: 2m 33s\n",
      "200:\tlearn: 0.9436335\ttest: 1.0077206\tbest: 1.0077206 (200)\ttotal: 15.6s\tremaining: 2m 19s\n",
      "300:\tlearn: 0.9124896\ttest: 0.9995822\tbest: 0.9995822 (300)\ttotal: 23.6s\tremaining: 2m 13s\n",
      "400:\tlearn: 0.8822889\ttest: 0.9939004\tbest: 0.9939004 (400)\ttotal: 31.1s\tremaining: 2m 4s\n",
      "500:\tlearn: 0.8551879\ttest: 0.9913451\tbest: 0.9912755 (496)\ttotal: 38.4s\tremaining: 1m 54s\n",
      "600:\tlearn: 0.8365599\ttest: 0.9900943\tbest: 0.9900943 (600)\ttotal: 45.8s\tremaining: 1m 46s\n",
      "700:\tlearn: 0.8141519\ttest: 0.9892871\tbest: 0.9892217 (695)\ttotal: 53.5s\tremaining: 1m 39s\n",
      "800:\tlearn: 0.7989507\ttest: 0.9885389\tbest: 0.9885389 (800)\ttotal: 1m\tremaining: 1m 30s\n",
      "900:\tlearn: 0.7821195\ttest: 0.9885459\tbest: 0.9883701 (820)\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "1000:\tlearn: 0.7667646\ttest: 0.9882161\tbest: 0.9881959 (983)\ttotal: 1m 15s\tremaining: 1m 15s\n",
      "1100:\tlearn: 0.7531612\ttest: 0.9877186\tbest: 0.9877186 (1100)\ttotal: 1m 23s\tremaining: 1m 7s\n",
      "1200:\tlearn: 0.7362127\ttest: 0.9878522\tbest: 0.9876671 (1114)\ttotal: 1m 30s\tremaining: 1m\n",
      "1300:\tlearn: 0.7219347\ttest: 0.9879743\tbest: 0.9876671 (1114)\ttotal: 1m 38s\tremaining: 52.9s\n",
      "1400:\tlearn: 0.7074383\ttest: 0.9879640\tbest: 0.9876671 (1114)\ttotal: 1m 46s\tremaining: 45.3s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.9876670972\n",
      "bestIteration = 1114\n",
      "\n",
      "Shrink model to first 1115 iterations.\n",
      "Partial score of fold 2 is: 0.5854089028734453\n",
      "0:\tlearn: 1.2478061\ttest: 1.2475197\tbest: 1.2475197 (0)\ttotal: 100ms\tremaining: 3m 20s\n",
      "100:\tlearn: 0.9924215\ttest: 1.0084585\tbest: 1.0084585 (100)\ttotal: 7.79s\tremaining: 2m 26s\n",
      "200:\tlearn: 0.9483678\ttest: 0.9921007\tbest: 0.9921007 (200)\ttotal: 15.1s\tremaining: 2m 15s\n",
      "300:\tlearn: 0.9148755\ttest: 0.9866080\tbest: 0.9865393 (298)\ttotal: 22.5s\tremaining: 2m 7s\n",
      "400:\tlearn: 0.8878811\ttest: 0.9836772\tbest: 0.9836663 (397)\ttotal: 29.9s\tremaining: 1m 59s\n",
      "500:\tlearn: 0.8646567\ttest: 0.9821446\tbest: 0.9821027 (499)\ttotal: 37.3s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.8456518\ttest: 0.9810919\tbest: 0.9810740 (597)\ttotal: 44.8s\tremaining: 1m 44s\n",
      "700:\tlearn: 0.8293867\ttest: 0.9800060\tbest: 0.9800030 (699)\ttotal: 52.1s\tremaining: 1m 36s\n",
      "800:\tlearn: 0.8093085\ttest: 0.9795991\tbest: 0.9794782 (795)\ttotal: 59.8s\tremaining: 1m 29s\n",
      "900:\tlearn: 0.7936001\ttest: 0.9795561\tbest: 0.9793691 (823)\ttotal: 1m 7s\tremaining: 1m 22s\n",
      "1000:\tlearn: 0.7772044\ttest: 0.9792098\tbest: 0.9792098 (1000)\ttotal: 1m 15s\tremaining: 1m 14s\n",
      "1100:\tlearn: 0.7613945\ttest: 0.9795180\tbest: 0.9791663 (1005)\ttotal: 1m 22s\tremaining: 1m 7s\n",
      "1200:\tlearn: 0.7438911\ttest: 0.9800872\tbest: 0.9791663 (1005)\ttotal: 1m 30s\tremaining: 1m\n",
      "1300:\tlearn: 0.7287074\ttest: 0.9805884\tbest: 0.9791663 (1005)\ttotal: 1m 37s\tremaining: 52.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.9791663053\n",
      "bestIteration = 1005\n",
      "\n",
      "Shrink model to first 1006 iterations.\n",
      "Partial score of fold 3 is: 0.6009761991401739\n",
      "0:\tlearn: 1.2477552\ttest: 1.2474470\tbest: 1.2474470 (0)\ttotal: 64.8ms\tremaining: 2m 9s\n",
      "100:\tlearn: 0.9897797\ttest: 1.0133065\tbest: 1.0133065 (100)\ttotal: 7.47s\tremaining: 2m 20s\n",
      "200:\tlearn: 0.9441546\ttest: 0.9949712\tbest: 0.9949712 (200)\ttotal: 15.4s\tremaining: 2m 17s\n",
      "300:\tlearn: 0.9143630\ttest: 0.9889102\tbest: 0.9889102 (300)\ttotal: 23.6s\tremaining: 2m 12s\n",
      "400:\tlearn: 0.8829607\ttest: 0.9854679\tbest: 0.9854679 (400)\ttotal: 31.5s\tremaining: 2m 5s\n",
      "500:\tlearn: 0.8587168\ttest: 0.9835423\tbest: 0.9835181 (492)\ttotal: 39s\tremaining: 1m 56s\n",
      "600:\tlearn: 0.8390380\ttest: 0.9820029\tbest: 0.9820029 (600)\ttotal: 48s\tremaining: 1m 51s\n",
      "700:\tlearn: 0.8208741\ttest: 0.9813299\tbest: 0.9813299 (700)\ttotal: 55.5s\tremaining: 1m 42s\n",
      "800:\tlearn: 0.8066114\ttest: 0.9806553\tbest: 0.9806553 (800)\ttotal: 1m 2s\tremaining: 1m 34s\n",
      "900:\tlearn: 0.7934453\ttest: 0.9805627\tbest: 0.9805278 (896)\ttotal: 1m 10s\tremaining: 1m 25s\n",
      "1000:\tlearn: 0.7805537\ttest: 0.9805810\tbest: 0.9804844 (994)\ttotal: 1m 18s\tremaining: 1m 17s\n",
      "1100:\tlearn: 0.7666565\ttest: 0.9804065\tbest: 0.9803101 (1018)\ttotal: 1m 26s\tremaining: 1m 10s\n",
      "1200:\tlearn: 0.7535905\ttest: 0.9805657\tbest: 0.9803101 (1018)\ttotal: 1m 34s\tremaining: 1m 3s\n",
      "1300:\tlearn: 0.7397715\ttest: 0.9807314\tbest: 0.9803101 (1018)\ttotal: 1m 43s\tremaining: 55.6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.9803101065\n",
      "bestIteration = 1018\n",
      "\n",
      "Shrink model to first 1019 iterations.\n",
      "Partial score of fold 4 is: 0.593807586040725\n",
      "Our oof cohen kappa score is:  0.5914163678923854\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, params=Cat_BO.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "Using categorical_feature in Dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.960227\tvalid_1's rmse: 1.01255\n",
      "[200]\ttraining's rmse: 0.905703\tvalid_1's rmse: 0.99632\n",
      "[300]\ttraining's rmse: 0.871168\tvalid_1's rmse: 0.994549\n",
      "[400]\ttraining's rmse: 0.842945\tvalid_1's rmse: 0.993623\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttraining's rmse: 0.846363\tvalid_1's rmse: 0.993185\n",
      "Partial score of fold 0 is: 0.5771779186404624\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.963072\tvalid_1's rmse: 1.00169\n",
      "[200]\ttraining's rmse: 0.909022\tvalid_1's rmse: 0.983306\n",
      "[300]\ttraining's rmse: 0.874776\tvalid_1's rmse: 0.979157\n",
      "[400]\ttraining's rmse: 0.847111\tvalid_1's rmse: 0.978879\n",
      "[500]\ttraining's rmse: 0.823407\tvalid_1's rmse: 0.978972\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's rmse: 0.831361\tvalid_1's rmse: 0.978499\n",
      "Partial score of fold 1 is: 0.6034812812980384\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.961099\tvalid_1's rmse: 1.01123\n",
      "[200]\ttraining's rmse: 0.907236\tvalid_1's rmse: 0.990043\n",
      "[300]\ttraining's rmse: 0.872281\tvalid_1's rmse: 0.985917\n",
      "[400]\ttraining's rmse: 0.844831\tvalid_1's rmse: 0.983941\n",
      "[500]\ttraining's rmse: 0.821116\tvalid_1's rmse: 0.984146\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttraining's rmse: 0.841516\tvalid_1's rmse: 0.9836\n",
      "Partial score of fold 2 is: 0.600260461380784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.963665\tvalid_1's rmse: 1.00402\n",
      "[200]\ttraining's rmse: 0.909248\tvalid_1's rmse: 0.983693\n",
      "[300]\ttraining's rmse: 0.874582\tvalid_1's rmse: 0.980958\n",
      "[400]\ttraining's rmse: 0.846445\tvalid_1's rmse: 0.980494\n",
      "[500]\ttraining's rmse: 0.822355\tvalid_1's rmse: 0.980388\n",
      "[600]\ttraining's rmse: 0.800981\tvalid_1's rmse: 0.980238\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttraining's rmse: 0.808842\tvalid_1's rmse: 0.98005\n",
      "Partial score of fold 3 is: 0.6004393958206315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.961615\tvalid_1's rmse: 1.00448\n",
      "[200]\ttraining's rmse: 0.90899\tvalid_1's rmse: 0.985371\n",
      "[300]\ttraining's rmse: 0.875052\tvalid_1's rmse: 0.980187\n",
      "[400]\ttraining's rmse: 0.848369\tvalid_1's rmse: 0.978072\n",
      "[500]\ttraining's rmse: 0.824628\tvalid_1's rmse: 0.977624\n",
      "[600]\ttraining's rmse: 0.803539\tvalid_1's rmse: 0.977614\n",
      "Early stopping, best iteration is:\n",
      "[588]\ttraining's rmse: 0.805945\tvalid_1's rmse: 0.97715\n",
      "Partial score of fold 4 is: 0.6020406113952642\n",
      "Our oof cohen kappa score is:  0.5962480769265942\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# solve: LightGBMError: Do not support special JSON characters in feature name.\n",
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "ajusted_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in ajusted_test.columns]\n",
    "features = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in features]\n",
    "\n",
    "lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, params=LGB_pramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.86276\tval-rmse:1.86279\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.22342\tval-rmse:1.2567\n",
      "[200]\ttrain-rmse:0.961003\tval-rmse:1.04815\n",
      "[300]\ttrain-rmse:0.888981\tval-rmse:1.00676\n",
      "[400]\ttrain-rmse:0.860978\tval-rmse:0.996174\n",
      "[500]\ttrain-rmse:0.848121\tval-rmse:0.992865\n",
      "[600]\ttrain-rmse:0.839747\tval-rmse:0.991163\n",
      "[700]\ttrain-rmse:0.833758\tval-rmse:0.989902\n",
      "[800]\ttrain-rmse:0.829752\tval-rmse:0.989357\n",
      "[900]\ttrain-rmse:0.825923\tval-rmse:0.988945\n",
      "[1000]\ttrain-rmse:0.823023\tval-rmse:0.988786\n",
      "[1100]\ttrain-rmse:0.819966\tval-rmse:0.988581\n",
      "[1200]\ttrain-rmse:0.817507\tval-rmse:0.98846\n",
      "Stopping. Best iteration:\n",
      "[1138]\ttrain-rmse:0.818869\tval-rmse:0.988413\n",
      "\n",
      "Partial score of fold 0 is: 0.5905980016290215\n",
      "[0]\ttrain-rmse:1.86276\tval-rmse:1.8629\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.22338\tval-rmse:1.25691\n",
      "[200]\ttrain-rmse:0.963441\tval-rmse:1.04065\n",
      "[300]\ttrain-rmse:0.890731\tval-rmse:0.993996\n",
      "[400]\ttrain-rmse:0.862569\tval-rmse:0.980688\n",
      "[500]\ttrain-rmse:0.849888\tval-rmse:0.976792\n",
      "[600]\ttrain-rmse:0.841611\tval-rmse:0.974742\n",
      "[700]\ttrain-rmse:0.83672\tval-rmse:0.974211\n",
      "[800]\ttrain-rmse:0.832682\tval-rmse:0.973854\n",
      "[900]\ttrain-rmse:0.828619\tval-rmse:0.973607\n",
      "[1000]\ttrain-rmse:0.825328\tval-rmse:0.9733\n",
      "[1100]\ttrain-rmse:0.822526\tval-rmse:0.973031\n",
      "[1200]\ttrain-rmse:0.819493\tval-rmse:0.972726\n",
      "[1300]\ttrain-rmse:0.816826\tval-rmse:0.97263\n",
      "[1400]\ttrain-rmse:0.814506\tval-rmse:0.972612\n",
      "Stopping. Best iteration:\n",
      "[1372]\ttrain-rmse:0.81529\tval-rmse:0.972534\n",
      "\n",
      "Partial score of fold 1 is: 0.6075967734145298\n",
      "[0]\ttrain-rmse:1.86271\tval-rmse:1.86289\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.2224\tval-rmse:1.2577\n",
      "[200]\ttrain-rmse:0.961661\tval-rmse:1.04594\n",
      "[300]\ttrain-rmse:0.889818\tval-rmse:1.00156\n",
      "[400]\ttrain-rmse:0.861754\tval-rmse:0.989506\n",
      "[500]\ttrain-rmse:0.849135\tval-rmse:0.986085\n",
      "[600]\ttrain-rmse:0.840454\tval-rmse:0.984043\n",
      "[700]\ttrain-rmse:0.835082\tval-rmse:0.983026\n",
      "[800]\ttrain-rmse:0.830613\tval-rmse:0.982615\n",
      "[900]\ttrain-rmse:0.826646\tval-rmse:0.982161\n",
      "[1000]\ttrain-rmse:0.823347\tval-rmse:0.98188\n",
      "[1100]\ttrain-rmse:0.820194\tval-rmse:0.981366\n",
      "[1200]\ttrain-rmse:0.817455\tval-rmse:0.981106\n",
      "[1300]\ttrain-rmse:0.815314\tval-rmse:0.980778\n",
      "[1400]\ttrain-rmse:0.813241\tval-rmse:0.980494\n",
      "[1500]\ttrain-rmse:0.811354\tval-rmse:0.980379\n",
      "Stopping. Best iteration:\n",
      "[1488]\ttrain-rmse:0.811597\tval-rmse:0.980336\n",
      "\n",
      "Partial score of fold 2 is: 0.6016919368995637\n",
      "[0]\ttrain-rmse:1.86277\tval-rmse:1.86297\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.22272\tval-rmse:1.25763\n",
      "[200]\ttrain-rmse:0.962643\tval-rmse:1.04474\n",
      "[300]\ttrain-rmse:0.891137\tval-rmse:0.999269\n",
      "[400]\ttrain-rmse:0.864642\tval-rmse:0.986422\n",
      "[500]\ttrain-rmse:0.851761\tval-rmse:0.982927\n",
      "[600]\ttrain-rmse:0.844398\tval-rmse:0.981375\n",
      "[700]\ttrain-rmse:0.838387\tval-rmse:0.980372\n",
      "[800]\ttrain-rmse:0.833884\tval-rmse:0.979257\n",
      "[900]\ttrain-rmse:0.830454\tval-rmse:0.979042\n",
      "[1000]\ttrain-rmse:0.827042\tval-rmse:0.978822\n",
      "[1100]\ttrain-rmse:0.823774\tval-rmse:0.9787\n",
      "[1200]\ttrain-rmse:0.820947\tval-rmse:0.978324\n",
      "[1300]\ttrain-rmse:0.818426\tval-rmse:0.978004\n",
      "[1400]\ttrain-rmse:0.816102\tval-rmse:0.977866\n",
      "[1500]\ttrain-rmse:0.814284\tval-rmse:0.977732\n",
      "[1600]\ttrain-rmse:0.81208\tval-rmse:0.977424\n",
      "[1700]\ttrain-rmse:0.809894\tval-rmse:0.977191\n",
      "[1800]\ttrain-rmse:0.807977\tval-rmse:0.977078\n",
      "[1900]\ttrain-rmse:0.806518\tval-rmse:0.976946\n",
      "[2000]\ttrain-rmse:0.80535\tval-rmse:0.976812\n",
      "Stopping. Best iteration:\n",
      "[1998]\ttrain-rmse:0.805383\tval-rmse:0.976801\n",
      "\n",
      "Partial score of fold 3 is: 0.604912756816818\n",
      "[0]\ttrain-rmse:1.86276\tval-rmse:1.86289\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.22365\tval-rmse:1.25561\n",
      "[200]\ttrain-rmse:0.962943\tval-rmse:1.0403\n",
      "[300]\ttrain-rmse:0.891177\tval-rmse:0.995242\n",
      "[400]\ttrain-rmse:0.863253\tval-rmse:0.982014\n",
      "[500]\ttrain-rmse:0.850972\tval-rmse:0.978104\n",
      "[600]\ttrain-rmse:0.843822\tval-rmse:0.976497\n",
      "[700]\ttrain-rmse:0.837832\tval-rmse:0.975455\n",
      "[800]\ttrain-rmse:0.833372\tval-rmse:0.974729\n",
      "[900]\ttrain-rmse:0.830388\tval-rmse:0.974613\n",
      "[1000]\ttrain-rmse:0.827154\tval-rmse:0.974478\n",
      "[1100]\ttrain-rmse:0.824013\tval-rmse:0.974316\n",
      "[1200]\ttrain-rmse:0.82139\tval-rmse:0.974144\n",
      "[1300]\ttrain-rmse:0.819138\tval-rmse:0.973732\n",
      "[1400]\ttrain-rmse:0.817105\tval-rmse:0.973374\n",
      "[1500]\ttrain-rmse:0.81521\tval-rmse:0.973106\n",
      "[1600]\ttrain-rmse:0.813215\tval-rmse:0.97291\n",
      "[1700]\ttrain-rmse:0.811522\tval-rmse:0.972776\n",
      "[1800]\ttrain-rmse:0.809986\tval-rmse:0.97279\n",
      "Stopping. Best iteration:\n",
      "[1767]\ttrain-rmse:0.810499\tval-rmse:0.972734\n",
      "\n",
      "Partial score of fold 4 is: 0.607230996944865\n",
      "Our oof cohen kappa score is:  0.6020461277676448\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model = Xgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, params=XGB_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = Cnn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_model = Nn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "# stacker = LinearRegression()\n",
    "# S_train = np.concatenate(\n",
    "#     (lgb_model.oof_pred.reshape(-1,1), \\\n",
    "#      xgb_model.oof_pred.reshape(-1,1), \\\n",
    "#      cat_model.oof_pred.reshape(-1,1)),\\\n",
    "#     axis=1)\n",
    "# S_test = np.concatenate(\n",
    "#     (lgb_model.y_pred.reshape(-1,1), \\\n",
    "#      xgb_model.y_pred.reshape(-1,1), \\\n",
    "#      cat_model.y_pred.reshape(-1,1)),\\\n",
    "#     axis=1)\n",
    "# stacker.fit(S_train, reduce_train['accuracy_group'])\n",
    "# final_pred = stacker.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = {'lgb': 0.60, 'cat': 0.20, 'xgb': 0.20, 'nn': 0.20}\n",
    "\n",
    "# final_pred = (lgb_model.y_pred * weights['lgb']) + (xgb_model.y_pred * weights['xgb']) + (cat_model.y_pred * weights['cat'])\n",
    "# print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = lgb_model.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8225551158846827, 1: 1.9779536461277303, 2: 2.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.500\n",
       "0    0.375\n",
       "2    0.125\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = Counter(reduce_train['accuracy_group'])\n",
    "for k in dist:\n",
    "    dist[k] /= len(reduce_train)\n",
    "reduce_train['accuracy_group'].hist()\n",
    "\n",
    "acum = 0\n",
    "bound = {}\n",
    "for i in range(3):\n",
    "    acum += dist[i]\n",
    "    bound[i] = np.percentile(final_pred, acum * 100)\n",
    "print(bound)\n",
    "\n",
    "bound[0] = 1.18253215\n",
    "bound[1] = 1.81532098\n",
    "bound[2] = 2.17071483\n",
    "\n",
    "def classify(x):\n",
    "    if x <= bound[0]:\n",
    "        return 0\n",
    "    elif x <= bound[1]:\n",
    "        return 1\n",
    "    elif x <= bound[2]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "final_pred = np.array(list(map(classify, final_pred)))\n",
    "\n",
    "sample_submission['accuracy_group'] = final_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
