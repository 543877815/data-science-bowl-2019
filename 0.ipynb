{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the code for feature generation from this kernel: https://www.kaggle.com/artgor/quick-and-dirty-regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from bayes_opt import BayesianOptimization\n",
    "import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from typing import Any\n",
    "from itertools import product\n",
    "pd.set_option('max_rows', 500)\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "base_dir = 'data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv(base_dir + 'train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv(base_dir + 'test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv(base_dir + 'train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv(base_dir + 'specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv(base_dir + 'sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission\n",
    "\n",
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n",
    "\n",
    "\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_game_titles = ['All Star Sorting', 'Fireworks (Activity)', 'Flower Waterer (Activity)', 'Air Show', 'Crystals Rule', 'Bug Measurer (Activity)', 'Sandcastle Builder (Activity)', 'Scrub-A-Dub', 'Watering Hole (Activity)', 'Dino Drink', 'Bubble Bath', 'Bottle Filler (Activity)', 'Dino Dive', 'Chow Time', 'Chicken Balancer (Activity)', 'Happy Camel', 'Leaf Leader', 'Pan Balance', 'Egg Dropper (Activity)']\n",
    "game_titles = ['All Star Sorting', 'Air Show', 'Crystals Rule', 'Scrub-A-Dub', 'Dino Drink', 'Bubble Bath', 'Dino Dive', 'Chow Time', 'Happy Camel', 'Leaf Leader', 'Pan Balance']\n",
    "media_sequence = {'Welcome to Lost Lagoon!': 19, 'Tree Top City - Level 1':17, 'Ordering Spheres':61, 'Costume Box':61,'12 Monkeys':109, 'Tree Top City - Level 2':25, \"Pirate's Tale\":80, \n",
    "                  'Treasure Map':156, 'Tree Top City - Level 3':26, 'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18, \n",
    "                  'Balancing Act':72,'Lifting Heavy Things':118, 'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19, 'Heavy, Heavier, Heaviest':61}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1345/17000 [04:46<32:01,  8.15it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e8ee0025eecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# tranform function to get the train and test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m \u001b[0mreduce_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategoricals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e8ee0025eecc>\u001b[0m in \u001b[0;36mget_train_and_test\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mcompiled_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mins_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'installation_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mcompiled_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mins_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'installation_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e8ee0025eecc>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(user_sample, test_set)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msession_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Assessment'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# search for event_code 4100, that represents the assessments trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mall_attempts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'event_code == {win_code[session_title]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;31m# then, check the numbers of wins and the number of losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtrue_attempts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_attempts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3197\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3199\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3201\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresolvers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3309\u001b[0m             \u001b[0mindex_resolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_index_resolvers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3310\u001b[0;31m             \u001b[0mcolumn_resolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_space_character_free_column_resolvers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3311\u001b[0m             \u001b[0mresolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_resolvers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_resolvers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"target\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_space_character_free_column_resolvers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_remove_spaces_column_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0m_remove_spaces_column_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_remove_spaces_column_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0m_remove_spaces_column_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mitems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_item_cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_box_item_values\u001b[0;34m(self, key, values)\u001b[0m\n\u001b[1;32m   3457\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_get_info_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_indexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3459\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3460\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    user_activities_time = {'Clip_time_mean':[], 'Activity_time_mean': [], 'Game_time_mean': []}\n",
    "    \n",
    "    positive_words = \"play again|did it|job|wow|cool|nice|amazing|exactly|Great|awe|That's it|just right|good|Alright|gold|That's right|All right|right amount|Well done|you're right|happy|won|Whoa\"\n",
    "    negative_words = \"try again|too|Almost|n't|but|Whoops|Oops|not right|Uh oh\"\n",
    "    accumulated_positive_events = 0\n",
    "    accumulated_negative_events = 0\n",
    "    accumulated_positive_title = {'accumulated_positive_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_negative_title = {'accumulated_negative_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_positive_title_ratio = {'accumulated_positive_ratio_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_negative_title_ratio = {'accumulated_negative_ratio_'+t: 0 for t in activity_game_titles}\n",
    "    accumulated_won_game = {'accumulated_won_game_count_'+g: 0 for g in game_titles}\n",
    "    \n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0\n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    durations = []\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {e_c: 0 for e_c in list_of_event_code}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()}\n",
    "    title_event_code_count: Dict[str, int] = {t_e: 0 for t_e in all_title_event_code}\n",
    "    accumulated_correct_title = {'accumulated_correct_'+title: 0 for title in assess_titles}\n",
    "    accumulated_uncorrect_title = {'accumulated_uncorrect_'+title: 0 for title in assess_titles}\n",
    "    accumulated_accuracy_title = {'acc_mean_' + title: 0 for title in assess_titles}\n",
    "    accumulated_accuracy_titles = {'acc_' + title: [] for title in assess_titles}\n",
    "    \n",
    "    time_spent_each_act = {t+\"_time\": 0 for t in list_of_user_activities}\n",
    "    time_spent_each_acts = {t+\"_time\": [] for t in list_of_user_activities}\n",
    "    time_spent_each_act_mean = {t+\"_time_mean\": 0 for t in list_of_user_activities}\n",
    "    \n",
    "    \n",
    "    # itarates through each session of one installation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "    \n",
    "        if (session_type=='Clip'):\n",
    "            time_spent = media_sequence[session_title_text]\n",
    "            user_activities_time[session_type+'_time_mean'].append(time_spent)\n",
    "            time_spent_each_act[session_title_text + \"_time\"] += time_spent\n",
    "            time_spent_each_acts[session_title_text + \"_time\"].append(time_spent)\n",
    "        \n",
    "        elif(session_type=='Activity' or session_type=='Game'):\n",
    "            time_spent = (session.iloc[-1, 2] - session.iloc[0, 2]).seconds\n",
    "            user_activities_time[session_type+'_time_mean'].append(time_spent)\n",
    "            time_spent_each_act[session_title_text + \"_time\"] += time_spent\n",
    "            time_spent_each_acts[session_title_text + \"_time\"].append(time_spent)\n",
    "            \n",
    "            sum_positive_events = session['event_data'].str.contains(positive_words, flags=re.IGNORECASE).sum()\n",
    "            sum_negative_events = session['event_data'].str.contains(negative_words, flags=re.IGNORECASE).sum()\n",
    "            accumulated_positive_events += sum_positive_events\n",
    "            accumulated_negative_events += sum_negative_events\n",
    "            accumulated_positive_title['accumulated_positive_'+session_title_text] += sum_positive_events\n",
    "            accumulated_negative_title['accumulated_negative_'+session_title_text] += sum_negative_events\n",
    "            p = accumulated_positive_title['accumulated_positive_'+session_title_text]\n",
    "            n = accumulated_negative_title['accumulated_negative_'+session_title_text]\n",
    "            accumulated_positive_title_ratio['accumulated_positive__ratio_'+session_title_text] = p/(p+n) if (p+n)>0 else 0\n",
    "            accumulated_negative_title_ratio['accumulated_negative__ratio_'+session_title_text] = n/(p+n) if (p+n)>0 else 0\n",
    "            \n",
    "            if session_type == 'Game':\n",
    "                accumulated_won_game['accumulated_won_game_count_'+session_title_text]+=session['event_data'].str.contains('play again', flags=re.IGNORECASE).sum()\n",
    "        \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(accumulated_correct_title.copy())\n",
    "            features.update(accumulated_uncorrect_title.copy())\n",
    "            features.update(accumulated_accuracy_title.copy())\n",
    "            features.update(accumulated_positive_title)\n",
    "            features.update(accumulated_negative_title)\n",
    "            features.update(accumulated_positive_title_ratio)\n",
    "            features.update(accumulated_negative_title_ratio)\n",
    "            features.update(accumulated_won_game.copy())\n",
    "            features.update(time_spent_each_act.copy())\n",
    "            features.update(time_spent_each_act_mean.copy())\n",
    "            \n",
    "            variety_features = [('var_title', title_count),\n",
    "                                ('var_event_code', event_code_count),\n",
    "                               ('var_title_event_code', title_event_code_count)]\n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "            \n",
    "            # positive & negative events\n",
    "            features['accumulated_positive_events'] = accumulated_positive_events\n",
    "            features['accumulated_negative_events'] = accumulated_negative_events\n",
    "            positive_negative_events = accumulated_positive_events + accumulated_negative_events\n",
    "            features['positive_events_ratio'] = accumulated_positive_events/positive_negative_events if positive_negative_events > 0 else 0\n",
    "            features['negative_events_ratio'] = accumulated_negative_events/positive_negative_events if positive_negative_events > 0 else 0\n",
    "            accumulated_positive_events = 0\n",
    "            accumulated_negative_events = 0\n",
    "            \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_title['accumulated_correct_'+session_title_text] += true_attempts\n",
    "            accumulated_uncorrect_title['accumulated_uncorrect_'+session_title_text] += false_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "                features['accumulated_correct_duration'] = 0\n",
    "                features['accumulated_uncorrect_duration'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                features['accumulated_correct_duration'] = features['accumulated_correct_attempts']/np.sum(durations)\n",
    "                features['accumulated_uncorrect_duration'] = features['accumulated_uncorrect_attempts']/np.sum(durations)\n",
    "            if user_activities_time['Clip_time_mean']==[]:\n",
    "                features['Clip_time_mean'] = 0\n",
    "                features['Clip_time_std'] = 0\n",
    "            else:\n",
    "                features['Clip_time_mean'] = np.mean(user_activities_time['Clip_time_mean'])\n",
    "                features['Clip_time_std'] = np.std(user_activities_time['Clip_time_mean'])\n",
    "            if user_activities_time['Activity_time_mean']==[]:\n",
    "                features['Activity_time_mean'] = 0\n",
    "                features['Activity_time_std'] = 0\n",
    "            else:\n",
    "                features['Activity_time_mean'] = np.mean(user_activities_time['Activity_time_mean'])\n",
    "                features['Activity_time_std'] = np.std(user_activities_time['Activity_time_mean'])\n",
    "            if user_activities_time['Game_time_mean']==[]:\n",
    "                features['Game_time_mean'] = 0\n",
    "                features['Game_time_std'] = 0\n",
    "            else:\n",
    "                features['Game_time_mean'] = np.mean(user_activities_time['Game_time_mean'])\n",
    "                features['Game_time_std'] = np.std(user_activities_time['Game_time_mean'])\n",
    "            time_spent = (session.iloc[-1, 2] - session.iloc[0, 2]).seconds\n",
    "            time_spent_each_act[session_title_text + \"_time\"] += time_spent\n",
    "            time_spent_each_acts[session_title_text + \"_time\"].append(time_spent)\n",
    "            durations.append(time_spent)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            accumulated_accuracy_titles['acc_' + session_title_text].append(accuracy)\n",
    "            if accumulated_accuracy_titles['acc_' + session_title_text]==[]:\n",
    "                accumulated_accuracy_title['acc_mean_' + session_title_text] = 0\n",
    "            else:\n",
    "                accumulated_accuracy_title['acc_mean_' + session_title_text] = np.mean(accumulated_accuracy_titles['acc_' + session_title_text])\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "        \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "        \n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments\n",
    "\n",
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "        \n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    \n",
    "    return reduce_train, reduce_test, categoricals\n",
    "\n",
    "\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reduce_train, reduce_test):\n",
    "    for df in [reduce_train, reduce_test]:\n",
    "        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n",
    "        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n",
    "        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "        \n",
    "        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n",
    "                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n",
    "                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n",
    "        \n",
    "        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n",
    "   \n",
    "    return reduce_train, reduce_test\n",
    "\n",
    "# call feature engineering function\n",
    "reduce_train, reduce_test = preprocess(reduce_train, reduce_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduce_train.shape)\n",
    "print(reduce_test.shape)\n",
    "print(categoricals)\n",
    "# reduce_train.to_csv('reduce_train.csv', index=False)\n",
    "# reduce_test.to_csv('reduce_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_train = pd.read_csv('reduce_train0.csv')\n",
    "# reduce_test = pd.read_csv('reduce_test0.csv')\n",
    "# reduce_train.iloc[5353]['accuracy_group']\n",
    "# reduce_train = reduce_train.copy().sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in features if x not in ['accuracy_group', 'installation_id']]\n",
    "\n",
    "counter = 0\n",
    "to_remove = []\n",
    "for feat_a in features:\n",
    "    for feat_b in features:\n",
    "        if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n",
    "            c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]\n",
    "            if c > 0.995:\n",
    "                counter += 1\n",
    "                to_remove.append(feat_b)\n",
    "                print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))\n",
    "\n",
    "# to_exclude = [] \n",
    "# ajusted_test = reduce_test.copy()\n",
    "# for feature in ajusted_test.columns:\n",
    "#     if feature not in ['accuracy_group', 'installation_id', 'accuracy_group', 'session_title']:\n",
    "#         data = reduce_train[feature]\n",
    "#         train_mean = data.mean()\n",
    "#         data = ajusted_test[feature] \n",
    "#         test_mean = data.mean()\n",
    "#         try:\n",
    "#             error = stract_hists(feature, adjust=True)\n",
    "#             ajust_factor = train_mean / test_mean\n",
    "#             if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "#                 to_exclude.append(feature)\n",
    "#                 print(feature, train_mean, test_mean, error)\n",
    "#             else:\n",
    "#                 ajusted_test[feature] *= ajust_factor\n",
    "#         except:\n",
    "#             to_exclude.append(feature)\n",
    "#             print(feature, train_mean, test_mean)\n",
    "\n",
    "features = [x for x in features if x not in (to_remove)]\n",
    "reduce_train[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.extend(['accuracy_group', 'installation_id'])\n",
    "reduce_train = reduce_train[features]\n",
    "# reduce_test = ajusted_test\n",
    "reduce_test = reduce_test[features]\n",
    "reduce_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "@jit\n",
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e\n",
    "\n",
    "\n",
    "def eval_qwk_lgb(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    y_pred[y_pred <= 1.12232214] = 0\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.12232214, y_pred <= 1.73925866))] = 1\n",
    "    y_pred[np.where(np.logical_and(y_pred > 1.73925866, y_pred <= 2.22506454))] = 2\n",
    "    y_pred[y_pred > 2.22506454] = 3\n",
    "\n",
    "    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "\n",
    "    return 'cappa', qwk(y_true, y_pred), True\n",
    "\n",
    "\n",
    "class LGBWrapper_regr(object):\n",
    "    \"\"\"\n",
    "    A wrapper for lightgbm model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = lgb.LGBMRegressor()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "        if params['objective'] == 'regression':\n",
    "            eval_metric = eval_qwk_lgb_regr\n",
    "        else:\n",
    "            eval_metric = 'auc'\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "            eval_names.append('valid')\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "            eval_names.append('holdout')\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = 'auto'\n",
    "        else:\n",
    "            categorical_columns = 'auto'\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_metric,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test, num_iteration=self.model.best_iteration_)\n",
    "\n",
    "    \n",
    "def eval_qwk_xgb(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for xgb.\n",
    "    \"\"\"\n",
    "    # print('y_true', y_true)\n",
    "    # print('y_pred', y_pred)\n",
    "    y_true = y_true.get_label()\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    return 'cappa', -qwk(y_true, y_pred)\n",
    "\n",
    "\n",
    "class LGBWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for lightgbm model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = lgb.LGBMClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        eval_names = ['train']\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "            eval_names.append('valid')\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "            eval_names.append('holdout')\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = 'auto'\n",
    "        else:\n",
    "            categorical_columns = 'auto'\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_qwk_lgb,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       categorical_feature=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if self.model.objective == 'binary':\n",
    "            return self.model.predict_proba(X_test, num_iteration=self.model.best_iteration_)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, num_iteration=self.model.best_iteration_)\n",
    "\n",
    "\n",
    "class CatWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for catboost model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = cat.CatBoostClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        self.model = self.model.set_params(**{k: v for k, v in params.items() if k != 'cat_cols'})\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "\n",
    "        if 'cat_cols' in params.keys():\n",
    "            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n",
    "            if len(cat_cols) > 0:\n",
    "                categorical_columns = params['cat_cols']\n",
    "            else:\n",
    "                categorical_columns = None\n",
    "        else:\n",
    "            categorical_columns = None\n",
    "        \n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n",
    "                       cat_features=categorical_columns)\n",
    "\n",
    "        self.best_score_ = self.model.best_score_\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if 'MultiClass' not in self.model.get_param('loss_function'):\n",
    "            return self.model.predict_proba(X_test, ntree_end=self.model.best_iteration_)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, ntree_end=self.model.best_iteration_)\n",
    "\n",
    "\n",
    "class XGBWrapper(object):\n",
    "    \"\"\"\n",
    "    A wrapper for xgboost model so that we will have a single api for various models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n",
    "\n",
    "        eval_set = [(X_train, y_train)]\n",
    "        self.model = self.model.set_params(**params)\n",
    "\n",
    "        if X_valid is not None:\n",
    "            eval_set.append((X_valid, y_valid))\n",
    "\n",
    "        if X_holdout is not None:\n",
    "            eval_set.append((X_holdout, y_holdout))\n",
    "\n",
    "        self.model.fit(X=X_train, y=y_train,\n",
    "                       eval_set=eval_set, eval_metric=eval_qwk_xgb,\n",
    "                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'])\n",
    "\n",
    "        scores = self.model.evals_result()\n",
    "        self.best_score_ = {k: {m: m_v[-1] for m, m_v in v.items()} for k, v in scores.items()}\n",
    "        self.best_score_ = {k: {m: n if m != 'cappa' else -n for m, n in v.items()} for k, v in self.best_score_.items()}\n",
    "\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        if self.model.objective == 'binary':\n",
    "            return self.model.predict_proba(X_test, ntree_limit=self.model.best_iteration)[:, 1]\n",
    "        else:\n",
    "            return self.model.predict_proba(X_test, ntree_limit=self.model.best_iteration)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MainTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, convert_cyclical: bool = False, create_interactions: bool = False, n_interactions: int = 20):\n",
    "        \"\"\"\n",
    "        Main transformer for the data. Can be used for processing on the whole data.\n",
    "\n",
    "        :param convert_cyclical: convert cyclical features into continuous\n",
    "        :param create_interactions: create interactions between features\n",
    "        \"\"\"\n",
    "\n",
    "        self.convert_cyclical = convert_cyclical\n",
    "        self.create_interactions = create_interactions\n",
    "        self.feats_for_interaction = None\n",
    "        self.n_interactions = n_interactions\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.create_interactions:\n",
    "            self.feats_for_interaction = [col for col in X.columns if 'sum' in col\n",
    "                                          or 'mean' in col or 'max' in col or 'std' in col\n",
    "                                          or 'attempt' in col]\n",
    "            self.feats_for_interaction1 = np.random.choice(self.feats_for_interaction, self.n_interactions)\n",
    "            self.feats_for_interaction2 = np.random.choice(self.feats_for_interaction, self.n_interactions)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "        if self.create_interactions:\n",
    "            for col1 in self.feats_for_interaction1:\n",
    "                for col2 in self.feats_for_interaction2:\n",
    "                    data[f'{col1}_int_{col2}'] = data[col1] * data[col2]\n",
    "\n",
    "        if self.convert_cyclical:\n",
    "            data['timestampHour'] = np.sin(2 * np.pi * data['timestampHour'] / 23.0)\n",
    "            data['timestampMonth'] = np.sin(2 * np.pi * data['timestampMonth'] / 23.0)\n",
    "            data['timestampWeek'] = np.sin(2 * np.pi * data['timestampWeek'] / 23.0)\n",
    "            data['timestampMinute'] = np.sin(2 * np.pi * data['timestampMinute'] / 23.0)\n",
    "\n",
    "#         data['installation_session_count'] = data.groupby(['installation_id'])['Clip'].transform('count')\n",
    "#         data['installation_duration_mean'] = data.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "#         data['installation_title_nunique'] = data.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "\n",
    "#         data['sum_event_code_count'] = data[['2000', '3010', '3110', '4070', '4090', '4030', '4035', '4021', '4020', '4010', '2080', '2083', '2040', '2020', '2030', '3021', '3121', '2050', '3020', '3120', '2060', '2070', '4031', '4025', '5000', '5010', '2081', '2025', '4022', '2035', '4040', '4100', '2010', '4110', '4045', '4095', '4220', '2075', '4230', '4235', '4080', '4050']].sum(axis=1)\n",
    "\n",
    "        # data['installation_event_code_count_mean'] = data.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, main_cat_features: list = None, num_cols: list = None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param main_cat_features:\n",
    "        :param num_cols:\n",
    "        \"\"\"\n",
    "        self.main_cat_features = main_cat_features\n",
    "        self.num_cols = num_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "#         self.num_cols = [col for col in X.columns if 'sum' in col or 'mean' in col or 'max' in col or 'std' in col\n",
    "#                          or 'attempt' in col]\n",
    "        \n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "#         for col in self.num_cols:\n",
    "#             data[f'{col}_to_mean'] = data[col] / data.groupby('installation_id')[col].transform('mean')\n",
    "#             data[f'{col}_to_std'] = data[col] / data.groupby('installation_id')[col].transform('std')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModel(object):\n",
    "    \"\"\"\n",
    "    A wrapper class for classification models.\n",
    "    It can be used for training and prediction.\n",
    "    Can plot feature importance and training progress (if relevant for model).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns: list = None, model_wrapper=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param original_columns:\n",
    "        :param model_wrapper:\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.result_dict = {}\n",
    "        self.train_one_fold = False\n",
    "        self.preprocesser = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y,\n",
    "            X_holdout: pd.DataFrame = None, y_holdout=None,\n",
    "            folds=None,\n",
    "            params: dict = None,\n",
    "            eval_metric='rmse',\n",
    "            cols_to_drop: list = None,\n",
    "            preprocesser=None,\n",
    "            transformers: dict = None,\n",
    "            adversarial: bool = False,\n",
    "            plot: bool = True):\n",
    "        \"\"\"\n",
    "        Training the model.\n",
    "\n",
    "        :param X: training data\n",
    "        :param y: training target\n",
    "        :param X_holdout: holdout data\n",
    "        :param y_holdout: holdout target\n",
    "        :param folds: folds to split the data. If not defined, then model will be trained on the whole X\n",
    "        :param params: training parameters\n",
    "        :param eval_metric: metric for validataion\n",
    "        :param cols_to_drop: list of columns to drop (for example ID)\n",
    "        :param preprocesser: preprocesser class\n",
    "        :param transformers: transformer to use on folds\n",
    "        :param adversarial\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if folds is None:\n",
    "            folds = KFold(n_splits=3, random_state=42)\n",
    "            self.train_one_fold = True\n",
    "\n",
    "        self.columns = X.columns if self.columns is None else self.columns\n",
    "        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n",
    "        self.trained_transformers = {k: [] for k in transformers}\n",
    "        self.transformers = transformers\n",
    "        self.models = []\n",
    "        self.folds_dict = {}\n",
    "        self.eval_metric = eval_metric\n",
    "        n_target = 1\n",
    "        self.oof = np.zeros((len(X), n_target))\n",
    "        self.n_target = n_target\n",
    "\n",
    "        X = X[self.columns]\n",
    "        if X_holdout is not None:\n",
    "            X_holdout = X_holdout[self.columns]\n",
    "\n",
    "        if preprocesser is not None:\n",
    "            self.preprocesser = preprocesser\n",
    "            self.preprocesser.fit(X, y)\n",
    "            X = self.preprocesser.transform(X, y)\n",
    "            self.columns = X.columns.tolist()\n",
    "            if X_holdout is not None:\n",
    "                X_holdout = self.preprocesser.transform(X_holdout)\n",
    "\n",
    "        for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y, X['installation_id'])):\n",
    "\n",
    "            if X_holdout is not None:\n",
    "                X_hold = X_holdout.copy()\n",
    "            else:\n",
    "                X_hold = None\n",
    "            self.folds_dict[fold_n] = {}\n",
    "            if params['verbose']:\n",
    "                print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "            self.folds_dict[fold_n] = {}\n",
    "\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            if self.train_one_fold:\n",
    "                X_train = X[self.original_columns]\n",
    "                y_train = y\n",
    "                X_valid = None\n",
    "                y_valid = None\n",
    "\n",
    "            datasets = {'X_train': X_train, 'X_valid': X_valid, 'X_holdout': X_hold, 'y_train': y_train}\n",
    "            X_train, X_valid, X_hold = self.transform_(datasets, cols_to_drop)\n",
    "\n",
    "            self.folds_dict[fold_n]['columns'] = X_train.columns.tolist()\n",
    "\n",
    "            model = copy.deepcopy(self.model_wrapper)\n",
    "\n",
    "            if adversarial:\n",
    "                X_new1 = X_train.copy()\n",
    "                if X_valid is not None:\n",
    "                    X_new2 = X_valid.copy()\n",
    "                elif X_holdout is not None:\n",
    "                    X_new2 = X_holdout.copy()\n",
    "                X_new = pd.concat([X_new1, X_new2], axis=0)\n",
    "                y_new = np.hstack((np.zeros((X_new1.shape[0])), np.ones((X_new2.shape[0]))))\n",
    "                X_train, X_valid, y_train, y_valid = train_test_split(X_new, y_new)\n",
    "\n",
    "            model.fit(X_train, y_train, X_valid, y_valid, X_hold, y_holdout, params=params)\n",
    "\n",
    "            self.folds_dict[fold_n]['scores'] = model.best_score_\n",
    "            if self.oof.shape[0] != len(X):\n",
    "                self.oof = np.zeros((X.shape[0], self.oof.shape[1]))\n",
    "            if not adversarial:\n",
    "                self.oof[valid_index] = model.predict(X_valid).reshape(-1, n_target)\n",
    "\n",
    "            fold_importance = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)),\n",
    "                                           columns=['feature', 'importance'])\n",
    "            self.feature_importances = self.feature_importances.append(fold_importance)\n",
    "            self.models.append(model)\n",
    "\n",
    "        self.feature_importances['importance'] = self.feature_importances['importance'].astype(int)\n",
    "\n",
    "        # if params['verbose']:\n",
    "        self.calc_scores_()\n",
    "\n",
    "        if plot:\n",
    "            # print(classification_report(y, self.oof.argmax(1)))\n",
    "            fig, ax = plt.subplots(figsize=(16, 12))\n",
    "            plt.subplot(2, 2, 1)\n",
    "            self.plot_feature_importance(top_n=20)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            self.plot_metric()\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.hist(y.values.reshape(-1, 1) - self.oof)\n",
    "            plt.title('Distribution of errors')\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.hist(self.oof)\n",
    "            plt.title('Distribution of oof predictions');\n",
    "\n",
    "    def transform_(self, datasets, cols_to_drop):\n",
    "        for name, transformer in self.transformers.items():\n",
    "            transformer.fit(datasets['X_train'], datasets['y_train'])\n",
    "            datasets['X_train'] = transformer.transform(datasets['X_train'])\n",
    "            if datasets['X_valid'] is not None:\n",
    "                datasets['X_valid'] = transformer.transform(datasets['X_valid'])\n",
    "            if datasets['X_holdout'] is not None:\n",
    "                datasets['X_holdout'] = transformer.transform(datasets['X_holdout'])\n",
    "            self.trained_transformers[name].append(transformer)\n",
    "        if cols_to_drop is not None:\n",
    "            cols_to_drop = [col for col in cols_to_drop if col in datasets['X_train'].columns]\n",
    "\n",
    "            datasets['X_train'] = datasets['X_train'].drop(cols_to_drop, axis=1)\n",
    "            if datasets['X_valid'] is not None:\n",
    "                datasets['X_valid'] = datasets['X_valid'].drop(cols_to_drop, axis=1)\n",
    "            if datasets['X_holdout'] is not None:\n",
    "                datasets['X_holdout'] = datasets['X_holdout'].drop(cols_to_drop, axis=1)\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "\n",
    "        return datasets['X_train'], datasets['X_valid'], datasets['X_holdout']\n",
    "\n",
    "    def calc_scores_(self):\n",
    "        print()\n",
    "        datasets = [k for k, v in [v['scores'] for k, v in self.folds_dict.items()][0].items() if len(v) > 0]\n",
    "        self.scores = {}\n",
    "        for d in datasets:\n",
    "            scores = [v['scores'][d][self.eval_metric] for k, v in self.folds_dict.items()]\n",
    "            print(f\"CV mean score on {d}: {np.mean(scores):.4f} +/- {np.std(scores):.4f} std.\")\n",
    "            self.scores[d] = np.mean(scores)\n",
    "\n",
    "    def predict(self, X_test, averaging: str = 'usual'):\n",
    "        \"\"\"\n",
    "        Make prediction\n",
    "\n",
    "        :param X_test:\n",
    "        :param averaging: method of averaging\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_prediction = np.zeros((X_test.shape[0], self.oof.shape[1]))\n",
    "        if self.preprocesser is not None:\n",
    "            X_test = self.preprocesser.transform(X_test)\n",
    "        for i in range(len(self.models)):\n",
    "            X_t = X_test.copy()\n",
    "            for name, transformers in self.trained_transformers.items():\n",
    "                X_t = transformers[i].transform(X_t)\n",
    "\n",
    "            if self.cols_to_drop is not None:\n",
    "                cols_to_drop = [col for col in self.cols_to_drop if col in X_t.columns]\n",
    "                X_t = X_t.drop(cols_to_drop, axis=1)\n",
    "            y_pred = self.models[i].predict(X_t[self.folds_dict[i]['columns']]).reshape(-1, full_prediction.shape[1])\n",
    "\n",
    "            # if case transformation changes the number of the rows\n",
    "            if full_prediction.shape[0] != len(y_pred):\n",
    "                full_prediction = np.zeros((y_pred.shape[0], self.oof.shape[1]))\n",
    "\n",
    "            if averaging == 'usual':\n",
    "                full_prediction += y_pred\n",
    "            elif averaging == 'rank':\n",
    "                full_prediction += pd.Series(y_pred).rank().values\n",
    "\n",
    "        return full_prediction / len(self.models)\n",
    "\n",
    "    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Plot default feature importance.\n",
    "\n",
    "        :param drop_null_importance: drop columns with null feature importance\n",
    "        :param top_n: show top n columns\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        top_feats = self.get_top_features(drop_null_importance, top_n)\n",
    "        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n",
    "        feature_importances['feature'] = feature_importances['feature'].astype(str)\n",
    "        top_feats = [str(i) for i in top_feats]\n",
    "        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats)\n",
    "        plt.title('Feature importances')\n",
    "\n",
    "    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Get top features by importance.\n",
    "\n",
    "        :param drop_null_importance:\n",
    "        :param top_n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n",
    "        if drop_null_importance:\n",
    "            grouped_feats = grouped_feats[grouped_feats != 0]\n",
    "        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n",
    "\n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "        Plot training progress.\n",
    "        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_evals_results = pd.DataFrame()\n",
    "        for model in self.models:\n",
    "            evals_result = pd.DataFrame()\n",
    "            for k in model.model.evals_result_.keys():\n",
    "                evals_result[k] = model.model.evals_result_[k][self.eval_metric]\n",
    "            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n",
    "            full_evals_results = full_evals_results.append(evals_result)\n",
    "\n",
    "        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n",
    "                                                                                            'variable': 'dataset'})\n",
    "        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n",
    "        plt.title('Training progress')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cat_cols=None, drop_original: bool = False, encoder=OrdinalEncoder()):\n",
    "        \"\"\"\n",
    "        Categorical transformer. This is a wrapper for categorical encoders.\n",
    "\n",
    "        :param cat_cols:\n",
    "        :param drop_original:\n",
    "        :param encoder:\n",
    "        \"\"\"\n",
    "        self.cat_cols = cat_cols\n",
    "        self.drop_original = drop_original\n",
    "        self.encoder = encoder\n",
    "        self.default_encoder = OrdinalEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.cat_cols is None:\n",
    "            kinds = np.array([dt.kind for dt in X.dtypes])\n",
    "            is_cat = kinds == 'O'\n",
    "            self.cat_cols = list(X.columns[is_cat])\n",
    "        self.encoder.set_params(cols=self.cat_cols)\n",
    "        self.default_encoder.set_params(cols=self.cat_cols)\n",
    "\n",
    "        self.encoder.fit(X[self.cat_cols], y)\n",
    "        self.default_encoder.fit(X[self.cat_cols], y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data = copy.deepcopy(X)\n",
    "        new_cat_names = [f'{col}_encoded' for col in self.cat_cols]\n",
    "        encoded_data = self.encoder.transform(data[self.cat_cols])\n",
    "        if encoded_data.shape[1] == len(self.cat_cols):\n",
    "            data[new_cat_names] = encoded_data\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self.drop_original:\n",
    "            data = data.drop(self.cat_cols, axis=1)\n",
    "        else:\n",
    "            data[self.cat_cols] = self.default_encoder.transform(data[self.cat_cols])\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        data = copy.deepcopy(X)\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators':2000,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.75,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.04,\n",
    "            'feature_fraction': 0.9,\n",
    "            'max_depth': 15,\n",
    "            'lambda_l1': 1,  \n",
    "            'lambda_l2': 1,\n",
    "            'verbose': 100,\n",
    "            'early_stopping_rounds': 100, 'eval_metric': 'cappa'\n",
    "            }\n",
    "\n",
    "y = reduce_train['accuracy_group']\n",
    "n_fold = 5\n",
    "folds = GroupKFold(n_splits=n_fold)\n",
    "cols_to_drop = ['game_session', 'installation_id', 'timestamp', 'accuracy_group', 'timestampDate']\n",
    "mt = MainTransformer()\n",
    "ft = FeatureTransformer()\n",
    "transformers = {'ft': ft}\n",
    "regressor_model1 = RegressorModel(model_wrapper=LGBWrapper_regr())\n",
    "regressor_model1.fit(X=reduce_train, y=y, folds=folds, params=params, preprocesser=mt, transformers=transformers,\n",
    "                    eval_metric='cappa', cols_to_drop=cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(regressor_model1.feature_importances['importance'].mean())\n",
    "# importance = regressor_model1.feature_importances.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(300)\n",
    "# print(list(importance.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy as sp\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -qwk(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pr1 = regressor_model1.predict(reduce_train)\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(pr1.reshape(-1,), y)\n",
    "coefficients = optR.coefficients()\n",
    "# coefficients = [1.253629671522606, 1.697962321814793, 1.9425373198379534]\n",
    "# dist = Counter(reduce_train['accuracy_group'])\n",
    "# for k in dist:\n",
    "#     dist[k] /= len(reduce_train)\n",
    "# reduce_train['accuracy_group'].hist()\n",
    "# acum = 0\n",
    "# bound = [0, 0, 0]\n",
    "# for i in range(3):\n",
    "#     acum += dist[i]\n",
    "#     bound[i] = np.percentile(pr1, acum * 100)\n",
    "# coefficients = bound\n",
    "print(coefficients)\n",
    "\n",
    "# coefficients = [1.2614043207566141, 1.6603066679104515, 1.8960011870210187]\n",
    "# coefficients = [1.30, 1.83925866, 2.155] 0.543\n",
    "\n",
    "# coefficients = [1.30, 1.83925866, 2.154] 0.544\n",
    "# coefficients = [1.5256, 1.898, 2.154] 0.535\n",
    "# coefficients = [1.364, 1.83925866, 2.154] 0.545\n",
    "# coefficients = [1.369, 1.83925866, 2.154] 0.545\n",
    "# coefficients = [1.369, 1.845, 2.154] 0.544\n",
    "# coefficients = [1.369, 1.841, 2.154] 0.545\n",
    "# coefficients = [1.40, 1.841, 2.154] 0.542\n",
    "# coefficients = [1.32, 1.83925866, 2.154] 0.542\n",
    "\n",
    "\n",
    "# \n",
    "# coefficients = [1.263, 1.77, 2.025] 0.534\n",
    "# coefficients = [1.16253215,1.71532098,2.17071483] 0.544\n",
    "# coefficients = [1.16253215,1.71532098,2.07071483] 0.543\n",
    "# coefficients = [1.16253215,1.71532098,2.10071483] 0.542\n",
    "# coefficients = [1.18253215,1.71532098,2.17071483] 0.544\n",
    "coefficients = [1.18253215,1.81532098,2.17071483]\n",
    "\n",
    "opt_preds = optR.predict(pr1.reshape(-1, ), coefficients)\n",
    "qwk(y, opt_preds)\n",
    "\n",
    "# some coefficients calculated by me.\n",
    "pr1 = regressor_model1.predict(reduce_test)\n",
    "# print(pr1)\n",
    "# pr1[pr1 <= 1.12232214] = 0\n",
    "# pr1[np.where(np.logical_and(pr1 > 1.12232214, pr1 <= 1.73925866))] = 1\n",
    "# pr1[np.where(np.logical_and(pr1 > 1.73925866, pr1 <= 2.22506454))] = 2\n",
    "# pr1[pr1 > 2.22506454] = 3\n",
    "pr1[pr1 <= coefficients[0]] = 0\n",
    "pr1[np.where(np.logical_and(pr1 > coefficients[0], pr1 <= coefficients[1]))] = 1\n",
    "pr1[np.where(np.logical_and(pr1 > coefficients[1], pr1 <= coefficients[2]))] = 2\n",
    "pr1[pr1 > coefficients[2]] = 3\n",
    "\n",
    "sample_submission['accuracy_group'] = pr1.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
