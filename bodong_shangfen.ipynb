{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sample_submission.csv\n",
      "data/reduce_test.csv\n",
      "data/train_labels.csv\n",
      "data/test.csv\n",
      "data/reduce_train.csv\n",
      "data/train.csv\n",
      "data/specs.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "import re\n",
    "\n",
    "base_dir = 'data/'\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(base_dir):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "* In the last notebook we create our baseline model including a feature selection part. \n",
    "* Cohen cappa score of 0.456 (lb) with a local cv score of 0.529\n",
    "* In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve.\n",
    "* Next, we will check if this improvement aligns with the lb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Check the distribution of the target variable of the out of folds score and the prediction distribution. A good model should more or less have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(reduce_train['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(reduce_train)\n",
    "    reduce_train['accuracy_group'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohenkappa(ypred, y):\n",
    "    y = y.get_label().astype(\"int\")\n",
    "    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n",
    "    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n",
    "    return \"cappa\", loss, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv(base_dir + 'train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv(base_dir + 'test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv(base_dir + 'train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv(base_dir + 'specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv(base_dir + 'sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "\n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    test['hour'] = test['timestamp'].dt.hour\n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_time = {'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n",
    "        '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n",
    "        'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n",
    "        'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n",
    "        'Heavy, Heavier, Heaviest':61}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function that convert the raw data into processed features\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    clip_durations = []\n",
    "    Activity_durations = []\n",
    "    Game_durations = []\n",
    "    \n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "        \n",
    "    # last features\n",
    "    sessions_count = 0\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "                    \n",
    "        if session_type == 'Clip':\n",
    "            clip_durations.append((clip_time[activities_labels[session_title]]))\n",
    "        \n",
    "        if session_type == 'Activity':\n",
    "            Activity_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "        \n",
    "        if session_type == 'Game':\n",
    "            Game_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features['installation_session_count'] = sessions_count\n",
    "            features['hour'] = session['hour'].iloc[-1]\n",
    "            \n",
    "            variety_features = [('var_event_code', event_code_count),\n",
    "                              ('var_event_id', event_id_count),\n",
    "                               ('var_title', title_count),\n",
    "                               ('var_title_event_code', title_event_code_count)]\n",
    "            \n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "                 \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                \n",
    "            if clip_durations == []:\n",
    "                features['Clip_duration_mean'] = 0\n",
    "                features['Clip_duration_std'] = 0\n",
    "            else:\n",
    "                features['Clip_duration_mean'] = np.mean(clip_durations)\n",
    "                features['Clip_duration_std'] = np.std(clip_durations)\n",
    "                \n",
    "            if Activity_durations == []:\n",
    "                features['Activity_duration_mean'] = 0\n",
    "                features['Activity_duration_std'] = 0\n",
    "            else:\n",
    "                features['Activity_duration_mean'] = np.mean(Activity_durations)\n",
    "                features['Activity_duration_std'] = np.std(Activity_durations)\n",
    "                \n",
    "            if Game_durations == []:\n",
    "                features['Game_duration_mean'] = 0\n",
    "                features['Game_duration_std'] = 0\n",
    "            else:\n",
    "                features['Game_duration_mean'] = np.mean(Game_durations)\n",
    "                features['Game_duration_std'] = np.std(Game_durations)\n",
    "                \n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        sessions_count += 1\n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "\n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(reduce_train), ))\n",
    "        y_pred = np.zeros((len(reduce_test), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof cohen kappa score is: ', loss_score)\n",
    "        return y_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 15,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "                         verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000}\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        clf = CatBoostRegressor(**self.params)\n",
    "        clf.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                eval_set=(val_set['X'], val_set['y']),\n",
    "                verbose=verbosity, \n",
    "                cat_features=self.categoricals)\n",
    "        return clf\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'loss_function': 'RMSE',\n",
    "                   'task_type': \"CPU\",\n",
    "                   'iterations': 5000,\n",
    "                   'od_type': \"Iter\",\n",
    "                    'depth': 10,\n",
    "                  'colsample_bylevel': 0.5, \n",
    "                   'early_stopping_rounds': 300,\n",
    "                    'l2_leaf_reg': 18,\n",
    "                   'random_seed': 42,\n",
    "                    'use_best_model': True\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "class Nn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        print(train_df[features].shape)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(train_set['X'].shape[1],)),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(100, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(25, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1, activation='relu')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class Cnn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        self.create_feat_2d(features)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def create_feat_2d(self, features, n_feats_repeat=50):\n",
    "        self.n_feats = len(features)\n",
    "        self.n_feats_repeat = n_feats_repeat\n",
    "        self.mask = np.zeros((self.n_feats_repeat, self.n_feats), dtype=np.int32)\n",
    "        for i in range(self.n_feats_repeat):\n",
    "            l = list(range(self.n_feats))\n",
    "            for j in range(self.n_feats):\n",
    "                c = l.pop(choice(range(len(l))))\n",
    "                self.mask[i, j] = c\n",
    "        self.mask = tf.convert_to_tensor(self.mask)\n",
    "        print(self.mask.shape)\n",
    "       \n",
    "        \n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "\n",
    "        inp = tf.keras.layers.Input(shape=(self.n_feats))\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.gather(x, self.mask, axis=1))(inp)\n",
    "        x = tf.keras.layers.Reshape((self.n_feats_repeat, self.n_feats, 1))(x)\n",
    "        x = tf.keras.layers.Conv2D(18, (50, 50), strides=50, activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        #x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "        #x = tf.keras.layers.LayerNormalization()(x)\n",
    "        #x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        out = tf.keras.layers.Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inp, out)\n",
    "    \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a29a17b20a4b14873a8a5bf1f5f995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b047fdf47f4200a17460a18c6fd4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)\n",
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "reduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stract_hists(feature, train=reduce_train, test=reduce_test, adjust=False, plot=False):\n",
    "    n_bins = 10\n",
    "    train_data = train[feature]\n",
    "    test_data = test[feature]\n",
    "    if adjust:\n",
    "        test_data *= train_data.mean() / test_data.mean()\n",
    "    perc_90 = np.percentile(train_data, 95)\n",
    "    train_data = np.clip(train_data, 0, perc_90)\n",
    "    test_data = np.clip(test_data, 0, perc_90)\n",
    "    train_hist = np.histogram(train_data, bins=n_bins)[0] / len(train_data)\n",
    "    test_hist = np.histogram(test_data, bins=n_bins)[0] / len(test_data)\n",
    "    msre = mean_squared_error(train_hist, test_hist)\n",
    "    if plot:\n",
    "        print(msre)\n",
    "        plt.bar(range(n_bins), train_hist, color='blue', alpha=0.5)\n",
    "        plt.bar(range(n_bins), test_hist, color='red', alpha=0.5)\n",
    "        plt.show()\n",
    "    return msre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call feature engineering function\n",
    "features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in features if x not in ['accuracy_group', 'installation_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# to_remove = []\n",
    "# for feat_a in features:\n",
    "#     for feat_b in features:\n",
    "#         if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n",
    "#             c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]\n",
    "#             if c > 0.995:\n",
    "#                 counter += 1\n",
    "#                 to_remove.append(feat_b)\n",
    "#                 print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_Cart_Balancer__Assessment_ -0.04020325710970143 -0.47065833333333335 0.006732930476733109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13f56524 0.04392312040700961 0.0\n",
      "e4d32835 0.0013001695873374789 0.0\n",
      "ecc6157f 0.007292255511588468 0.0\n",
      "eb2c19cd 0.17382702091577162 0.008 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4074bac2 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119b5b02 0.0002826455624646693 0.0\n",
      "01ca3a3c 0.0004522328999434709 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfc77bd6 0.012832108535895986 0.0\n",
      "5dc079d8 0.0 0.0\n",
      "7fd1ac25 0.01978518937252685 0.0\n",
      "1b54d27f 0.0007348784624081402 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611485c5 0.0013566986998304127 0.0\n",
      "003cd2ee 0.0 0.0\n",
      "17ca3959 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ec694de 0.008988128886376484 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab4ec3a4 0.0009044657998869418 0.0\n",
      "dcb1663e 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a8cc6fec 0.0 0.0\n",
      "29a42aea 0.004070096099491238 0.0\n",
      "0ce40006 0.0008479366873940079 0.0\n",
      "6aeafed4 0.14703222159412097 0.008 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy_Camel_4080 0.0008479366873940079 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fireworks__Activity__4080 0.0013566986998304127 0.0\n",
      "Leaf_Leader_4080 0.0004522328999434709 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubble_Bath_4080 0.004070096099491238 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan_Balance_4080 0.0013001695873374789 0.0\n",
      "Mushroom_Sorter__Assessment__4080 0.04392312040700961 0.0\n",
      "Watering_Hole__Activity__2010 0.0007348784624081402 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandcastle_Builder__Activity__2010 0.0 0.0\n",
      "Egg_Dropper__Activity__4080 0.01978518937252685 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air_Show_4080 0.0 0.0\n",
      "Dino_Dive_4080 0.0002826455624646693 0.0\n",
      "Mushroom_Sorter__Assessment__4090 0.17382702091577162 0.008 0.0\n",
      "Cart_Balancer__Assessment__4080 0.007292255511588468 0.0\n",
      "Chest_Sorter__Assessment__4080 0.012832108535895986 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crystals_Rule_2010 0.0 0.0\n",
      "Dino_Drink_4080 0.0009044657998869418 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug_Measurer__Activity__4080 0.008988128886376484 0.0\n",
      "Pan_Balance_2010 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottle_Filler__Activity__2010 0.0 0.0\n",
      "Scrub_A_Dub_4080 0.0 0.0\n",
      "Bubble_Bath_4090 0.14703222159412097 0.008 0.0\n"
     ]
    }
   ],
   "source": [
    "to_exclude = [] \n",
    "ajusted_test = reduce_test.copy()\n",
    "for feature in ajusted_test.columns:\n",
    "    if feature not in ['accuracy_group', 'installation_id', 'accuracy_group', 'session_title']:\n",
    "        data = reduce_train[feature]\n",
    "        train_mean = data.mean()\n",
    "        data = ajusted_test[feature] \n",
    "        test_mean = data.mean()\n",
    "        try:\n",
    "            error = stract_hists(feature, adjust=True)\n",
    "            ajust_factor = train_mean / test_mean\n",
    "            if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature, train_mean, test_mean, error)\n",
    "            else:\n",
    "                ajusted_test[feature] *= ajust_factor\n",
    "        except:\n",
    "            to_exclude.append(feature)\n",
    "            print(feature, train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 863)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [x for x in features if x not in (to_exclude + to_remove)]\n",
    "reduce_train[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "Using categorical_feature in Dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.0305\tvalid_1's rmse: 1.05931\n",
      "[200]\ttraining's rmse: 0.962271\tvalid_1's rmse: 1.01588\n",
      "[300]\ttraining's rmse: 0.927093\tvalid_1's rmse: 1.00228\n",
      "[400]\ttraining's rmse: 0.902874\tvalid_1's rmse: 0.996695\n",
      "[500]\ttraining's rmse: 0.883154\tvalid_1's rmse: 0.993725\n",
      "[600]\ttraining's rmse: 0.865987\tvalid_1's rmse: 0.99214\n",
      "[700]\ttraining's rmse: 0.850378\tvalid_1's rmse: 0.991052\n",
      "[800]\ttraining's rmse: 0.836225\tvalid_1's rmse: 0.990259\n",
      "[900]\ttraining's rmse: 0.822752\tvalid_1's rmse: 0.989936\n",
      "Early stopping, best iteration is:\n",
      "[899]\ttraining's rmse: 0.822866\tvalid_1's rmse: 0.989926\n",
      "Partial score of fold 0 is: 0.5809355418772589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.03384\tvalid_1's rmse: 1.0504\n",
      "[200]\ttraining's rmse: 0.965089\tvalid_1's rmse: 1.00166\n",
      "[300]\ttraining's rmse: 0.930042\tvalid_1's rmse: 0.985712\n",
      "[400]\ttraining's rmse: 0.905769\tvalid_1's rmse: 0.980441\n",
      "[500]\ttraining's rmse: 0.885815\tvalid_1's rmse: 0.978511\n",
      "[600]\ttraining's rmse: 0.868726\tvalid_1's rmse: 0.977886\n",
      "[700]\ttraining's rmse: 0.852884\tvalid_1's rmse: 0.977783\n",
      "Early stopping, best iteration is:\n",
      "[678]\ttraining's rmse: 0.856254\tvalid_1's rmse: 0.977595\n",
      "Partial score of fold 1 is: 0.5993657891815468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.03496\tvalid_1's rmse: 1.06088\n",
      "[200]\ttraining's rmse: 0.964167\tvalid_1's rmse: 1.01113\n",
      "[300]\ttraining's rmse: 0.929483\tvalid_1's rmse: 0.994947\n",
      "[400]\ttraining's rmse: 0.905057\tvalid_1's rmse: 0.988096\n",
      "[500]\ttraining's rmse: 0.885467\tvalid_1's rmse: 0.985068\n",
      "[600]\ttraining's rmse: 0.868539\tvalid_1's rmse: 0.983066\n",
      "[700]\ttraining's rmse: 0.852982\tvalid_1's rmse: 0.982054\n",
      "[800]\ttraining's rmse: 0.839042\tvalid_1's rmse: 0.98172\n",
      "[900]\ttraining's rmse: 0.825494\tvalid_1's rmse: 0.982014\n",
      "Early stopping, best iteration is:\n",
      "[837]\ttraining's rmse: 0.833959\tvalid_1's rmse: 0.981527\n",
      "Partial score of fold 2 is: 0.5941766904259707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.03634\tvalid_1's rmse: 1.05579\n",
      "[200]\ttraining's rmse: 0.966416\tvalid_1's rmse: 1.00489\n",
      "[300]\ttraining's rmse: 0.930997\tvalid_1's rmse: 0.989161\n",
      "[400]\ttraining's rmse: 0.906186\tvalid_1's rmse: 0.982569\n",
      "[500]\ttraining's rmse: 0.8865\tvalid_1's rmse: 0.980111\n",
      "[600]\ttraining's rmse: 0.8694\tvalid_1's rmse: 0.97893\n",
      "[700]\ttraining's rmse: 0.853795\tvalid_1's rmse: 0.97838\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's rmse: 0.856052\tvalid_1's rmse: 0.978315\n",
      "Partial score of fold 3 is: 0.5999025925010892\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.0329\tvalid_1's rmse: 1.05009\n",
      "[200]\ttraining's rmse: 0.965046\tvalid_1's rmse: 1.00398\n",
      "[300]\ttraining's rmse: 0.930292\tvalid_1's rmse: 0.990013\n",
      "[400]\ttraining's rmse: 0.906519\tvalid_1's rmse: 0.984329\n",
      "[500]\ttraining's rmse: 0.887095\tvalid_1's rmse: 0.981685\n",
      "[600]\ttraining's rmse: 0.87052\tvalid_1's rmse: 0.97974\n",
      "[700]\ttraining's rmse: 0.855327\tvalid_1's rmse: 0.979076\n",
      "[800]\ttraining's rmse: 0.841423\tvalid_1's rmse: 0.978085\n",
      "[900]\ttraining's rmse: 0.8281\tvalid_1's rmse: 0.977912\n",
      "[1000]\ttraining's rmse: 0.815661\tvalid_1's rmse: 0.977882\n",
      "[1100]\ttraining's rmse: 0.803662\tvalid_1's rmse: 0.977651\n",
      "[1200]\ttraining's rmse: 0.792202\tvalid_1's rmse: 0.977362\n",
      "Early stopping, best iteration is:\n",
      "[1196]\ttraining's rmse: 0.792603\tvalid_1's rmse: 0.977318\n",
      "Partial score of fold 4 is: 0.5909439250478419\n",
      "Our oof cohen kappa score is:  0.5924900810110985\n",
      "[0]\ttrain-rmse:1.85612\tval-rmse:1.85738\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.99957\tval-rmse:1.16053\n",
      "[200]\ttrain-rmse:0.714648\tval-rmse:1.02601\n",
      "[300]\ttrain-rmse:0.599779\tval-rmse:1.00477\n",
      "[400]\ttrain-rmse:0.537144\tval-rmse:1.0018\n",
      "[500]\ttrain-rmse:0.496866\tval-rmse:1.00193\n",
      "Stopping. Best iteration:\n",
      "[404]\ttrain-rmse:0.535324\tval-rmse:1.00178\n",
      "\n",
      "Partial score of fold 0 is: 0.5687679999676319\n",
      "[0]\ttrain-rmse:1.85616\tval-rmse:1.85729\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.00056\tval-rmse:1.15477\n",
      "[200]\ttrain-rmse:0.714156\tval-rmse:1.01785\n",
      "[300]\ttrain-rmse:0.593561\tval-rmse:0.995171\n",
      "[400]\ttrain-rmse:0.532417\tval-rmse:0.993758\n",
      "Stopping. Best iteration:\n",
      "[377]\ttrain-rmse:0.543678\tval-rmse:0.993567\n",
      "\n",
      "Partial score of fold 1 is: 0.5809355418772589\n",
      "[0]\ttrain-rmse:1.85617\tval-rmse:1.85734\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.997311\tval-rmse:1.15409\n",
      "[200]\ttrain-rmse:0.712836\tval-rmse:1.01563\n",
      "[300]\ttrain-rmse:0.598006\tval-rmse:0.992203\n",
      "[400]\ttrain-rmse:0.53793\tval-rmse:0.99002\n",
      "Stopping. Best iteration:\n",
      "[378]\ttrain-rmse:0.548639\tval-rmse:0.989776\n",
      "\n",
      "Partial score of fold 2 is: 0.5795040663584793\n",
      "[0]\ttrain-rmse:1.8562\tval-rmse:1.85742\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.996781\tval-rmse:1.15657\n",
      "[200]\ttrain-rmse:0.710566\tval-rmse:1.02056\n",
      "[300]\ttrain-rmse:0.594359\tval-rmse:0.998205\n",
      "[400]\ttrain-rmse:0.531454\tval-rmse:0.995187\n",
      "[500]\ttrain-rmse:0.499338\tval-rmse:0.995448\n",
      "Stopping. Best iteration:\n",
      "[434]\ttrain-rmse:0.518724\tval-rmse:0.995113\n",
      "\n",
      "Partial score of fold 3 is: 0.5784304597193946\n",
      "[0]\ttrain-rmse:1.85616\tval-rmse:1.85733\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.00201\tval-rmse:1.1556\n",
      "[200]\ttrain-rmse:0.72335\tval-rmse:1.01515\n",
      "[300]\ttrain-rmse:0.605512\tval-rmse:0.990535\n",
      "[400]\ttrain-rmse:0.54368\tval-rmse:0.986923\n",
      "[500]\ttrain-rmse:0.50673\tval-rmse:0.986275\n",
      "[600]\ttrain-rmse:0.480177\tval-rmse:0.985507\n",
      "Stopping. Best iteration:\n",
      "[594]\ttrain-rmse:0.482324\tval-rmse:0.98547\n",
      "\n",
      "Partial score of fold 4 is: 0.5900490309875659\n",
      "Our oof cohen kappa score is:  0.5807594936247868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "xgb_model = Xgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_model = Cnn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "# nn_model = Nn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "weights = {'lbg': 0.80, 'cat': 0, 'xgb': 0.20, 'nn': 0.00}\n",
    "\n",
    "final_pred = (lgb_model.y_pred * weights['lbg']) + (xgb_model.y_pred * weights['xgb']) \n",
    "#final_pred = cnn_model.y_pred\n",
    "print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([(round(a, 2), round(b, 2), round(c, 2), round(d, 2)) for a, b, c, d in zip(lgb_model.y_pred, cat_model.y_pred, xgb_model.y_pred, nn_model.y_pred)], columns=['lgb', 'cat', 'xgb', 'nn']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.2888956743521631, 1: 1.666786697578272, 2: 1.9239508984737972}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.500\n",
       "0    0.239\n",
       "1    0.136\n",
       "2    0.125\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = Counter(reduce_train['accuracy_group'])\n",
    "for k in dist:\n",
    "    dist[k] /= len(reduce_train)\n",
    "reduce_train['accuracy_group'].hist()\n",
    "\n",
    "acum = 0\n",
    "bound = {}\n",
    "for i in range(3):\n",
    "    acum += dist[i]\n",
    "    bound[i] = np.percentile(final_pred, acum * 100)\n",
    "print(bound)\n",
    "\n",
    "def classify(x):\n",
    "    if x <= bound[0]:\n",
    "        return 0\n",
    "    elif x <= bound[1]:\n",
    "        return 1\n",
    "    elif x <= bound[2]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "final_pred = np.array(list(map(classify, final_pred)))\n",
    "\n",
    "sample_submission['accuracy_group'] = final_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f8fbc1dc7c946c5b2c627033dbd537d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3198b70da28047ef9f46b341c527ee6e",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bc2972de3dab4bbf9693277ce7f5b2d7",
       "value": 17000
      }
     },
     "11c7c10c6d694193bb68077b00357a23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23722272b7ff4922a8da6a5e520bc543": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "270fc5c55e1d49d7906318182fce377d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef4a74da4e3e452f9f716b31cf528983",
       "placeholder": "",
       "style": "IPY_MODEL_9f64d25818834d5090e6654c537b0c65",
       "value": " 17000/17000 [09:26&lt;00:00, 29.98it/s]"
      }
     },
     "3198b70da28047ef9f46b341c527ee6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e7dcfdc8e9543ea9df23d50d6ae7aa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f8fbc1dc7c946c5b2c627033dbd537d",
        "IPY_MODEL_270fc5c55e1d49d7906318182fce377d"
       ],
       "layout": "IPY_MODEL_d634caf07e7b4bfeb4da13eb04a83f50"
      }
     },
     "9f64d25818834d5090e6654c537b0c65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a28f70a7b3aa4507bc32bc4aeb042098": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff5c2752c48044c184370523389cea67",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_23722272b7ff4922a8da6a5e520bc543",
       "value": 1000
      }
     },
     "bc2972de3dab4bbf9693277ce7f5b2d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c251eb78a6c345dbaa7e4f7fa59f316c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce79367993c94068bc4941095e5d9874": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c251eb78a6c345dbaa7e4f7fa59f316c",
       "placeholder": "",
       "style": "IPY_MODEL_f4344f8da6bc435cbe86cead5ef2c959",
       "value": " 1000/1000 [01:05&lt;00:00, 15.37it/s]"
      }
     },
     "d634caf07e7b4bfeb4da13eb04a83f50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddeb594e1b324481b35383edca9c1858": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a28f70a7b3aa4507bc32bc4aeb042098",
        "IPY_MODEL_ce79367993c94068bc4941095e5d9874"
       ],
       "layout": "IPY_MODEL_11c7c10c6d694193bb68077b00357a23"
      }
     },
     "ef4a74da4e3e452f9f716b31cf528983": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4344f8da6bc435cbe86cead5ef2c959": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ff5c2752c48044c184370523389cea67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
